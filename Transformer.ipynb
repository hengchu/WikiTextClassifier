{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import math\n",
    "import time\n",
    "import importlib\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from cis700.dataset import DBPediaDataset, count_lines\n",
    "from cis700.tokenizer import build_tokenizer\n",
    "from cis700 import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we develop the modules of our attention-based classifier. We had used the blog-post (https://towardsdatascience.com/how-to-code-the-transformer-in-pytorch-24db27c8f9ec) as reference.\n",
    "\n",
    "`WordEmbedding`: a simple wrapper around `nn.Embedding`\n",
    "\n",
    "`PositionEncoding`: a module that implements the sinuoid position encoding described in \"Attention is All You Need\"\n",
    "\n",
    "`MultiheadAttention`: a module that implmenets scale dot product attention\n",
    "\n",
    "`FeedForward`: a simple 2-layer feedforward module with sparsity and dropout\n",
    "\n",
    "`Normalization`: a module that implements batch normalization\n",
    "\n",
    "`EncoderLayer`: a module that puts together self-attention and feedforward module to form a single layer of encoder\n",
    "\n",
    "`Encoder`: a module that places N `EncoderLayers` one after another\n",
    "\n",
    "`Classifier`: encoder plus linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordEmbedding(nn.Module):\n",
    "  def __init__(self, vocab_size, dim_embedding):\n",
    "    super(WordEmbedding, self).__init__()\n",
    "    self.embed = nn.Embedding(vocab_size, dim_embedding)\n",
    "  def forward(self, x):\n",
    "    return self.embed(x)\n",
    "  \n",
    "class PositionEncoding(nn.Module):\n",
    "  def __init__(self, dim_embedding, max_seq_len):\n",
    "    super(PositionEncoding, self).__init__()\n",
    "    self.dim_embedding = dim_embedding\n",
    "    \n",
    "    pe = torch.zeros(max_seq_len, dim_embedding)\n",
    "    for pos in range(max_seq_len):\n",
    "      for i in range(0, dim_embedding, 2):\n",
    "        pe[pos, i] = math.sin(pos / (10000 ** ((2 * i) / dim_embedding)))\n",
    "        pe[pos, i+1] = math.cos(pos / (10000 ** ((2 * (i+1)) / dim_embedding)))\n",
    "        \n",
    "    pe = pe.unsqueeze(0)\n",
    "    self.register_buffer('pe', pe)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    x = x * math.sqrt(self.dim_embedding)\n",
    "    x_len = x.size(1)\n",
    "    x = x + Variable(self.pe[:,:x_len], requires_grad=False).cuda()\n",
    "    return x\n",
    "  \n",
    "class MultiheadAttention(nn.Module):\n",
    "  def __init__(self, num_heads, dim_embedding, dropout = 0.1):\n",
    "    super(MultiheadAttention, self).__init__()\n",
    "    \n",
    "    self.dim_embedding = dim_embedding\n",
    "    self.dim_k = dim_embedding / num_heads\n",
    "    if int(self.dim_k) != self.dim_k:\n",
    "      raise ValueError('num_heads should divide dim_embedding evenly! num_heads = %d, dim_embedding = %d' \\\n",
    "                       % (num_heads, dim_embedding))\n",
    "    self.dim_k = int(self.dim_k)\n",
    "    self.num_heads = num_heads\n",
    "    \n",
    "    self.q_linear = nn.Linear(dim_embedding, dim_embedding)\n",
    "    self.v_linear = nn.Linear(dim_embedding, dim_embedding)\n",
    "    self.k_linear = nn.Linear(dim_embedding, dim_embedding)\n",
    "    \n",
    "    self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    self.out = nn.Linear(dim_embedding, dim_embedding)\n",
    "    \n",
    "  def attention(self, q, v, k, mask):\n",
    "    scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.dim_k)\n",
    "    # print('q.size = %s' % str(q.size()))\n",
    "    # print('scores.size = %s' % str(scores.size()))\n",
    "    mask = mask.unsqueeze(1).unsqueeze(1)\n",
    "    scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    \n",
    "    # print(scores.size())\n",
    "    scores = F.softmax(scores, dim=-1)\n",
    "    # print(scores.size())\n",
    "    scores = self.dropout(scores)\n",
    "    \n",
    "    return torch.matmul(scores, v)\n",
    "    \n",
    "  def forward(self, q, v, k, mask):\n",
    "    batch_size = q.size(0)\n",
    "    \n",
    "    q = self.q_linear(q).view(batch_size, -1, self.num_heads, self.dim_k)\n",
    "    v = self.v_linear(v).view(batch_size, -1, self.num_heads, self.dim_k)\n",
    "    k = self.k_linear(k).view(batch_size, -1, self.num_heads, self.dim_k)\n",
    "    \n",
    "    q = q.transpose(1, 2)\n",
    "    v = v.transpose(1, 2)\n",
    "    k = k.transpose(1, 2)\n",
    "    \n",
    "    scores = self.attention(q, v, k, mask)\n",
    "    scores = scores.transpose(1, 2).contiguous().view(batch_size, -1, self.dim_embedding)\n",
    "    return scores\n",
    "  \n",
    "class FeedForward(nn.Module):\n",
    "  def __init__(self, dim_embedding, num_features, dropout = 0.1):\n",
    "    super(FeedForward, self).__init__()\n",
    "    self.fc1 = nn.Linear(dim_embedding, num_features)\n",
    "    self.dropout = nn.Dropout(dropout)\n",
    "    self.fc2 = nn.Linear(num_features, dim_embedding)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    x = self.fc1(x)\n",
    "    x = F.relu(x)\n",
    "    x = self.dropout(x)\n",
    "    return self.fc2(x)\n",
    "  \n",
    "class Normalization(nn.Module):\n",
    "  def __init__(self, dim_embedding, eps = 1e-6):\n",
    "    super(Normalization, self).__init__()\n",
    "    \n",
    "    self.dim_embedding = dim_embedding\n",
    "    self.alpha = nn.Parameter(torch.ones(self.dim_embedding))\n",
    "    self.bias = nn.Parameter(torch.zeros(self.dim_embedding))\n",
    "    self.eps = eps\n",
    "    \n",
    "  def forward(self, x):\n",
    "    norm = self.alpha * (x - x.mean(dim=-1, keepdim=True)) / (x.std(dim=-1, keepdim=True) + self.eps) + self.bias\n",
    "    return norm\n",
    "  \n",
    "class EncoderLayer(nn.Module):\n",
    "  def __init__(self, num_heads, dim_embedding, ff_num_features, dropout=0.1):\n",
    "    super(EncoderLayer, self).__init__()\n",
    "    self.attention = MultiheadAttention(num_heads, dim_embedding)\n",
    "    self.norm1 = Normalization(dim_embedding)\n",
    "    self.ff = FeedForward(dim_embedding, ff_num_features)\n",
    "    self.norm2 = Normalization(dim_embedding)\n",
    "    self.drop1 = nn.Dropout(dropout)\n",
    "    self.drop2 = nn.Dropout(dropout)\n",
    "    \n",
    "  def forward(self, x, mask):\n",
    "    x_ = self.norm1(x)\n",
    "    x = x + self.drop1(self.attention(x_, x_, x_, mask))\n",
    "    x_ = self.norm2(x)\n",
    "    x = x + self.drop2(self.ff(x_))\n",
    "    return x\n",
    "  \n",
    "class Encoder(nn.Module):\n",
    "  def __init__(self, vocab_size, dim_embedding, num_heads, ff_num_features, num_encoder_layers, max_seq_len):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.num_encoder_layers = num_encoder_layers\n",
    "    self.embed = WordEmbedding(vocab_size, dim_embedding)\n",
    "    self.pe = PositionEncoding(dim_embedding, max_seq_len)\n",
    "    self.encoder_layers = \\\n",
    "      nn.ModuleList([EncoderLayer(num_heads, dim_embedding, ff_num_features) for _ in range(num_encoder_layers)])\n",
    "    self.norm = Normalization(dim_embedding)\n",
    "    \n",
    "  def forward(self, x, mask):\n",
    "    x = self.embed(x)\n",
    "    x = self.pe(x)\n",
    "    for i in range(self.num_encoder_layers):\n",
    "      x = self.encoder_layers[i](x, mask)\n",
    "    return self.norm(x)\n",
    "  \n",
    "class Classifier(nn.Module):\n",
    "  def __init__(self, \n",
    "               vocab_size, dim_embedding, num_heads, \n",
    "               ff_num_features, num_encoder_layers, \n",
    "               max_seq_len, num_classes):\n",
    "    super(Classifier, self).__init__()\n",
    "    self.dim_embedding = dim_embedding\n",
    "    self.max_seq_len = max_seq_len\n",
    "    self.encoder = Encoder(vocab_size, dim_embedding, num_heads, ff_num_features, num_encoder_layers, max_seq_len)\n",
    "    self.fc = nn.Linear(dim_embedding * max_seq_len, num_classes)\n",
    "    \n",
    "  def forward(self, x, mask):\n",
    "    x = self.encoder(x, mask)\n",
    "    return self.fc(x.view(-1, self.dim_embedding * self.max_seq_len))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some utility functions working with models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(model):\n",
    "  for p in model.parameters():\n",
    "    if p.dim() > 1:\n",
    "      nn.init.xavier_uniform_(p)\n",
    "      \n",
    "def save_model(model, name, epoch, step):\n",
    "  filename = 'checkpoints/%s.epoch-%d.step-%d.pth' % (name, epoch, step)\n",
    "  torch.save(model.state_dict(), filename)\n",
    "\n",
    "def human_readable_prediction(text, model, max_seq_len, cat_id2text_fun):\n",
    "  tok = build_tokenizer()\n",
    "  tokens = tok.tokenize(text)\n",
    "  ids = tok.convert_tokens_to_ids(tokens)\n",
    "  if len(ids) > max_seq_len:\n",
    "    ids = ids[0:max_seq_len]\n",
    "  masks = [1] * len(ids)\n",
    "  ids += [0] * (max_seq_len - len(ids))\n",
    "  masks += [0] * (max_seq_len - len(masks))\n",
    "  \n",
    "  model.eval()\n",
    "  ids = torch.Tensor(ids).type(torch.LongTensor).cuda().unsqueeze(0)\n",
    "  masks = torch.Tensor(masks).cuda().unsqueeze(0)\n",
    "  scores = model(ids, masks).squeeze()\n",
    "  top_k = 5\n",
    "  _, max_cat_ids = torch.topk(scores, k = top_k, dim = 0)\n",
    "  top_cats = [cat_id2text_fun(int(max_cat_ids[i])) for i in range(top_k)]\n",
    "  return top_cats\n",
    "\n",
    "def swap_linear_layer(model, new_num_classes):\n",
    "  model.fc = nn.Linear(model.dim_embedding * model.max_seq_len, new_num_classes)\n",
    "  return model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1 (Baseline on fine categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurations\n",
    "max_seq_len        = 256\n",
    "dim_embedding      = 50\n",
    "num_heads          = 5\n",
    "num_encoder_layers = 6\n",
    "ff_num_features    = 1024\n",
    "vocab_size         = count_lines('cis700/vocab/bert-base-uncased-vocab.txt')\n",
    "batch_size         = 50\n",
    "\n",
    "network_name = 'transformer-fine-s%d-e%d-h%d-l%d' % (max_seq_len, dim_embedding, num_heads, num_encoder_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1384619/1384619 [00:09<00:00, 148528.73it/s]\n",
      "100%|██████████| 1384619/1384619 [12:08<00:00, 1901.85it/s]\n"
     ]
    }
   ],
   "source": [
    "dbpedia_data = DBPediaDataset('/Users/hengchu/Downloads/cis700data/joinedlonabstract_en.nt', max_seq_len=max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_portion = 0.8\n",
    "validation_portion = 0.1\n",
    "\n",
    "train_size = int(len(dbpedia_data) * train_portion)\n",
    "validation_size = int(len(dbpedia_data) * validation_portion)\n",
    "test_size = len(dbpedia_data) - train_size - validation_size\n",
    "\n",
    "train_set, validation_set, test_set = \\\n",
    "  torch.utils.data.random_split(dbpedia_data, [train_size, validation_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(validation_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather number of categories\n",
    "num_fine_classes = dbpedia_data.num_fine_cats()\n",
    "num_coarse_classes = dbpedia_data.num_coarse_cats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[0] took 3039.741480 seconds\n",
      "train = 0.266667, validation = 0.372993, loss = 2.936191\n",
      "Epoch[1] took 3021.754335 seconds\n",
      "train = 0.400000, validation = 0.402705, loss = 2.192239\n",
      "Epoch[2] took 3022.240774 seconds\n",
      "train = 0.488889, validation = 0.416861, loss = 2.177934\n",
      "Epoch[3] took 3020.754504 seconds\n",
      "train = 0.511111, validation = 0.430367, loss = 2.063056\n",
      "Epoch[4] took 3020.989862 seconds\n",
      "train = 0.488889, validation = 0.431053, loss = 2.216483\n",
      "Epoch[5] took 3020.094303 seconds\n",
      "train = 0.733333, validation = 0.433537, loss = 1.485769\n",
      "Epoch[6] took 3020.544596 seconds\n",
      "train = 0.600000, validation = 0.435661, loss = 1.564788\n",
      "Epoch[7] took 3019.780324 seconds\n",
      "train = 0.711111, validation = 0.434606, loss = 1.338268\n",
      "Epoch[8] took 3019.645545 seconds\n",
      "train = 0.733333, validation = 0.435083, loss = 1.493338\n",
      "Epoch[9] took 3020.677503 seconds\n",
      "train = 0.577778, validation = 0.432555, loss = 1.768355\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0')\n",
    "\n",
    "model = Classifier(vocab_size, dim_embedding, num_heads,\n",
    "                   ff_num_features, num_encoder_layers, \n",
    "                   max_seq_len, num_fine_classes)\n",
    "initialize_model(model)\n",
    "model = model.cuda()\n",
    "optimizer = Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
    "loss_fun = nn.CrossEntropyLoss()\n",
    "tb_writer = SummaryWriter('./logs')\n",
    "epochs = 10\n",
    "\n",
    "step  = 0\n",
    "epoch = 0\n",
    "\n",
    "for i in range(epochs):\n",
    "  start_time = time.time()\n",
    "  loss_val, validation_score, train_score = None, None, None\n",
    "  for i_batch, batch_data in enumerate(train_loader):\n",
    "    ids = batch_data[0].type(torch.LongTensor)\n",
    "    masks = batch_data[1]\n",
    "    fine_cats = batch_data[2]\n",
    "    loss_val, train_score = utils.transformer_train(model, ids.cuda(), masks.cuda(), fine_cats.cuda(), loss_fun, optimizer)\n",
    "    tb_writer.add_scalar('%s/loss_val' % network_name, loss_val, global_step=step)\n",
    "    tb_writer.add_scalar('%s/train_acc' % network_name, train_score, global_step=step)\n",
    "    step += 1\n",
    "    if step % 5000 == 0:\n",
    "      save_model(model, network_name, epoch, step)\n",
    "  validation_score = utils.transformer_validate(model, validation_loader, 2, device)\n",
    "  tb_writer.add_scalar('%s/validation_acc' % network_name, validation_score, global_step=step)\n",
    "  end_time = time.time()\n",
    "  epoch = i\n",
    "  print('Epoch[%d] took %f seconds' % (epoch, end_time - start_time))\n",
    "  print('train = %f, validation = %f, loss = %f' % (train_score, validation_score, loss_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, network_name, epoch, step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2 ((Baseline on f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurations\n",
    "max_seq_len        = 256\n",
    "dim_embedding      = 50\n",
    "num_heads          = 5\n",
    "num_encoder_layers = 6\n",
    "ff_num_features    = 1024\n",
    "vocab_size         = count_lines('cis700/vocab/bert-base-uncased-vocab.txt')\n",
    "batch_size         = 50\n",
    "\n",
    "network_name = 'transformer-coarse-2-s%d-e%d-h%d-l%d' % (max_seq_len, dim_embedding, num_heads, num_encoder_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1384619/1384619 [00:10<00:00, 135355.49it/s]\n",
      "100%|██████████| 1384619/1384619 [12:02<00:00, 1916.24it/s]\n"
     ]
    }
   ],
   "source": [
    "dbpedia_data = DBPediaDataset('/Users/hengchu/Downloads/cis700data/joinedlonabstract_en.nt', max_seq_len=max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_portion = 0.8\n",
    "validation_portion = 0.1\n",
    "\n",
    "train_size = int(len(dbpedia_data) * train_portion)\n",
    "validation_size = int(len(dbpedia_data) * validation_portion)\n",
    "test_size = len(dbpedia_data) - train_size - validation_size\n",
    "\n",
    "train_set, validation_set, test_set = \\\n",
    "  torch.utils.data.random_split(dbpedia_data, [train_size, validation_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(validation_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather number of categories\n",
    "num_fine_classes = dbpedia_data.num_fine_cats()\n",
    "num_coarse_classes = dbpedia_data.num_coarse_cats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[0] took 2919.140594 seconds\n",
      "train = 0.355556, validation = 0.382851, loss = 2.669782\n",
      "Epoch[1] took 2914.652169 seconds\n",
      "train = 0.488889, validation = 0.412867, loss = 2.143310\n",
      "Epoch[2] took 2914.346581 seconds\n",
      "train = 0.488889, validation = 0.425087, loss = 2.048670\n",
      "Epoch[3] took 2912.895249 seconds\n",
      "train = 0.466667, validation = 0.433349, loss = 1.624332\n",
      "Epoch[4] took 2913.289681 seconds\n",
      "train = 0.488889, validation = 0.439763, loss = 1.862073\n",
      "Epoch[5] took 2915.485798 seconds\n",
      "train = 0.466667, validation = 0.442630, loss = 1.840591\n",
      "Epoch[6] took 2913.253220 seconds\n",
      "train = 0.644444, validation = 0.443396, loss = 1.529210\n",
      "Epoch[7] took 2908.874687 seconds\n",
      "train = 0.644444, validation = 0.443338, loss = 1.066650\n",
      "Epoch[8] took 2908.982422 seconds\n",
      "train = 0.444444, validation = 0.443908, loss = 2.040223\n",
      "Epoch[9] took 2909.085295 seconds\n",
      "train = 0.577778, validation = 0.442226, loss = 1.453888\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0')\n",
    "\n",
    "model = Classifier(vocab_size, dim_embedding, num_heads,\n",
    "                   ff_num_features, num_encoder_layers, \n",
    "                   max_seq_len, num_coarse_classes)\n",
    "initialize_model(model)\n",
    "model = model.cuda()\n",
    "optimizer = Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
    "loss_fun = nn.CrossEntropyLoss()\n",
    "tb_writer = SummaryWriter('./logs')\n",
    "epochs = 10\n",
    "\n",
    "step  = 0\n",
    "epoch = 0\n",
    "\n",
    "for i in range(epochs):\n",
    "  start_time = time.time()\n",
    "  loss_val, validation_score, train_score = None, None, None\n",
    "  for i_batch, batch_data in enumerate(train_loader):\n",
    "    ids = batch_data[0].type(torch.LongTensor)\n",
    "    masks = batch_data[1]\n",
    "    coarse_cats = batch_data[3]\n",
    "    loss_val, train_score = utils.transformer_train(model, ids.cuda(), masks.cuda(), coarse_cats.cuda(), loss_fun, optimizer)\n",
    "    tb_writer.add_scalar('%s/loss_val' % network_name, loss_val, global_step=step)\n",
    "    tb_writer.add_scalar('%s/train_acc' % network_name, train_score, global_step=step)\n",
    "    step += 1\n",
    "    if step % 5000 == 0:\n",
    "      save_model(model, network_name, epoch, step)\n",
    "  validation_score = utils.transformer_validate(model, validation_loader, 3, device)\n",
    "  tb_writer.add_scalar('%s/validation_acc' % network_name, validation_score, global_step=step)\n",
    "  end_time = time.time()\n",
    "  epoch = i\n",
    "  print('Epoch[%d] took %f seconds' % (epoch, end_time - start_time))\n",
    "  print('train = %f, validation = %f, loss = %f' % (train_score, validation_score, loss_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, network_name, epoch, step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurations\n",
    "max_seq_len        = 256\n",
    "dim_embedding      = 50\n",
    "num_heads          = 5\n",
    "num_encoder_layers = 6\n",
    "ff_num_features    = 1024\n",
    "vocab_size         = count_lines('cis700/vocab/bert-base-uncased-vocab.txt')\n",
    "batch_size         = 50\n",
    "\n",
    "network_name = 'transformer-bootstrap2-s%d-e%d-h%d-l%d' % (max_seq_len, dim_embedding, num_heads, num_encoder_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1384619/1384619 [00:09<00:00, 142777.82it/s]\n",
      "100%|██████████| 1384619/1384619 [12:58<00:00, 1779.17it/s]\n"
     ]
    }
   ],
   "source": [
    "dbpedia_data = DBPediaDataset('/Users/hengchu/Downloads/cis700data/joinedlonabstract_en.nt', max_seq_len=max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_portion = 0.8\n",
    "validation_portion = 0.1\n",
    "\n",
    "train_size = int(len(dbpedia_data) * train_portion)\n",
    "validation_size = int(len(dbpedia_data) * validation_portion)\n",
    "test_size = len(dbpedia_data) - train_size - validation_size\n",
    "\n",
    "train_set, validation_set, test_set = \\\n",
    "  torch.utils.data.random_split(dbpedia_data, [train_size, validation_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(validation_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather number of categories\n",
    "num_fine_classes = dbpedia_data.num_fine_cats()\n",
    "num_coarse_classes = dbpedia_data.num_coarse_cats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[0] took 3009.360830 seconds\n",
      "train = 0.511111, validation = 0.386304, loss = 2.504602\n",
      "Epoch[1] took 3004.730604 seconds\n",
      "train = 0.288889, validation = 0.413633, loss = 2.671784\n",
      "Epoch[0] took 3008.795308 seconds\n",
      "train = 0.400000, validation = 0.393410, loss = 2.783735\n",
      "Epoch[1] took 3007.895700 seconds\n",
      "train = 0.422222, validation = 0.406815, loss = 2.259828\n",
      "Epoch[2] took 3008.049983 seconds\n",
      "train = 0.422222, validation = 0.420718, loss = 2.710992\n",
      "Epoch[3] took 3006.731926 seconds\n",
      "train = 0.377778, validation = 0.426106, loss = 2.422018\n",
      "Epoch[4] took 3007.334610 seconds\n",
      "train = 0.400000, validation = 0.429457, loss = 2.677648\n",
      "Epoch[5] took 3006.229599 seconds\n",
      "train = 0.400000, validation = 0.431089, loss = 2.263628\n",
      "Epoch[6] took 3005.469187 seconds\n",
      "train = 0.511111, validation = 0.434823, loss = 2.273735\n",
      "Epoch[7] took 3005.929760 seconds\n",
      "train = 0.533333, validation = 0.436267, loss = 2.120381\n",
      "Epoch[8] took 3004.892882 seconds\n",
      "train = 0.488889, validation = 0.436997, loss = 2.239928\n",
      "Epoch[9] took 3007.185283 seconds\n",
      "train = 0.422222, validation = 0.439171, loss = 2.480966\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0')\n",
    "\n",
    "model = Classifier(vocab_size, dim_embedding, num_heads,\n",
    "                   ff_num_features, num_encoder_layers, \n",
    "                   max_seq_len, num_coarse_classes)\n",
    "initialize_model(model)\n",
    "model = model.cuda()\n",
    "optimizer = Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
    "loss_fun = nn.CrossEntropyLoss()\n",
    "tb_writer = SummaryWriter('./logs')\n",
    "coarse_epochs = 2\n",
    "fine_epochs = 10\n",
    "\n",
    "step  = 0\n",
    "epoch = 0\n",
    "\n",
    "# train coarse_epochs on coarse labels\n",
    "for i in range(coarse_epochs):\n",
    "  start_time = time.time()\n",
    "  loss_val, validation_score, train_score = None, None, None\n",
    "  for i_batch, batch_data in enumerate(train_loader):\n",
    "    ids = batch_data[0].type(torch.LongTensor)\n",
    "    masks = batch_data[1]\n",
    "    coarse_cats = batch_data[3]\n",
    "    loss_val, train_score = utils.transformer_train(model, ids.cuda(), masks.cuda(), coarse_cats.cuda(), loss_fun, optimizer)\n",
    "    tb_writer.add_scalar('%s/loss_val' % network_name, loss_val, global_step=step)\n",
    "    tb_writer.add_scalar('%s/train_acc' % network_name, train_score, global_step=step)\n",
    "    step += 1\n",
    "    if step % 5000 == 0:\n",
    "      save_model(model, network_name, epoch, step)\n",
    "  validation_score = utils.transformer_validate(model, validation_loader, 3, device)\n",
    "  tb_writer.add_scalar('%s/validation_acc' % network_name, validation_score, global_step=step)\n",
    "  end_time = time.time()\n",
    "  epoch = i\n",
    "  print('Epoch[%d] took %f seconds' % (epoch, end_time - start_time))\n",
    "  print('train = %f, validation = %f, loss = %f' % (train_score, validation_score, loss_val))\n",
    "  \n",
    "model = swap_linear_layer(model, num_fine_classes)\n",
    "\n",
    "# then train fine_epochs on fine labels, compare accuracy increases to vanilla training on fine labels\n",
    "for i in range(fine_epochs):\n",
    "  start_time = time.time()\n",
    "  loss_val, validation_score, train_score = None, None, None\n",
    "  for i_batch, batch_data in enumerate(train_loader):\n",
    "    ids = batch_data[0].type(torch.LongTensor)\n",
    "    masks = batch_data[1]\n",
    "    fine_cats = batch_data[2]\n",
    "    loss_val, train_score = utils.transformer_train(model, ids.cuda(), masks.cuda(), fine_cats.cuda(), loss_fun, optimizer)\n",
    "    tb_writer.add_scalar('%s/loss_val' % network_name, loss_val, global_step=step)\n",
    "    tb_writer.add_scalar('%s/train_acc' % network_name, train_score, global_step=step)\n",
    "    step += 1\n",
    "    if step % 5000 == 0:\n",
    "      save_model(model, network_name, epoch, step)\n",
    "  validation_score = utils.transformer_validate(model, validation_loader, 2, device)\n",
    "  tb_writer.add_scalar('%s/validation_acc' % network_name, validation_score, global_step=step)\n",
    "  end_time = time.time()\n",
    "  epoch = i\n",
    "  print('Epoch[%d] took %f seconds' % (epoch, end_time - start_time))\n",
    "  print('train = %f, validation = %f, loss = %f' % (train_score, validation_score, loss_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, network_name, epoch, step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check (please ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d6acb9c9488c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mff_num_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_encoder_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_seq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_fine_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/fun/cis700project/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \"\"\"\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/fun/cis700project/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/fun/cis700project/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/fun/cis700project/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/fun/cis700project/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    191\u001b[0m                 \u001b[0;31m# Tensors stored in modules are graph leaves, and we don't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m                 \u001b[0;31m# want to create copy nodes, so we have to unpack the data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m                 \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                     \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/fun/cis700project/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \"\"\"\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  if model:\n",
    "    del model\n",
    "except:\n",
    "  pass\n",
    "\n",
    "model = Classifier(vocab_size, dim_embedding, num_heads, ff_num_features, num_encoder_layers, max_seq_len, num_fine_classes)\n",
    "model = model.cuda()\n",
    "_, first_batch = next(enumerate(train_loader))\n",
    "ids = first_batch[0].type(torch.LongTensor).cuda()\n",
    "masks = first_batch[1].cuda()\n",
    "r = model(ids, masks)\n",
    "print(r)\n",
    "print(r.size())\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scratch cells (please ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'cis700.utils' from '/Users/hengchu/Documents/fun/cis700project/cis700/utils.py'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, network_name, epoch, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-d8a48a525a57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/fun/cis700project/cis700/utils.py\u001b[0m in \u001b[0;36mtransformer_validate\u001b[0;34m(model, dataloader, y_idx, device)\u001b[0m\n\u001b[1;32m    119\u001b[0m       \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m       \u001b[0mnum_correct\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m       \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "utils.transformer_validate(model, validation_loader, 3, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.0368, device='cuda:0', grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4496, device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> raw text\n",
      "In fencing, an attack is the first offensive movement of a phrase.\n",
      ">>> coarse cat:\n",
      "<http://dbpedia.org/resource/Category:Behavior>\n",
      ">>> fine cat:\n",
      "<http://dbpedia.org/resource/Category:Conflict>\n",
      ">>> top predictions: \n",
      "<http://dbpedia.org/resource/Category:Humans>\n",
      "<http://dbpedia.org/resource/Category:Society>\n",
      "<http://dbpedia.org/resource/Category:Government>\n",
      "<http://dbpedia.org/resource/Category:Social_institutions>\n",
      "<http://dbpedia.org/resource/Category:Politics>\n"
     ]
    }
   ],
   "source": [
    "# find cases where the network guesses wrong\n",
    "\n",
    "go = True\n",
    "while go:\n",
    "  idx = random.randint(0, len(dbpedia_data))\n",
    "  features = dbpedia_data.get_feature(idx)\n",
    "  top_cats = human_readable_prediction(dbpedia_data.get_feature(idx).text,\n",
    "                                       model,\n",
    "                                       max_seq_len,\n",
    "                                       lambda id: dbpedia_data.fine_id2cat(id))\n",
    "  if features.fine_cat_text in top_cats:\n",
    "    continue\n",
    "\n",
    "  print('>>> raw text')\n",
    "  print(features.text)\n",
    "  print('\\n')\n",
    "  print('>>> coarse cat:')\n",
    "  print(features.coarse_cat_text)\n",
    "  print('\\n')\n",
    "  print('>>> fine cat:')\n",
    "  print(features.fine_cat_text)\n",
    "  print('\\n')\n",
    "  print('>>> top predictions: ')\n",
    "  for c in top_cats:\n",
    "    print(c)\n",
    "    \n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> raw text\n",
      "In metadata, property equivalence is the statement that two properties have the same property extension or values. This usually (but not always) implies that the two properties have the same semantics or meaning. Technically it only implies that the data elements have the same values. Property equivalence is one of the three ways that a metadata registry can store equivalence mappings to other metadata registries. Note that property equivalence is not the same as property equality. Equivalent properties have the same \\\"values\\\", but may have different intensional meaning (i.e., denote different concepts). Property equality should be expressed with the owl:sameAs construct. As this requires that properties are treated as individuals, such axioms are only allowed in OWL Full.\n",
      "\n",
      ">>> coarse cat:\n",
      "<http://dbpedia.org/resource/Category:Technology>\n",
      "\n",
      ">>> fine cat:\n",
      "<http://dbpedia.org/resource/Category:Information_technology>\n",
      "\n",
      ">>> top predictions: \n",
      "\n",
      "<http://dbpedia.org/resource/Category:Information_technology>\n",
      "<http://dbpedia.org/resource/Category:Technology_by_type>\n",
      "<http://dbpedia.org/resource/Category:Computing>\n",
      "<http://dbpedia.org/resource/Category:Academic_disciplines>\n",
      "<http://dbpedia.org/resource/Category:Nature>\n"
     ]
    }
   ],
   "source": [
    "  idx = random.randint(0, len(dbpedia_data))\n",
    "  features = dbpedia_data.get_feature(idx)\n",
    "  top_cats = human_readable_prediction(dbpedia_data.get_feature(idx).text,\n",
    "                                       model,\n",
    "                                       max_seq_len,\n",
    "                                       lambda id: dbpedia_data.fine_id2cat(id))\n",
    "\n",
    "  print('>>> raw text')\n",
    "  print(features.text)\n",
    "  print('')\n",
    "  print('>>> coarse cat:')\n",
    "  print(features.coarse_cat_text)\n",
    "  print('')\n",
    "  print('>>> fine cat:')\n",
    "  print(features.fine_cat_text)\n",
    "  print('')\n",
    "  print('>>> top predictions: ')\n",
    "  print('')\n",
    "  for c in top_cats:\n",
    "    print(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mighty and terrible god of internet typos. The mysterious and all-knowing overlord of the Twitter trolls, and Pepe is his prophet. On this the 30th day of May, he was summoned by the orange king to begin his reign of terror over the lawless wasteland of cyberspace. And it shall be that no blogger, no profile, no Twitter egg shall know peace in the hereafter until they have bowed in reverence and fear at the glorious might of Covfefe.\n",
      "\n",
      "<http://dbpedia.org/resource/Category:Categories_for_renaming>\n",
      "<http://dbpedia.org/resource/Category:Books_by_genre>\n",
      "<http://dbpedia.org/resource/Category:Categories_by_year>\n",
      "<http://dbpedia.org/resource/Category:Information>\n",
      "<http://dbpedia.org/resource/Category:Literature>\n"
     ]
    }
   ],
   "source": [
    "text = 'The mighty and terrible god of internet typos. The mysterious and all-knowing overlord of the Twitter trolls, and Pepe is his prophet. On this the 30th day of May, he was summoned by the orange king to begin his reign of terror over the lawless wasteland of cyberspace. And it shall be that no blogger, no profile, no Twitter egg shall know peace in the hereafter until they have bowed in reverence and fear at the glorious might of Covfefe.'\n",
    "top_cats = human_readable_prediction(text,\n",
    "                                     model,\n",
    "                                     max_seq_len,\n",
    "                                     lambda id: dbpedia_data.fine_id2cat(id))\n",
    "print(text)\n",
    "print('')\n",
    "for c in top_cats:\n",
    "  print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"-30- (released as Deadline Midnight in the UK) is a 1959 movie starring William Conrad and Jack Webb as the editor and publisher, respectively, of a fictional Los Angeles evening newspaper. As the shift of a typical day starts, in which they don't know what will happen, the newspaper is created before our eyes as different stories are discovered and reported.\", 'ids': [1011, 2382, 1011, 1006, 2207, 2004, 15117, 7090, 1999, 1996, 2866, 1007, 2003, 1037, 3851, 3185, 4626, 2520, 10931, 1998, 2990, 10923, 2004, 1996, 3559, 1998, 6674, 1010, 4414, 1010, 1997, 1037, 7214, 3050, 3349, 3944, 3780, 1012, 2004, 1996, 5670, 1997, 1037, 5171, 2154, 4627, 1010, 1999, 2029, 2027, 2123, 1005, 1056, 2113, 2054, 2097, 4148, 1010, 1996, 3780, 2003, 2580, 2077, 2256, 2159, 2004, 2367, 3441, 2024, 3603, 1998, 2988, 1012, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'masks': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'fine_cat': 0, 'coarse_cat': 0, 'fine_cat_text': '<http://dbpedia.org/resource/Category:Art_media>', 'coarse_cat_text': '<http://dbpedia.org/resource/Category:Arts>'}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbpedia_data.get_feature(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-56b31908e0b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/fun/cis700project/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \"\"\"\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/fun/cis700project/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/fun/cis700project/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/fun/cis700project/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/fun/cis700project/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    191\u001b[0m                 \u001b[0;31m# Tensors stored in modules are graph leaves, and we don't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m                 \u001b[0;31m# want to create copy nodes, so we have to unpack the data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m                 \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                     \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/fun/cis700project/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \"\"\"\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (59) : device-side assert triggered at /Users/hengchu/Documents/work/pytorch/torch/csrc/cuda/Module.cpp:195",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-7dac343b941e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynchronize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/fun/cis700project/venv/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36msynchronize\u001b[0;34m()\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;34mr\"\"\"Waits for all kernels in all streams on current device to complete.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0m_lazy_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_synchronize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (59) : device-side assert triggered at /Users/hengchu/Documents/work/pytorch/torch/csrc/cuda/Module.cpp:195"
     ]
    }
   ],
   "source": [
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.max_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=100, out_features=10, bias=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Linear(100, 10).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (encoder): Encoder(\n",
       "    (embed): WordEmbedding(\n",
       "      (embed): Embedding(30522, 50)\n",
       "    )\n",
       "    (pe): PositionEncoding()\n",
       "    (encoder_layers): ModuleList(\n",
       "      (0): EncoderLayer(\n",
       "        (attention): MultiheadAttention(\n",
       "          (q_linear): Linear(in_features=50, out_features=50, bias=True)\n",
       "          (v_linear): Linear(in_features=50, out_features=50, bias=True)\n",
       "          (k_linear): Linear(in_features=50, out_features=50, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "          (out): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm1): Normalization()\n",
       "        (ff): FeedForward(\n",
       "          (fc1): Linear(in_features=50, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "          (fc2): Linear(in_features=1024, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm2): Normalization()\n",
       "        (drop1): Dropout(p=0.1)\n",
       "        (drop2): Dropout(p=0.1)\n",
       "      )\n",
       "      (1): EncoderLayer(\n",
       "        (attention): MultiheadAttention(\n",
       "          (q_linear): Linear(in_features=50, out_features=50, bias=True)\n",
       "          (v_linear): Linear(in_features=50, out_features=50, bias=True)\n",
       "          (k_linear): Linear(in_features=50, out_features=50, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "          (out): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm1): Normalization()\n",
       "        (ff): FeedForward(\n",
       "          (fc1): Linear(in_features=50, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "          (fc2): Linear(in_features=1024, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm2): Normalization()\n",
       "        (drop1): Dropout(p=0.1)\n",
       "        (drop2): Dropout(p=0.1)\n",
       "      )\n",
       "      (2): EncoderLayer(\n",
       "        (attention): MultiheadAttention(\n",
       "          (q_linear): Linear(in_features=50, out_features=50, bias=True)\n",
       "          (v_linear): Linear(in_features=50, out_features=50, bias=True)\n",
       "          (k_linear): Linear(in_features=50, out_features=50, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "          (out): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm1): Normalization()\n",
       "        (ff): FeedForward(\n",
       "          (fc1): Linear(in_features=50, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "          (fc2): Linear(in_features=1024, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm2): Normalization()\n",
       "        (drop1): Dropout(p=0.1)\n",
       "        (drop2): Dropout(p=0.1)\n",
       "      )\n",
       "      (3): EncoderLayer(\n",
       "        (attention): MultiheadAttention(\n",
       "          (q_linear): Linear(in_features=50, out_features=50, bias=True)\n",
       "          (v_linear): Linear(in_features=50, out_features=50, bias=True)\n",
       "          (k_linear): Linear(in_features=50, out_features=50, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "          (out): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm1): Normalization()\n",
       "        (ff): FeedForward(\n",
       "          (fc1): Linear(in_features=50, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "          (fc2): Linear(in_features=1024, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm2): Normalization()\n",
       "        (drop1): Dropout(p=0.1)\n",
       "        (drop2): Dropout(p=0.1)\n",
       "      )\n",
       "      (4): EncoderLayer(\n",
       "        (attention): MultiheadAttention(\n",
       "          (q_linear): Linear(in_features=50, out_features=50, bias=True)\n",
       "          (v_linear): Linear(in_features=50, out_features=50, bias=True)\n",
       "          (k_linear): Linear(in_features=50, out_features=50, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "          (out): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm1): Normalization()\n",
       "        (ff): FeedForward(\n",
       "          (fc1): Linear(in_features=50, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "          (fc2): Linear(in_features=1024, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm2): Normalization()\n",
       "        (drop1): Dropout(p=0.1)\n",
       "        (drop2): Dropout(p=0.1)\n",
       "      )\n",
       "      (5): EncoderLayer(\n",
       "        (attention): MultiheadAttention(\n",
       "          (q_linear): Linear(in_features=50, out_features=50, bias=True)\n",
       "          (v_linear): Linear(in_features=50, out_features=50, bias=True)\n",
       "          (k_linear): Linear(in_features=50, out_features=50, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "          (out): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm1): Normalization()\n",
       "        (ff): FeedForward(\n",
       "          (fc1): Linear(in_features=50, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "          (fc2): Linear(in_features=1024, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm2): Normalization()\n",
       "        (drop1): Dropout(p=0.1)\n",
       "        (drop2): Dropout(p=0.1)\n",
       "      )\n",
       "    )\n",
       "    (norm): Normalization()\n",
       "  )\n",
       "  (fc): Linear(in_features=12800, out_features=180, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swap_linear_layer(model, num_coarse_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier(vocab_size, dim_embedding, num_heads,\n",
    "                   ff_num_features, num_encoder_layers, \n",
    "                   max_seq_len, num_fine_classes)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('./checkpoints/transformer-bootstrap2-s256-e50-h5-l6.epoch-9.step-265848.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
