{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import math\n",
    "import time\n",
    "import importlib\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from cis700.dataset import DBPediaDataset, count_lines\n",
    "from cis700 import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordEmbedding(nn.Module):\n",
    "  def __init__(self, vocab_size, dim_embedding):\n",
    "    super(WordEmbedding, self).__init__()\n",
    "    self.embed = nn.Embedding(vocab_size, dim_embedding)\n",
    "  def forward(self, x):\n",
    "    return self.embed(x)\n",
    "  \n",
    "class PositionEncoding(nn.Module):\n",
    "  def __init__(self, dim_embedding, max_seq_len):\n",
    "    super(PositionEncoding, self).__init__()\n",
    "    self.dim_embedding = dim_embedding\n",
    "    \n",
    "    pe = torch.zeros(max_seq_len, dim_embedding)\n",
    "    for pos in range(max_seq_len):\n",
    "      for i in range(0, dim_embedding, 2):\n",
    "        pe[pos, i] = math.sin(pos / (10000 ** ((2 * i) / dim_embedding)))\n",
    "        pe[pos, i+1] = math.cos(pos / (10000 ** ((2 * (i+1)) / dim_embedding)))\n",
    "        \n",
    "    pe = pe.unsqueeze(0)\n",
    "    self.register_buffer('pe', pe)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    x = x * math.sqrt(self.dim_embedding)\n",
    "    x_len = x.size(1)\n",
    "    x = x + Variable(self.pe[:,:x_len], requires_grad=False).cuda()\n",
    "    return x\n",
    "  \n",
    "class MultiheadAttention(nn.Module):\n",
    "  def __init__(self, num_heads, dim_embedding, dropout = 0.1):\n",
    "    super(MultiheadAttention, self).__init__()\n",
    "    \n",
    "    self.dim_embedding = dim_embedding\n",
    "    self.dim_k = dim_embedding / num_heads\n",
    "    if int(self.dim_k) != self.dim_k:\n",
    "      raise ValueError('num_heads should divide dim_embedding evenly! num_heads = %d, dim_embedding = %d' \\\n",
    "                       % (num_heads, dim_embedding))\n",
    "    self.dim_k = int(self.dim_k)\n",
    "    self.num_heads = num_heads\n",
    "    \n",
    "    self.q_linear = nn.Linear(dim_embedding, dim_embedding)\n",
    "    self.v_linear = nn.Linear(dim_embedding, dim_embedding)\n",
    "    self.k_linear = nn.Linear(dim_embedding, dim_embedding)\n",
    "    \n",
    "    self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    self.out = nn.Linear(dim_embedding, dim_embedding)\n",
    "    \n",
    "  def attention(self, q, v, k, mask):\n",
    "    scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.dim_k)\n",
    "    # print('q.size = %s' % str(q.size()))\n",
    "    # print('scores.size = %s' % str(scores.size()))\n",
    "    mask = mask.unsqueeze(1).unsqueeze(1)\n",
    "    scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    \n",
    "    # print(scores.size())\n",
    "    scores = F.softmax(scores, dim=-1)\n",
    "    # print(scores.size())\n",
    "    scores = self.dropout(scores)\n",
    "    \n",
    "    return torch.matmul(scores, v)\n",
    "    \n",
    "  def forward(self, q, v, k, mask):\n",
    "    batch_size = q.size(0)\n",
    "    \n",
    "    q = self.q_linear(q).view(batch_size, -1, self.num_heads, self.dim_k)\n",
    "    v = self.v_linear(v).view(batch_size, -1, self.num_heads, self.dim_k)\n",
    "    k = self.k_linear(k).view(batch_size, -1, self.num_heads, self.dim_k)\n",
    "    \n",
    "    q = q.transpose(1, 2)\n",
    "    v = v.transpose(1, 2)\n",
    "    k = k.transpose(1, 2)\n",
    "    \n",
    "    scores = self.attention(q, v, k, mask)\n",
    "    scores = scores.transpose(1, 2).contiguous().view(batch_size, -1, self.dim_embedding)\n",
    "    return scores\n",
    "  \n",
    "class FeedForward(nn.Module):\n",
    "  def __init__(self, dim_embedding, num_features, dropout = 0.1):\n",
    "    super(FeedForward, self).__init__()\n",
    "    self.fc1 = nn.Linear(dim_embedding, num_features)\n",
    "    self.dropout = nn.Dropout(dropout)\n",
    "    self.fc2 = nn.Linear(num_features, dim_embedding)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    x = self.fc1(x)\n",
    "    x = F.relu(x)\n",
    "    x = self.dropout(x)\n",
    "    return self.fc2(x)\n",
    "  \n",
    "class Normalization(nn.Module):\n",
    "  def __init__(self, dim_embedding, eps = 1e-6):\n",
    "    super(Normalization, self).__init__()\n",
    "    \n",
    "    self.dim_embedding = dim_embedding\n",
    "    self.alpha = nn.Parameter(torch.ones(self.dim_embedding))\n",
    "    self.bias = nn.Parameter(torch.zeros(self.dim_embedding))\n",
    "    self.eps = eps\n",
    "    \n",
    "  def forward(self, x):\n",
    "    norm = self.alpha * (x - x.mean(dim=-1, keepdim=True)) / (x.std(dim=-1, keepdim=True) + self.eps) + self.bias\n",
    "    return norm\n",
    "  \n",
    "class EncoderLayer(nn.Module):\n",
    "  def __init__(self, num_heads, dim_embedding, ff_num_features, dropout=0.1):\n",
    "    super(EncoderLayer, self).__init__()\n",
    "    self.attention = MultiheadAttention(num_heads, dim_embedding)\n",
    "    self.norm1 = Normalization(dim_embedding)\n",
    "    self.ff = FeedForward(dim_embedding, ff_num_features)\n",
    "    self.norm2 = Normalization(dim_embedding)\n",
    "    self.drop1 = nn.Dropout(dropout)\n",
    "    self.drop2 = nn.Dropout(dropout)\n",
    "    \n",
    "  def forward(self, x, mask):\n",
    "    x_ = self.norm1(x)\n",
    "    x = x + self.drop1(self.attention(x_, x_, x_, mask))\n",
    "    x_ = self.norm2(x)\n",
    "    x = x + self.drop2(self.ff(x_))\n",
    "    return x\n",
    "  \n",
    "class Encoder(nn.Module):\n",
    "  def __init__(self, vocab_size, dim_embedding, num_heads, ff_num_features, num_encoder_layers, max_seq_len):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.num_encoder_layers = num_encoder_layers\n",
    "    self.embed = WordEmbedding(vocab_size, dim_embedding)\n",
    "    self.pe = PositionEncoding(dim_embedding, max_seq_len)\n",
    "    self.encoder_layers = \\\n",
    "      nn.ModuleList([EncoderLayer(num_heads, dim_embedding, ff_num_features) for _ in range(num_encoder_layers)])\n",
    "    self.norm = Normalization(dim_embedding)\n",
    "    \n",
    "  def forward(self, x, mask):\n",
    "    x = self.embed(x)\n",
    "    x = self.pe(x)\n",
    "    for i in range(self.num_encoder_layers):\n",
    "      x = self.encoder_layers[i](x, mask)\n",
    "    return self.norm(x)\n",
    "  \n",
    "class Classifier(nn.Module):\n",
    "  def __init__(self, \n",
    "               vocab_size, dim_embedding, num_heads, \n",
    "               ff_num_features, num_encoder_layers, \n",
    "               max_seq_len, num_classes):\n",
    "    super(Classifier, self).__init__()\n",
    "    self.encoder = Encoder(vocab_size, dim_embedding, num_heads, ff_num_features, num_encoder_layers, max_seq_len)\n",
    "    self.fc = nn.Linear(dim_embedding * max_seq_len, num_classes)\n",
    "    \n",
    "  def forward(self, x, mask):\n",
    "    x = self.encoder(x, mask)\n",
    "    return self.fc(x.view(-1, dim_embedding * max_seq_len))\n",
    "  \n",
    "def initialize_model(model):\n",
    "  for p in model.parameters():\n",
    "    if p.dim() > 1:\n",
    "      nn.init.xavier_uniform_(p)\n",
    "      \n",
    "def save_model(model, name, epoch, step):\n",
    "  filename = 'checkpoints/%s.epoch-%d.step-%d.pth' % (name, epoch, step)\n",
    "  torch.save(model.state_dict(), filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurations\n",
    "max_seq_len        = 256\n",
    "dim_embedding      = 200\n",
    "num_heads          = 5\n",
    "num_encoder_layers = 6\n",
    "ff_num_features    = 1024\n",
    "vocab_size         = count_lines('cis700/vocab/bert-base-uncased-vocab.txt')\n",
    "batch_size         = 50\n",
    "\n",
    "network_name = 'transformer-s%d-e%d-h%d-l%d' % (max_seq_len, dim_embedding, num_heads, num_encoder_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1384619/1384619 [00:09<00:00, 141536.96it/s]\n",
      "100%|██████████| 1384619/1384619 [12:32<00:00, 2253.37it/s]\n"
     ]
    }
   ],
   "source": [
    "dbpedia_data = DBPediaDataset('/Users/hengchu/Downloads/cis700data/joinedlonabstract_en.nt', max_seq_len=max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_portion = 0.8\n",
    "validation_portion = 0.1\n",
    "\n",
    "train_size = int(len(dbpedia_data) * train_portion)\n",
    "validation_size = int(len(dbpedia_data) * validation_portion)\n",
    "test_size = len(dbpedia_data) - train_size - validation_size\n",
    "\n",
    "train_set, validation_set, test_set = \\\n",
    "  torch.utils.data.random_split(dbpedia_data, [train_size, validation_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(validation_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather number of categories\n",
    "num_fine_classes = dbpedia_data.num_fine_cats()\n",
    "num_coarse_classes = dbpedia_data.num_coarse_cats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[0] took 4212.653124 seconds\n",
      "train = 0.555556, validation = 0.458223, loss = 1.944845\n",
      "Epoch[1] took 4202.755259 seconds\n",
      "train = 0.600000, validation = 0.459624, loss = 1.872153\n",
      "Epoch[2] took 4239.633796 seconds\n",
      "train = 0.688889, validation = 0.453391, loss = 1.285751\n",
      "Epoch[3] took 4304.622383 seconds\n",
      "train = 0.622222, validation = 0.446739, loss = 1.317384\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0')\n",
    "\"\"\"\n",
    "model = Classifier(vocab_size, dim_embedding, num_heads,\n",
    "                   ff_num_features, num_encoder_layers, \n",
    "                   max_seq_len, num_fine_classes)\n",
    "initialize_model(model)\n",
    "model = model.cuda()\n",
    "optimizer = Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
    "loss_fun = nn.CrossEntropyLoss()\n",
    "tb_writer = SummaryWriter('./logs')\n",
    "epochs = 10\n",
    "\n",
    "step  = 0\n",
    "epoch = 0\n",
    "\"\"\"\n",
    "for i in range(epoch, epochs):\n",
    "  start_time = time.time()\n",
    "  loss_val, validation_score, train_score = None, None, None\n",
    "  for i_batch, batch_data in enumerate(train_loader):\n",
    "    ids = batch_data[0].type(torch.LongTensor)\n",
    "    masks = batch_data[1]\n",
    "    fine_cats = batch_data[2]\n",
    "    loss_val, train_score = utils.transformer_train(model, ids.cuda(), masks.cuda(), fine_cats.cuda(), loss_fun, optimizer)\n",
    "    tb_writer.add_scalar('%s/loss_val' % network_name, loss_val, global_step=step)\n",
    "    tb_writer.add_scalar('%s/train_acc' % network_name, train_score, global_step=step)\n",
    "    step += 1\n",
    "    if step % 5000 == 0:\n",
    "      save_model(model, network_name, epoch, step)\n",
    "  validation_score = utils.transformer_validate(model, validation_loader, device)\n",
    "  tb_writer.add_scalar('%s/validation_acc' % network_name, validation_score, global_step=step)\n",
    "  end_time = time.time()\n",
    "  epoch = i\n",
    "  print('Epoch[%d] took %f seconds' % (epoch, end_time - start_time))\n",
    "  print('train = %f, validation = %f, loss = %f' % (train_score, validation_score, loss_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, network_name, epoch, step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check (please ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6255, -0.4053, -0.3875,  ..., -0.2081, -0.2709, -0.5915],\n",
      "        [ 0.4046, -0.6781, -0.9631,  ..., -0.0211, -0.0456, -0.4453],\n",
      "        [ 0.2149, -0.5845, -0.5949,  ...,  0.0097, -0.9538, -0.2194],\n",
      "        ...,\n",
      "        [ 0.4937, -0.8904, -0.3721,  ..., -0.3162, -0.0797, -0.4613],\n",
      "        [ 0.3535, -0.2306,  0.0034,  ...,  1.3421, -0.1081,  0.0705],\n",
      "        [ 0.7894, -1.1255, -0.3667,  ..., -0.2754,  0.3495,  0.2130]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "torch.Size([50, 370])\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  if model:\n",
    "    del model\n",
    "except:\n",
    "  pass\n",
    "\n",
    "model = Classifier(vocab_size, dim_embedding, num_heads, ff_num_features, num_encoder_layers, max_seq_len, num_fine_classes)\n",
    "model = model.cuda()\n",
    "_, first_batch = next(enumerate(train_loader))\n",
    "ids = first_batch[0].type(torch.LongTensor).cuda()\n",
    "masks = first_batch[1].cuda()\n",
    "r = model(ids, masks)\n",
    "print(r)\n",
    "print(r.size())\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scratch cells (please ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'cis700.utils' from '/Users/hengchu/Documents/fun/cis700project/cis700/utils.py'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, network_name, epoch, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-f8e6db53808d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/fun/cis700project/cis700/utils.py\u001b[0m in \u001b[0;36mtransformer_validate\u001b[0;34m(model, dataloader, device)\u001b[0m\n\u001b[1;32m    119\u001b[0m       \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m       \u001b[0mnum_correct\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m       \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "utils.transformer_validate(model, validation_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.0368, device='cuda:0', grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4496, device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
