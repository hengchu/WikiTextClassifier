{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import torch.cuda as cutorch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "from cis700.dataset import DBPediaDataset, count_lines\n",
    "from cis700 import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurations\n",
    "max_seq_len        = 256\n",
    "dim_embedding      = 100\n",
    "num_heads          = 5\n",
    "num_encoder_layers = 3\n",
    "ff_num_features    = 1024\n",
    "vocab_size         = count_lines('cis700/vocab/bert-base-uncased-vocab.txt')\n",
    "batch_size         = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1384619/1384619 [00:10<00:00, 138103.30it/s]\n",
      "100%|██████████| 1384619/1384619 [12:34<00:00, 1836.03it/s]\n"
     ]
    }
   ],
   "source": [
    "dbpedia_data = DBPediaDataset('/Users/hengchu/Downloads/cis700data/joinedlonabstract_en.nt', max_seq_len=max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_portion = 0.8\n",
    "validation_portion = 0.1\n",
    "\n",
    "train_size = int(len(dbpedia_data) * train_portion)\n",
    "validation_size = int(len(dbpedia_data) * validation_portion)\n",
    "test_size = len(dbpedia_data) - train_size - validation_size\n",
    "\n",
    "train_set, validation_set, test_set = \\\n",
    "  torch.utils.data.random_split(dbpedia_data, [train_size, validation_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(validation_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather number of categories\n",
    "num_fine_classes = dbpedia_data.num_fine_cats()\n",
    "num_coarse_classes = dbpedia_data.num_coarse_cats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1996.,  2685.,  1997.,  2422.,  3192.,  1004., 23713.,  1025.,  6951.,\n",
       "          2415.,  2120.,  2897.,  2001.,  1037.,  2120., 14495.,  1010.,  2512.,\n",
       "         26053.,  3029.,  4056.,  2000., 11973.,  2062.,  2111.,  1998.,  4219.,\n",
       "          1999., 13729.,  3809.,  2591.,  3471.,  1012.,  1999.,  2257.,  2289.,\n",
       "          1996.,  3029.,  5314.,  2007.,  1996.,  5865.,  1011.,  2241.,  2398.,\n",
       "          2006.,  2897.,  1012.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "             0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "             0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "             0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "             0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "             0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "             0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "             0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "             0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "             0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "             0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "             0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "             0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "             0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "             0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "             0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "             0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "             0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "             0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "             0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "             0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "             0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "             0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "             0.,     0.,     0.,     0.]),\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.]),\n",
       " 195,\n",
       " 87)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<http://dbpedia.org/resource/Category:Landforms>'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbpedia_data.fine_id2cat(169)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordEmbedding(nn.Module):\n",
    "  def __init__(self, vocab_size, dim_embedding):\n",
    "    super(WordEmbedding, self).__init__()\n",
    "    self.embed = nn.Embedding(vocab_size, dim_embedding)\n",
    "  def forward(self, x):\n",
    "    return self.embed(x)\n",
    "  \n",
    "class PositionEncoding(nn.Module):\n",
    "  def __init__(self, dim_embedding, max_seq_len):\n",
    "    super(PositionEncoding, self).__init__()\n",
    "    self.dim_embedding = dim_embedding\n",
    "    \n",
    "    pe = torch.zeros(max_seq_len, dim_embedding)\n",
    "    for pos in range(max_seq_len):\n",
    "      for i in range(0, dim_embedding, 2):\n",
    "        pe[pos, i] = math.sin(pos / (10000 ** ((2 * i) / dim_embedding)))\n",
    "        pe[pos, i+1] = math.cos(pos / (10000 ** ((2 * (i+1)) / dim_embedding)))\n",
    "        \n",
    "    pe = pe.unsqueeze(0)\n",
    "    self.register_buffer('pe', pe)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    x = x * math.sqrt(self.dim_embedding)\n",
    "    x_len = x.size(1)\n",
    "    x = x + Variable(self.pe[:,:x_len], requires_grad=False).cuda()\n",
    "    return x\n",
    "  \n",
    "class MultiheadAttention(nn.Module):\n",
    "  def __init__(self, num_heads, dim_embedding, dropout = 0.1):\n",
    "    super(MultiheadAttention, self).__init__()\n",
    "    \n",
    "    self.dim_embedding = dim_embedding\n",
    "    self.dim_k = dim_embedding / num_heads\n",
    "    if int(self.dim_k) != self.dim_k:\n",
    "      raise ValueError('num_heads should divide dim_embedding evenly! num_heads = %d, dim_embedding = %d' \\\n",
    "                       % (num_heads, dim_embedding))\n",
    "    self.dim_k = int(self.dim_k)\n",
    "    self.num_heads = num_heads\n",
    "    \n",
    "    self.q_linear = nn.Linear(dim_embedding, dim_embedding)\n",
    "    self.v_linear = nn.Linear(dim_embedding, dim_embedding)\n",
    "    self.k_linear = nn.Linear(dim_embedding, dim_embedding)\n",
    "    \n",
    "    self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    self.out = nn.Linear(dim_embedding, dim_embedding)\n",
    "    \n",
    "  def attention(self, q, v, k, mask):\n",
    "    scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.dim_k)\n",
    "    # print('q.size = %s' % str(q.size()))\n",
    "    # print('scores.size = %s' % str(scores.size()))\n",
    "    mask = mask.unsqueeze(1).unsqueeze(1)\n",
    "    scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    \n",
    "    # print(scores.size())\n",
    "    scores = F.softmax(scores, dim=-1)\n",
    "    # print(scores.size())\n",
    "    scores = self.dropout(scores)\n",
    "    \n",
    "    return torch.matmul(scores, v)\n",
    "    \n",
    "  def forward(self, q, v, k, mask):\n",
    "    batch_size = q.size(0)\n",
    "    \n",
    "    q = self.q_linear(q).view(batch_size, -1, self.num_heads, self.dim_k)\n",
    "    v = self.v_linear(v).view(batch_size, -1, self.num_heads, self.dim_k)\n",
    "    k = self.k_linear(k).view(batch_size, -1, self.num_heads, self.dim_k)\n",
    "    \n",
    "    q = q.transpose(1, 2)\n",
    "    v = v.transpose(1, 2)\n",
    "    k = k.transpose(1, 2)\n",
    "    \n",
    "    scores = self.attention(q, v, k, mask)\n",
    "    scores = scores.transpose(1, 2).contiguous().view(batch_size, -1, self.dim_embedding)\n",
    "    return scores\n",
    "  \n",
    "class FeedForward(nn.Module):\n",
    "  def __init__(self, dim_embedding, num_features, dropout = 0.1):\n",
    "    super(FeedForward, self).__init__()\n",
    "    self.fc1 = nn.Linear(dim_embedding, num_features)\n",
    "    self.dropout = nn.Dropout(dropout)\n",
    "    self.fc2 = nn.Linear(num_features, dim_embedding)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    x = self.fc1(x)\n",
    "    x = F.relu(x)\n",
    "    x = self.dropout(x)\n",
    "    return self.fc2(x)\n",
    "  \n",
    "class Normalization(nn.Module):\n",
    "  def __init__(self, dim_embedding, eps = 1e-6):\n",
    "    super(Normalization, self).__init__()\n",
    "    \n",
    "    self.dim_embedding = dim_embedding\n",
    "    self.alpha = nn.Parameter(torch.ones(self.dim_embedding))\n",
    "    self.bias = nn.Parameter(torch.zeros(self.dim_embedding))\n",
    "    self.eps = eps\n",
    "    \n",
    "  def forward(self, x):\n",
    "    norm = self.alpha * (x - x.mean(dim=-1, keepdim=True)) / (x.std(dim=-1, keepdim=True) + self.eps) + self.bias\n",
    "    return norm\n",
    "  \n",
    "class EncoderLayer(nn.Module):\n",
    "  def __init__(self, num_heads, dim_embedding, ff_num_features, dropout=0.1):\n",
    "    super(EncoderLayer, self).__init__()\n",
    "    self.attention = MultiheadAttention(num_heads, dim_embedding)\n",
    "    self.norm1 = Normalization(dim_embedding)\n",
    "    self.ff = FeedForward(dim_embedding, ff_num_features)\n",
    "    self.norm2 = Normalization(dim_embedding)\n",
    "    self.drop1 = nn.Dropout(dropout)\n",
    "    self.drop2 = nn.Dropout(dropout)\n",
    "    \n",
    "  def forward(self, x, mask):\n",
    "    x_ = self.norm1(x)\n",
    "    x = x + self.drop1(self.attention(x_, x_, x_, mask))\n",
    "    x_ = self.norm2(x)\n",
    "    x = x + self.drop2(self.ff(x_))\n",
    "    return x\n",
    "  \n",
    "class Encoder(nn.Module):\n",
    "  def __init__(self, vocab_size, dim_embedding, num_heads, ff_num_features, num_encoder_layers, max_seq_len):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.num_encoder_layers = num_encoder_layers\n",
    "    self.embed = WordEmbedding(vocab_size, dim_embedding)\n",
    "    self.pe = PositionEncoding(dim_embedding, max_seq_len)\n",
    "    self.encoder_layers = \\\n",
    "      nn.ModuleList([EncoderLayer(num_heads, dim_embedding, ff_num_features) for _ in range(num_encoder_layers)])\n",
    "    self.norm = Normalization(dim_embedding)\n",
    "    \n",
    "  def forward(self, x, mask):\n",
    "    x = self.embed(x)\n",
    "    x = self.pe(x)\n",
    "    for i in range(self.num_encoder_layers):\n",
    "      x = self.encoder_layers[i](x, mask)\n",
    "    return self.norm(x)\n",
    "  \n",
    "class Classifier(nn.Module):\n",
    "  def __init__(self, \n",
    "               vocab_size, dim_embedding, num_heads, \n",
    "               ff_num_features, num_encoder_layers, \n",
    "               max_seq_len, num_classes):\n",
    "    super(Classifier, self).__init__()\n",
    "    self.encoder = Encoder(vocab_size, dim_embedding, num_heads, ff_num_features, num_encoder_layers, max_seq_len)\n",
    "    self.fc = nn.Linear(dim_embedding * max_seq_len, num_classes)\n",
    "    \n",
    "  def forward(self, x, mask):\n",
    "    x = self.encoder(x, mask)\n",
    "    return self.fc(x.view(-1, dim_embedding * max_seq_len))\n",
    "  \n",
    "def initialize_model(model):\n",
    "  for p in model.parameters():\n",
    "    if p.dim() > 1:\n",
    "      nn.init.xavier_uniform_(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2389, -0.8082, -0.6686,  ...,  0.0877, -0.9130, -0.1621],\n",
      "        [-0.9009, -0.3074, -0.7217,  ..., -0.5653, -0.6046, -0.2575],\n",
      "        [-0.1366, -1.0973, -0.6884,  ...,  0.2743, -0.8374, -0.4158],\n",
      "        ...,\n",
      "        [ 1.1220, -0.0443, -0.3266,  ..., -0.0916,  0.4683,  0.6282],\n",
      "        [-0.2145, -0.0739,  0.5986,  ...,  1.1633,  0.2323,  0.1978],\n",
      "        [-0.2769, -1.2083, -0.7115,  ...,  0.3181, -0.6569,  0.3033]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "if model:\n",
    "  del model\n",
    "model = Classifier(vocab_size, dim_embedding, num_heads, ff_num_features, num_encoder_layers, max_seq_len, num_fine_classes)\n",
    "model = model.cuda()\n",
    "_, first_batch = next(enumerate(train_loader))\n",
    "ids = first_batch[0].type(torch.LongTensor).cuda()\n",
    "masks = first_batch[1].cuda()\n",
    "r = model(ids, masks)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 370])\n"
     ]
    }
   ],
   "source": [
    "print(r.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
