{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer_transferlearning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "hkO17YtDCfLl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 837
        },
        "outputId": "cc43f2db-7323-428b-abe3-3a5fba020e3a"
      },
      "cell_type": "code",
      "source": [
        "#Get dataset files, load dependencies, setup tensorboard, define helper functions\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "  \n",
        "\n",
        "!pip3 install tensorboardX\n",
        "!git clone https://github.com/huggingface/pytorch-pretrained-BERT/\n",
        "  \n",
        "\n",
        "import sys\n",
        "sys.path.insert(0, './cis700project')\n",
        "sys.path.insert(0, './pytorch-pretrained-BERT')\n",
        "import torch\n",
        "import math\n",
        "import subprocess\n",
        "import re\n",
        "import linecache\n",
        "import torch.utils.data as data\n",
        "import time\n",
        "import importlib\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from torch.autograd import Variable\n",
        "from torch.optim import Adam\n",
        "from tensorboardX import SummaryWriter\n",
        "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
        "from multiprocessing import Pool\n",
        "from cis700 import utils\n",
        "\n",
        "def build_tokenizer():\n",
        "    tokenizer = BertTokenizer('./cis700project/cis700/vocab/bert-base-uncased-vocab.txt')\n",
        "    return tokenizer\n",
        "\n",
        "def category_text_to_id(cat_map, cat_text, count):\n",
        "  if cat_text in cat_map:\n",
        "    return cat_map[cat_text], count\n",
        "  else:\n",
        "    cat_map[cat_text] = count\n",
        "    return cat_map[cat_text], count+1\n",
        "\n",
        "def count_lines(filepath):\n",
        "  r = subprocess.Popen(['wc', '-l', filepath], stdout=subprocess.PIPE)\n",
        "  r = r.communicate()\n",
        "  output = r[0].decode('utf-8')\n",
        "  output = output.strip(' ').split(' ')[0]\n",
        "  return int(output)\n",
        "\n",
        "# this needs to be global for multiprocessing purpose\n",
        "_tokenizer   = None\n",
        "_max_seq_len = None\n",
        "\n",
        "class Feature:\n",
        "  def __init__(self, text, ids, masks, fine_cat, coarse_cat, fine_cat_text, coarse_cat_text):\n",
        "    self.text = text\n",
        "    self.ids = ids\n",
        "    self.masks = masks\n",
        "    self.fine_cat = fine_cat\n",
        "    self.coarse_cat = coarse_cat\n",
        "    self.fine_cat_text = fine_cat_text\n",
        "    self.coarse_cat_text = coarse_cat_text\n",
        "\n",
        "  def __repr__(self):\n",
        "    return self.__dict__.__repr__()\n",
        "\n",
        "def _truncate(ids):\n",
        "  if len(ids) > _max_seq_len:\n",
        "    return ids[0:_max_seq_len]\n",
        "  return ids\n",
        "\n",
        "def _process(datum):\n",
        "  tokens = _tokenizer.tokenize(datum[0])\n",
        "  ids = _tokenizer.convert_tokens_to_ids(tokens)\n",
        "  ids = _truncate(ids)\n",
        "  masks = [1] * len(ids)\n",
        "  while len(ids) < _max_seq_len:\n",
        "    ids.append(0)\n",
        "    masks.append(0)\n",
        "  return Feature(datum[0], ids, masks, datum[1], datum[2], datum[3], datum[4])\n",
        "\n",
        "def convert_to_features(data_list, max_seq_len):\n",
        "  global _tokenizer\n",
        "  global _max_seq_len\n",
        "\n",
        "  _tokenizer = build_tokenizer()\n",
        "  _max_seq_len = max_seq_len\n",
        "\n",
        "  with Pool(processes=6) as pool:\n",
        "    return list(pool.imap(_process, tqdm(data_list)))\n",
        "\n",
        "  _tokenizer = None\n",
        "  _max_seq_len = None\n",
        "  \n",
        "class DBPediaDataset(Dataset):\n",
        "  def __init__(self, filepath, max_seq_len):\n",
        "    self.fine_cat_map = {}\n",
        "    fine_cat_count = 0\n",
        "    self.coarse_cat_map = {}\n",
        "    coarse_cat_count = 0\n",
        "    self.data = []\n",
        "\n",
        "    text_re = r'(\".+\"@en)'\n",
        "    cat_re = r'\\. (<[^<>]+>) (<[^<>]+>)$'\n",
        "    tok = build_tokenizer()\n",
        "\n",
        "    with open(filepath, 'r') as f:\n",
        "      for line in tqdm(f, total=count_lines(filepath)):\n",
        "        text_match = re.search(text_re, line)\n",
        "        text = text_match.group(1).strip('\"@en')\n",
        "        cat_match = re.search(cat_re, line)\n",
        "        fine_cat = cat_match.group(1)\n",
        "        coarse_cat = cat_match.group(2)\n",
        "        fine_cat_id, fine_cat_count = category_text_to_id(self.fine_cat_map, fine_cat, fine_cat_count)\n",
        "        coarse_cat_id, coarse_cat_count = category_text_to_id(self.coarse_cat_map, coarse_cat, coarse_cat_count)\n",
        "        self.data.append((text, fine_cat_id, coarse_cat_id, fine_cat, coarse_cat))\n",
        "\n",
        "    self.reverse_fine_cat_map = {}\n",
        "    self.reverse_coarse_cat_map = {}\n",
        "    for k in self.fine_cat_map:\n",
        "      v = self.fine_cat_map[k]\n",
        "      assert v not in self.reverse_fine_cat_map\n",
        "      self.reverse_fine_cat_map[v] = k\n",
        "    for k in self.coarse_cat_map:\n",
        "      v = self.coarse_cat_map[k]\n",
        "      assert v not in self.reverse_coarse_cat_map\n",
        "      self.reverse_coarse_cat_map[v] = k\n",
        "\n",
        "    self.data = convert_to_features(self.data, max_seq_len)\n",
        "\n",
        "  def fine_id2cat(self, id):\n",
        "    return self.reverse_fine_cat_map[id]\n",
        "\n",
        "  def coarse_id2cat(self, id):\n",
        "    return self.reverse_coarse_cat_map[id]\n",
        "\n",
        "  def num_fine_cats(self):\n",
        "    return len(self.reverse_fine_cat_map)\n",
        "\n",
        "  def num_coarse_cats(self):\n",
        "    return len(self.reverse_coarse_cat_map)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def get_feature(self, idx):\n",
        "    return self.data[idx]\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    dt = self.data[idx]\n",
        "    return torch.Tensor(dt.ids), torch.Tensor(dt.masks), dt.fine_cat, dt.coarse_cat, idx\n",
        "  \n",
        "LOG_DIR = './logs'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "\n",
        "!if [ -f ngrok ] ; then echo \"Ngrok already installed\" ; else wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip > /dev/null 2>&1 && unzip ngrok-stable-linux-amd64.zip > /dev/null 2>&1 ; fi\n",
        "  \n",
        "  # Code referenced from https://gist.github.com/gyglim/1f8dfb1b5c82627ae3efcfbbadb9f514\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import scipy.misc \n",
        "try:\n",
        "    from StringIO import StringIO  # Python 2.7\n",
        "except ImportError:\n",
        "    from io import BytesIO         # Python 3.x\n",
        "\n",
        "\n",
        "class Logger(object):\n",
        "    \n",
        "    def __init__(self, log_dir):\n",
        "        \"\"\"Create a summary writer logging to log_dir.\"\"\"\n",
        "        self.writer = tf.summary.FileWriter(log_dir)\n",
        "\n",
        "    def scalar_summary(self, tag, value, step):\n",
        "        \"\"\"Log a scalar variable.\"\"\"\n",
        "        summary = tf.Summary(value=[tf.Summary.Value(tag=tag, simple_value=value)])\n",
        "        self.writer.add_summary(summary, step)\n",
        "\n",
        "    def image_summary(self, tag, images, step):\n",
        "        \"\"\"Log a list of images.\"\"\"\n",
        "\n",
        "        img_summaries = []\n",
        "        for i, img in enumerate(images):\n",
        "            # Write the image to a string\n",
        "            try:\n",
        "                s = StringIO()\n",
        "            except:\n",
        "                s = BytesIO()\n",
        "            scipy.misc.toimage(img).save(s, format=\"png\")\n",
        "\n",
        "            # Create an Image object\n",
        "            img_sum = tf.Summary.Image(encoded_image_string=s.getvalue(),\n",
        "                                       height=img.shape[0],\n",
        "                                       width=img.shape[1])\n",
        "            # Create a Summary value\n",
        "            img_summaries.append(tf.Summary.Value(tag='%s/%d' % (tag, i), image=img_sum))\n",
        "\n",
        "        # Create and write Summary\n",
        "        summary = tf.Summary(value=img_summaries)\n",
        "        self.writer.add_summary(summary, step)\n",
        "        \n",
        "    def histo_summary(self, tag, values, step, bins=1000):\n",
        "        \"\"\"Log a histogram of the tensor of values.\"\"\"\n",
        "\n",
        "        # Create a histogram using numpy\n",
        "        counts, bin_edges = np.histogram(values, bins=bins)\n",
        "\n",
        "        # Fill the fields of the histogram proto\n",
        "        hist = tf.HistogramProto()\n",
        "        hist.min = float(np.min(values))\n",
        "        hist.max = float(np.max(values))\n",
        "        hist.num = int(np.prod(values.shape))\n",
        "        hist.sum = float(np.sum(values))\n",
        "        hist.sum_squares = float(np.sum(values**2))\n",
        "\n",
        "        # Drop the start of the first bin\n",
        "        bin_edges = bin_edges[1:]\n",
        "\n",
        "        # Add bin edges and counts\n",
        "        for edge in bin_edges:\n",
        "            hist.bucket_limit.append(edge)\n",
        "        for c in counts:\n",
        "            hist.bucket.append(c)\n",
        "\n",
        "        # Create and write Summary\n",
        "        summary = tf.Summary(value=[tf.Summary.Value(tag=tag, histo=hist)])\n",
        "        self.writer.add_summary(summary, step)\n",
        "        self.writer.flush()\n",
        "\n",
        "## Required packages\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "!pip3 install https://download.pytorch.org/whl/cu100/torch-1.0.1-cp36-cp36m-linux_x86_64.whl\n",
        "!pip3 install torchvision\n",
        "  \n",
        "import torch\n",
        "device =  torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/76/89dd44458eb976347e5a6e75eb79fecf8facd46c1ce259bad54e0044ea35/tensorboardX-1.6-py2.py3-none-any.whl (129kB)\n",
            "\u001b[K    100% |████████████████████████████████| 133kB 3.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.16.3)\n",
            "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.7.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.2.0->tensorboardX) (40.9.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-1.6\n",
            "Cloning into 'cis700project'...\n",
            "remote: Enumerating objects: 68, done.\u001b[K\n",
            "remote: Counting objects: 100% (68/68), done.\u001b[K\n",
            "remote: Compressing objects: 100% (40/40), done.\u001b[K\n",
            "remote: Total 68 (delta 33), reused 53 (delta 22), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (68/68), done.\n",
            "Cloning into 'pytorch-pretrained-BERT'...\n",
            "remote: Enumerating objects: 50, done.\u001b[K\n",
            "remote: Counting objects: 100% (50/50), done.\u001b[K\n",
            "remote: Compressing objects: 100% (43/43), done.\u001b[K\n",
            "remote: Total 3173 (delta 19), reused 25 (delta 6), pack-reused 3123\u001b[K\n",
            "Receiving objects: 100% (3173/3173), 1.54 MiB | 25.08 MiB/s, done.\n",
            "Resolving deltas: 100% (2167/2167), done.\n",
            "Collecting torch==1.0.1 from https://download.pytorch.org/whl/cu100/torch-1.0.1-cp36-cp36m-linux_x86_64.whl\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu100/torch-1.0.1-cp36-cp36m-linux_x86_64.whl (614.8MB)\n",
            "\u001b[K    100% |████████████████████████████████| 614.8MB 20kB/s \n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "  Found existing installation: torch 1.0.1.post2\n",
            "    Uninstalling torch-1.0.1.post2:\n",
            "      Successfully uninstalled torch-1.0.1.post2\n",
            "Successfully installed torch-1.0.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.2.post3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.16.3)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n",
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_25O-L-3Jscz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7b416df3-3095-4868-9b65-88ac82635971"
      },
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print('Tensorboard Link: ' +str(json.load(sys.stdin)['tunnels'][0]['public_url']))\""
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorboard Link: https://93e95796.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "r42TEk0uCfLu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Network Architecture"
      ]
    },
    {
      "metadata": {
        "id": "1CxWm-wtCfLw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "class WordEmbedding(nn.Module):\n",
        "  def __init__(self, vocab_size, dim_embedding):\n",
        "    super(WordEmbedding, self).__init__()\n",
        "    self.embed = nn.Embedding(vocab_size, dim_embedding)\n",
        "  def forward(self, x):\n",
        "    return self.embed(x)\n",
        "  \n",
        "class PositionEncoding(nn.Module):\n",
        "  def __init__(self, dim_embedding, max_seq_len):\n",
        "    super(PositionEncoding, self).__init__()\n",
        "    self.dim_embedding = dim_embedding\n",
        "    \n",
        "    pe = torch.zeros(max_seq_len, dim_embedding)\n",
        "    for pos in range(max_seq_len):\n",
        "      for i in range(0, dim_embedding, 2):\n",
        "        pe[pos, i] = math.sin(pos / (10000 ** ((2 * i) / dim_embedding)))\n",
        "        pe[pos, i+1] = math.cos(pos / (10000 ** ((2 * (i+1)) / dim_embedding)))\n",
        "        \n",
        "    pe = pe.unsqueeze(0)\n",
        "    self.register_buffer('pe', pe)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = x * math.sqrt(self.dim_embedding)\n",
        "    x_len = x.size(1)\n",
        "    x = x + Variable(self.pe[:,:x_len], requires_grad=False).cuda()\n",
        "    return x\n",
        "  \n",
        "class MultiheadAttention(nn.Module):\n",
        "  def __init__(self, num_heads, dim_embedding, dropout = 0.1):\n",
        "    super(MultiheadAttention, self).__init__()\n",
        "    \n",
        "    self.dim_embedding = dim_embedding\n",
        "    self.dim_k = dim_embedding / num_heads\n",
        "    if int(self.dim_k) != self.dim_k:\n",
        "      raise ValueError('num_heads should divide dim_embedding evenly! num_heads = %d, dim_embedding = %d' \\\n",
        "                       % (num_heads, dim_embedding))\n",
        "    self.dim_k = int(self.dim_k)\n",
        "    self.num_heads = num_heads\n",
        "    \n",
        "    self.q_linear = nn.Linear(dim_embedding, dim_embedding)\n",
        "    self.v_linear = nn.Linear(dim_embedding, dim_embedding)\n",
        "    self.k_linear = nn.Linear(dim_embedding, dim_embedding)\n",
        "    \n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    \n",
        "    self.out = nn.Linear(dim_embedding, dim_embedding)\n",
        "    \n",
        "  def attention(self, q, v, k, mask):\n",
        "    scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.dim_k)\n",
        "    # print('q.size = %s' % str(q.size()))\n",
        "    # print('scores.size = %s' % str(scores.size()))\n",
        "    mask = mask.unsqueeze(1).unsqueeze(1)\n",
        "    scores = scores.masked_fill(mask == 0, -1e9)\n",
        "    \n",
        "    # print(scores.size())\n",
        "    scores = F.softmax(scores, dim=-1)\n",
        "    # print(scores.size())\n",
        "    scores = self.dropout(scores)\n",
        "    \n",
        "    return torch.matmul(scores, v)\n",
        "    \n",
        "  def forward(self, q, v, k, mask):\n",
        "    batch_size = q.size(0)\n",
        "    \n",
        "    q = self.q_linear(q).view(batch_size, -1, self.num_heads, self.dim_k)\n",
        "    v = self.v_linear(v).view(batch_size, -1, self.num_heads, self.dim_k)\n",
        "    k = self.k_linear(k).view(batch_size, -1, self.num_heads, self.dim_k)\n",
        "    \n",
        "    q = q.transpose(1, 2)\n",
        "    v = v.transpose(1, 2)\n",
        "    k = k.transpose(1, 2)\n",
        "    \n",
        "    scores = self.attention(q, v, k, mask)\n",
        "    scores = scores.transpose(1, 2).contiguous().view(batch_size, -1, self.dim_embedding)\n",
        "    return scores\n",
        "  \n",
        "class FeedForward(nn.Module):\n",
        "  def __init__(self, dim_embedding, num_features, dropout = 0.1):\n",
        "    super(FeedForward, self).__init__()\n",
        "    self.fc1 = nn.Linear(dim_embedding, num_features)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.fc2 = nn.Linear(num_features, dim_embedding)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = self.fc1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.dropout(x)\n",
        "    return self.fc2(x)\n",
        "  \n",
        "class Normalization(nn.Module):\n",
        "  def __init__(self, dim_embedding, eps = 1e-6):\n",
        "    super(Normalization, self).__init__()\n",
        "    \n",
        "    self.dim_embedding = dim_embedding\n",
        "    self.alpha = nn.Parameter(torch.ones(self.dim_embedding))\n",
        "    self.bias = nn.Parameter(torch.zeros(self.dim_embedding))\n",
        "    self.eps = eps\n",
        "    \n",
        "  def forward(self, x):\n",
        "    norm = self.alpha * (x - x.mean(dim=-1, keepdim=True)) / (x.std(dim=-1, keepdim=True) + self.eps) + self.bias\n",
        "    return norm\n",
        "  \n",
        "class EncoderLayer(nn.Module):\n",
        "  def __init__(self, num_heads, dim_embedding, ff_num_features, dropout=0.1):\n",
        "    super(EncoderLayer, self).__init__()\n",
        "    self.attention = MultiheadAttention(num_heads, dim_embedding)\n",
        "    self.norm1 = Normalization(dim_embedding)\n",
        "    self.ff = FeedForward(dim_embedding, ff_num_features)\n",
        "    self.norm2 = Normalization(dim_embedding)\n",
        "    self.drop1 = nn.Dropout(dropout)\n",
        "    self.drop2 = nn.Dropout(dropout)\n",
        "    \n",
        "  def forward(self, x, mask):\n",
        "    x_ = self.norm1(x)\n",
        "    x = x + self.drop1(self.attention(x_, x_, x_, mask))\n",
        "    x_ = self.norm2(x)\n",
        "    x = x + self.drop2(self.ff(x_))\n",
        "    return x\n",
        "  \n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, vocab_size, dim_embedding, num_heads, ff_num_features, num_encoder_layers, max_seq_len):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.num_encoder_layers = num_encoder_layers\n",
        "    self.embed = WordEmbedding(vocab_size, dim_embedding)\n",
        "    self.pe = PositionEncoding(dim_embedding, max_seq_len)\n",
        "    self.encoder_layers = \\\n",
        "      nn.ModuleList([EncoderLayer(num_heads, dim_embedding, ff_num_features) for _ in range(num_encoder_layers)])\n",
        "    self.norm = Normalization(dim_embedding)\n",
        "    \n",
        "  def forward(self, x, mask):\n",
        "    x = self.embed(x)\n",
        "    x = self.pe(x)\n",
        "    for i in range(self.num_encoder_layers):\n",
        "      x = self.encoder_layers[i](x, mask)\n",
        "    return self.norm(x)\n",
        "  \n",
        "class Classifier(nn.Module):\n",
        "  def __init__(self, \n",
        "               vocab_size, dim_embedding, num_heads, \n",
        "               ff_num_features, num_encoder_layers, \n",
        "               max_seq_len, num_classes):\n",
        "    super(Classifier, self).__init__()\n",
        "    self.dim_embedding = dim_embedding\n",
        "    self.max_seq_len = max_seq_len\n",
        "    self.encoder = Encoder(vocab_size, dim_embedding, num_heads, ff_num_features, num_encoder_layers, max_seq_len)\n",
        "    self.fc = nn.Linear(dim_embedding * max_seq_len, num_classes)\n",
        "    \n",
        "  def forward(self, x, mask):\n",
        "    x = self.encoder(x, mask)\n",
        "    return self.fc(x.view(-1, self.dim_embedding * self.max_seq_len))\n",
        "  \n",
        "def initialize_model(model):\n",
        "  for p in model.parameters():\n",
        "    if p.dim() > 1:\n",
        "      nn.init.xavier_uniform_(p)\n",
        "      \n",
        "def save_model(model, name, epoch, step):\n",
        "  if not os.path.isdir(\"./checkpoints\"):\n",
        "    os.mkdir(\"./checkpoints\")\n",
        "  filename = './checkpoints/%s.epoch-%d.step-%d.pth' % (name, epoch, step)\n",
        "  torch.save(model.state_dict(), filename)\n",
        "  return filename\n",
        "\n",
        "def human_readable_prediction(text, model, max_seq_len, cat_id2text_fun):\n",
        "  tok = build_tokenizer()\n",
        "  tokens = tok.tokenize(text)\n",
        "  ids = tok.convert_tokens_to_ids(tokens)\n",
        "  if len(ids) > max_seq_len:\n",
        "    ids = ids[0:max_seq_len]\n",
        "  masks = [1] * len(ids)\n",
        "  ids += [0] * (max_seq_len - len(ids))\n",
        "  masks += [0] * (max_seq_len - len(masks))\n",
        "  \n",
        "  model.eval()\n",
        "  ids = torch.Tensor(ids).type(torch.LongTensor).cuda().unsqueeze(0)\n",
        "  masks = torch.Tensor(masks).cuda().unsqueeze(0)\n",
        "  scores = model(ids, masks).squeeze()\n",
        "  top_k = 5\n",
        "  _, max_cat_ids = torch.topk(scores, k = top_k, dim = 0)\n",
        "  top_cats = [cat_id2text_fun(int(max_cat_ids[i])) for i in range(top_k)]\n",
        "  return top_cats\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ePAGpjjRCfL1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Dataset/Loader"
      ]
    },
    {
      "metadata": {
        "id": "qFNyqB2GCfL8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f796a971-8341-4b48-b733-66ab53e3fcf7"
      },
      "cell_type": "code",
      "source": [
        "subcategory_size = 0\n",
        "subcategory2id = {}\n",
        "with open('/content/drive/My Drive/supercatstats.csv', 'r') as f:\n",
        "  # build stats\n",
        "  for index,line in enumerate(f):\n",
        "    subcategory2id[line.split(',')[0]]=subcategory_size\n",
        "    subcategory_size += 1\n",
        "    \n",
        "print(subcategory_size)\n",
        "\n",
        "category_size = 0\n",
        "category2id = {}\n",
        "with open('/content/drive/My Drive/catstats.csv', 'r') as f:\n",
        "  # build stats\n",
        "  for index,line in enumerate(f):\n",
        "    category2id[line.split(',')[0]]=category_size\n",
        "    category_size += 1\n",
        "    \n",
        "print(category_size)\n",
        "\n",
        "tok = build_tokenizer()\n",
        "\n",
        "class AbstractDataset(data.Dataset):\n",
        "  \"\"\"Abstract dataset.\"\"\"\n",
        "\n",
        "  def __init__(self, file = \"joinedlonabstract_en.nt\", root_dir = \"/content/drive/My Drive\"):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      csv_file (string): Path to the nt file.\n",
        "      root_dir (string): Directory with all the images.\n",
        "    \"\"\"\n",
        "    temp = linecache.getline(root_dir + '/' + file, 1)\n",
        "    self.fullfile = open(root_dir + '/' + file).readlines()\n",
        "    self.fullfile_len = len(self.fullfile)\n",
        "    self.root_dir = root_dir\n",
        "    self.category2id = category2id\n",
        "    self.subcategory2id = subcategory2id\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.fullfile_len\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    #line = linecache.getline(self.root_dir + '/' + self.file, index + 1)\n",
        "    line = self.fullfile[index]\n",
        "    match = re.findall(r'(<http://dbpedia.org/[^<]+)', line)\n",
        "    category = match[2].replace('<http://dbpedia.org/resource/Category:','').replace('>','').replace('\\n','').strip()\n",
        "    subcategory = match[3].replace('<http://dbpedia.org/resource/Category:','').replace('>','').replace('\\n','').strip()\n",
        "    abstract = match[1].replace('<http://dbpedia.org/property/abstract> \"','').replace('\"@en .',\"\").replace('\\n','').strip()\n",
        "    tokens = tok.tokenize(abstract)\n",
        "    if len(tokens) > 256:\n",
        "      tokens = tokens[:256]\n",
        "    ids = tok.convert_tokens_to_ids(tokens)\n",
        "    #print(ids)\n",
        "    #print(self.category2id[category])\n",
        "    return torch.Tensor(ids), torch.tensor(self.subcategory2id[subcategory]), torch.tensor(self.category2id[category]) \n",
        "\n",
        "  \n",
        "def collate_fn(data): \n",
        "    #Adapted from https://github.com/yunjey/seq2seq-dataloader/blob/master/data_loader.py\n",
        "    \"\"\"Creates mini-batch tensors from the list of tuples (src_seq, labels).\n",
        "    We should build a custom collate_fn rather than using default collate_fn,\n",
        "    because merging sequences (including padding) is not supported in default.\n",
        "    Seqeuences are padded to the maximum length of mini-batch sequences (dynamic padding).\n",
        "    Args:\n",
        "        data: list of tuple (src_seq, labels).\n",
        "            - src_seq: torch tensor of shape (?); variable length.\n",
        "            - subcategory: non-one-hot encoded labels\n",
        "            - category\n",
        "    Returns:\n",
        "        src_seqs: torch tensor of shape (batch_size, padded_length).\n",
        "        src_lengths: list of length (batch_size); valid length for each padded source sequence.\n",
        "    \"\"\"\n",
        "    def merge(sequences):\n",
        "        lengths = [len(seq) for seq in sequences]\n",
        "        padded_seqs = torch.zeros(len(sequences), 256).long()\n",
        "        mask = torch.zeros(len(sequences), 256).long()\n",
        "        for i, seq in enumerate(sequences):\n",
        "            end = lengths[i]\n",
        "            padded_seqs[i, :end] = seq[:end]\n",
        "            mask[i,:end] = 1\n",
        "        return padded_seqs, mask\n",
        "\n",
        "    # sort a list by sequence length (descending order) to use pack_padded_sequence\n",
        "    data.sort(key=lambda x: len(x[0]), reverse=True)\n",
        "\n",
        "    # seperate source and target sequences\n",
        "    src_seqs,subcategory, category = zip(*data)\n",
        "\n",
        "    # merge sequences (from tuple of 1D tensor to 2D tensor)\n",
        "    src_seqs, src_masks = merge(src_seqs)\n",
        "\n",
        "    return src_seqs, src_masks,torch.stack(subcategory),torch.stack(category)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "180\n",
            "370\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fReLo2QCRz7o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "outputId": "8f485de1-d2c1-478b-8415-554043b82bc5"
      },
      "cell_type": "code",
      "source": [
        "#Sanity check\n",
        "text_dataset = AbstractDataset()\n",
        "print(text_dataset[0])\n",
        "loader_train = torch.utils.data.DataLoader(text_dataset,shuffle=False, batch_size=1, collate_fn=collate_fn,num_workers=3,pin_memory=True)\n",
        "data_iter = iter(loader_train)\n",
        "a,b,c,d = next(data_iter)\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([ 1011.,  2382.,  1011.,  1006.,  2207.,  2004., 15117.,  7090.,  1999.,\n",
            "         1996.,  2866.,  1007.,  2003.,  1037.,  3851.,  3185.,  4626.,  2520.,\n",
            "        10931.,  1998.,  2990., 10923.,  2004.,  1996.,  3559.,  1998.,  6674.,\n",
            "         1010.,  4414.,  1010.,  1997.,  1037.,  7214.,  3050.,  3349.,  3944.,\n",
            "         3780.,  1012.,  2004.,  1996.,  5670.,  1997.,  1037.,  5171.,  2154.,\n",
            "         4627.,  1010.,  1999.,  2029.,  2027.,  2123.,  1005.,  1056.,  2113.,\n",
            "         2054.,  2097.,  4148.,  1010.,  1996.,  3780.,  2003.,  2580.,  2077.,\n",
            "         2256.,  2159.,  2004.,  2367.,  3441.,  2024.,  3603.,  1998.,  2988.,\n",
            "         1012.]), tensor(0), tensor(0))\n",
            "tensor([[ 1011,  2382,  1011,  1006,  2207,  2004, 15117,  7090,  1999,  1996,\n",
            "          2866,  1007,  2003,  1037,  3851,  3185,  4626,  2520, 10931,  1998,\n",
            "          2990, 10923,  2004,  1996,  3559,  1998,  6674,  1010,  4414,  1010,\n",
            "          1997,  1037,  7214,  3050,  3349,  3944,  3780,  1012,  2004,  1996,\n",
            "          5670,  1997,  1037,  5171,  2154,  4627,  1010,  1999,  2029,  2027,\n",
            "          2123,  1005,  1056,  2113,  2054,  2097,  4148,  1010,  1996,  3780,\n",
            "          2003,  2580,  2077,  2256,  2159,  2004,  2367,  3441,  2024,  3603,\n",
            "          1998,  2988,  1012,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0]])\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bcgp9TnS9QQe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train base model"
      ]
    },
    {
      "metadata": {
        "id": "KKI6c6ZBCfMV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3302
        },
        "outputId": "0d8bc368-7bcd-4990-a37d-15c88d9b0e02"
      },
      "cell_type": "code",
      "source": [
        "import time, datetime\n",
        "import torch.nn as nn\n",
        "from google.colab import files\n",
        "\n",
        "#Hyperparameters\n",
        "max_seq_len = 256\n",
        "dim_embedding = 50\n",
        "num_heads = 5\n",
        "num_encoder_layers = 6\n",
        "ff_num_features = 1024\n",
        "vocab_size = count_lines('./cis700project/cis700/vocab/bert-base-uncased-vocab.txt')\n",
        "batch_size = 128\n",
        "num_epochs = 10\n",
        "lr = 1e-3\n",
        "\n",
        "network_name = 'transformer-s%d-e%d-h%d-l%d' % (max_seq_len, dim_embedding, num_heads, num_encoder_layers)\n",
        "\n",
        "\n",
        "now = time.mktime(datetime.datetime.now().timetuple())\n",
        "logger = Logger(f'./logs/Transformer_{now}/')\n",
        "logger_val = Logger(f'./logs/Transformer_eval_{now}/')\n",
        "\n",
        "# gather number of categories\n",
        "num_fine_classes = category_size\n",
        "num_coarse_classes = subcategory_size\n",
        "\n",
        "#Seed\n",
        "torch.manual_seed(0)\n",
        "\n",
        "text_dataset = AbstractDataset()\n",
        "lengths = [int(len(text_dataset)*0.8), int(len(text_dataset)*0.1), int(len(text_dataset)) - \n",
        "           int(len(text_dataset)*0.8) - int(len(text_dataset)*0.1)]\n",
        "text_dataset_train, text_dataset_val, text_dataset_test = torch.utils.data.random_split(text_dataset, lengths)\n",
        "\n",
        "loader_train = torch.utils.data.DataLoader(text_dataset_train,shuffle=True, batch_size=batch_size, collate_fn=collate_fn,num_workers=3,pin_memory=True)\n",
        "loader_test = torch.utils.data.DataLoader(text_dataset_test,shuffle=True, batch_size=batch_size, collate_fn=collate_fn,num_workers=3,pin_memory=True)\n",
        "torch.backends.cudnn.enabled = True\n",
        "\n",
        "model = Classifier(vocab_size, dim_embedding, num_heads,\n",
        "                   ff_num_features, num_encoder_layers, \n",
        "                   max_seq_len, num_fine_classes)\n",
        "initialize_model(model)\n",
        "model = model.cuda()\n",
        "\n",
        "#Loss and optimizer\n",
        "loss_fun = torch.nn.CrossEntropyLoss() \n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.98), eps=1e-9)\n",
        "\n",
        "def validate(num_train_steps):     \n",
        "  #Get validation data\n",
        "  rand_sampler = torch.utils.data.RandomSampler(text_dataset_val, num_samples=batch_size, replacement=True)\n",
        "  loader_val = torch.utils.data.DataLoader(text_dataset_val, batch_size=batch_size, collate_fn=collate_fn,num_workers=3,pin_memory=True, sampler=rand_sampler)\n",
        "  get_data_step = iter(loader_val)\n",
        "  model.eval()\n",
        "  count_correct = 0\n",
        "  count_total = 0\n",
        "  with torch.no_grad():\n",
        "    abstract, mask, subcategory, category = next(get_data_step)\n",
        "    abstract = abstract.to(device)\n",
        "    subcategory = subcategory.to(device)\n",
        "    category = category.to(device)\n",
        "    mask = mask.to(device)\n",
        "    \n",
        "    result = model(abstract,mask)\n",
        "    loss = loss_fun(result, category)\n",
        "    _, argmax = torch.max(result, 1)\n",
        "    count_total += category.size(0)\n",
        "    count_correct += (argmax == category).sum().item()\n",
        "    accuracy = (category == argmax).float().mean()\n",
        "  \n",
        "    #Tensorboard logging\n",
        "    to_log = {'loss': loss.item(), 'accuracy': accuracy.item()}\n",
        "    for handle, val in to_log.items():\n",
        "      logger_val.scalar_summary(handle, val, num_train_steps+1)\n",
        "\n",
        "  print('The validation accuracy is: %s%% [%s]' % (count_correct/count_total * 100,batch_size))  \n",
        "  model.train()\n",
        "\n",
        "def evaluate():     \n",
        "  #Get testing data\n",
        "  get_data_step = iter(loader_test)\n",
        "  epoch_length = len(loader_test)\n",
        "\n",
        "  model.eval()\n",
        "  count_correct = 0\n",
        "  count_total = 0\n",
        "  with torch.no_grad():\n",
        "    for test_step in range(epoch_length):\n",
        "      abstract, mask, subcategory, category = next(get_data_step)\n",
        "\n",
        "      abstract = abstract.to(device)\n",
        "      subcategory = subcategory.to(device)\n",
        "      category = category.to(device)\n",
        "      mask = mask.to(device)\n",
        "\n",
        "      result = model(abstract, mask)\n",
        "      _, argmax = torch.max(result, 1)\n",
        "      count_total += category.size(0)\n",
        "      count_correct += (argmax == category).sum().item()\n",
        "\n",
        "  print('The testing set accuracy is: %s%% [%s]' % (count_correct/count_total * 100,epoch_length * batch_size))  \n",
        "  model.train()\n",
        "  \n",
        "#Training loop\n",
        "model.train()\n",
        "num_train_steps = 0\n",
        "for epoch in range(num_epochs):\n",
        "    #Get an epoch\n",
        "    get_data_step = iter(loader_train)\n",
        "    epoch_length = len(loader_train)\n",
        "    for train_step in range(epoch_length):\n",
        "      #start = time.time()\n",
        "      num_train_steps += 1\n",
        "      \n",
        "      abstract, mask, subcategory, category = next(get_data_step)\n",
        "      #print(abstract)\n",
        "      abstract = abstract.to(device)\n",
        "      subcategory = subcategory.to(device)\n",
        "      category = category.to(device)\n",
        "      mask = mask.to(device)\n",
        "    \n",
        "      # Do a forward pass\n",
        "      #start = time.time()\n",
        "      result = model(abstract, mask)\n",
        "      #end = time.time()\n",
        "      loss = loss_fun(result, category)\n",
        "    \n",
        "      # Now backpropagate\n",
        "      optimizer.zero_grad()\n",
        "      #start = time.time()\n",
        "      loss.backward()\n",
        "      #end = time.time()\n",
        "      \n",
        "      optimizer.step()\n",
        "\n",
        "      # Find the accuracy\n",
        "      _, argmax = torch.max(result,1)\n",
        "      accuracy = (category == argmax).float().mean()\n",
        "      \n",
        "      #Print\n",
        "      if (num_train_steps + 1) % 100 == 0: \n",
        "        print('Epoch: [% d/% d], Step: [% d/% d], Loss: %.4f, Accuracy: %4f'\n",
        "          % (epoch + 1, num_epochs, num_train_steps, len(loader_train) * num_epochs, loss.item(), accuracy.item())) \n",
        "        validate(num_train_steps+1)\n",
        "      #print(torch.cuda.memory_allocated(device))\n",
        "      #print(torch.cuda.memory_cached(device))\n",
        "      end = time.time()\n",
        "      #print(end-start)\n",
        "      del abstract, mask, subcategory, category, result, argmax\n",
        "      torch.cuda.empty_cache()\n",
        "      \n",
        "      if num_train_steps % 1 == 0:  \n",
        "        #Tensorboard logging\n",
        "        to_log = {'loss': loss.item(), 'accuracy': accuracy.item()}\n",
        "        for handle, val in to_log.items():\n",
        "            logger.scalar_summary(handle, val, num_train_steps+1)\n",
        "            \n",
        "    evaluate()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: [ 1/ 10], Step: [ 99/ 86540], Loss: 6.1380, Accuracy: 0.039062\n",
            "The validation accuracy is: 6.25% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 199/ 86540], Loss: 5.2292, Accuracy: 0.062500\n",
            "The validation accuracy is: 12.5% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 299/ 86540], Loss: 4.5735, Accuracy: 0.195312\n",
            "The validation accuracy is: 25.0% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 399/ 86540], Loss: 3.5834, Accuracy: 0.281250\n",
            "The validation accuracy is: 28.90625% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 499/ 86540], Loss: 3.4190, Accuracy: 0.281250\n",
            "The validation accuracy is: 29.6875% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 599/ 86540], Loss: 4.0454, Accuracy: 0.203125\n",
            "The validation accuracy is: 27.34375% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 699/ 86540], Loss: 3.5594, Accuracy: 0.242188\n",
            "The validation accuracy is: 24.21875% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 799/ 86540], Loss: 3.0185, Accuracy: 0.281250\n",
            "The validation accuracy is: 32.03125% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 899/ 86540], Loss: 2.8580, Accuracy: 0.328125\n",
            "The validation accuracy is: 28.125% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 999/ 86540], Loss: 3.0095, Accuracy: 0.335938\n",
            "The validation accuracy is: 33.59375% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 1099/ 86540], Loss: 3.1694, Accuracy: 0.265625\n",
            "The validation accuracy is: 36.71875% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 1199/ 86540], Loss: 3.1577, Accuracy: 0.320312\n",
            "The validation accuracy is: 28.125% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 1299/ 86540], Loss: 2.9319, Accuracy: 0.351562\n",
            "The validation accuracy is: 34.375% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 1399/ 86540], Loss: 2.7966, Accuracy: 0.335938\n",
            "The validation accuracy is: 35.9375% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 1499/ 86540], Loss: 2.7556, Accuracy: 0.406250\n",
            "The validation accuracy is: 35.15625% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 1599/ 86540], Loss: 3.1002, Accuracy: 0.312500\n",
            "The validation accuracy is: 41.40625% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 1699/ 86540], Loss: 3.2284, Accuracy: 0.265625\n",
            "The validation accuracy is: 32.03125% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 1799/ 86540], Loss: 2.6608, Accuracy: 0.312500\n",
            "The validation accuracy is: 31.25% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 1899/ 86540], Loss: 2.5179, Accuracy: 0.414062\n",
            "The validation accuracy is: 28.90625% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 1999/ 86540], Loss: 3.0710, Accuracy: 0.296875\n",
            "The validation accuracy is: 39.0625% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 2099/ 86540], Loss: 2.7401, Accuracy: 0.382812\n",
            "The validation accuracy is: 40.625% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 2199/ 86540], Loss: 2.8423, Accuracy: 0.335938\n",
            "The validation accuracy is: 38.28125% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 2299/ 86540], Loss: 2.1486, Accuracy: 0.492188\n",
            "The validation accuracy is: 38.28125% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 2399/ 86540], Loss: 2.4242, Accuracy: 0.406250\n",
            "The validation accuracy is: 35.9375% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 2499/ 86540], Loss: 2.7321, Accuracy: 0.335938\n",
            "The validation accuracy is: 47.65625% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 2599/ 86540], Loss: 2.3986, Accuracy: 0.414062\n",
            "The validation accuracy is: 36.71875% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 2699/ 86540], Loss: 2.4128, Accuracy: 0.367188\n",
            "The validation accuracy is: 35.9375% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 2799/ 86540], Loss: 2.8621, Accuracy: 0.304688\n",
            "The validation accuracy is: 36.71875% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 2899/ 86540], Loss: 2.3640, Accuracy: 0.398438\n",
            "The validation accuracy is: 42.96875% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 2999/ 86540], Loss: 2.5934, Accuracy: 0.343750\n",
            "The validation accuracy is: 38.28125% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 3099/ 86540], Loss: 2.1488, Accuracy: 0.484375\n",
            "The validation accuracy is: 32.8125% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 3199/ 86540], Loss: 2.5633, Accuracy: 0.375000\n",
            "The validation accuracy is: 35.15625% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 3299/ 86540], Loss: 2.6387, Accuracy: 0.382812\n",
            "The validation accuracy is: 43.75% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 3399/ 86540], Loss: 2.5240, Accuracy: 0.375000\n",
            "The validation accuracy is: 35.9375% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 3499/ 86540], Loss: 2.5899, Accuracy: 0.367188\n",
            "The validation accuracy is: 42.1875% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 3599/ 86540], Loss: 2.4967, Accuracy: 0.375000\n",
            "The validation accuracy is: 41.40625% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 3699/ 86540], Loss: 2.5702, Accuracy: 0.351562\n",
            "The validation accuracy is: 42.96875% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 3799/ 86540], Loss: 2.3960, Accuracy: 0.414062\n",
            "The validation accuracy is: 32.03125% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 3899/ 86540], Loss: 2.2224, Accuracy: 0.421875\n",
            "The validation accuracy is: 38.28125% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 3999/ 86540], Loss: 2.5375, Accuracy: 0.375000\n",
            "The validation accuracy is: 36.71875% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 4099/ 86540], Loss: 2.4129, Accuracy: 0.398438\n",
            "The validation accuracy is: 40.625% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 4199/ 86540], Loss: 2.7935, Accuracy: 0.320312\n",
            "The validation accuracy is: 33.59375% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 4299/ 86540], Loss: 2.4789, Accuracy: 0.382812\n",
            "The validation accuracy is: 39.0625% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 4399/ 86540], Loss: 2.5130, Accuracy: 0.359375\n",
            "The validation accuracy is: 42.1875% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 4499/ 86540], Loss: 2.3987, Accuracy: 0.406250\n",
            "The validation accuracy is: 46.09375% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 4599/ 86540], Loss: 2.4340, Accuracy: 0.429688\n",
            "The validation accuracy is: 46.875% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 4699/ 86540], Loss: 2.2037, Accuracy: 0.382812\n",
            "The validation accuracy is: 42.1875% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 4799/ 86540], Loss: 2.7086, Accuracy: 0.359375\n",
            "The validation accuracy is: 41.40625% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 4899/ 86540], Loss: 2.3737, Accuracy: 0.398438\n",
            "The validation accuracy is: 32.03125% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 4999/ 86540], Loss: 2.5944, Accuracy: 0.390625\n",
            "The validation accuracy is: 37.5% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 5099/ 86540], Loss: 2.1719, Accuracy: 0.460938\n",
            "The validation accuracy is: 34.375% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 5199/ 86540], Loss: 2.2407, Accuracy: 0.406250\n",
            "The validation accuracy is: 41.40625% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 5299/ 86540], Loss: 2.0807, Accuracy: 0.437500\n",
            "The validation accuracy is: 46.875% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 5399/ 86540], Loss: 2.3301, Accuracy: 0.445312\n",
            "The validation accuracy is: 32.8125% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 5499/ 86540], Loss: 2.2916, Accuracy: 0.492188\n",
            "The validation accuracy is: 44.53125% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 5599/ 86540], Loss: 2.4425, Accuracy: 0.382812\n",
            "The validation accuracy is: 45.3125% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 5699/ 86540], Loss: 2.3631, Accuracy: 0.421875\n",
            "The validation accuracy is: 36.71875% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 5799/ 86540], Loss: 2.5247, Accuracy: 0.398438\n",
            "The validation accuracy is: 45.3125% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 5899/ 86540], Loss: 2.1917, Accuracy: 0.500000\n",
            "The validation accuracy is: 42.96875% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 5999/ 86540], Loss: 2.3986, Accuracy: 0.421875\n",
            "The validation accuracy is: 42.96875% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 6099/ 86540], Loss: 2.1535, Accuracy: 0.421875\n",
            "The validation accuracy is: 38.28125% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 6199/ 86540], Loss: 2.3255, Accuracy: 0.421875\n",
            "The validation accuracy is: 35.9375% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 6299/ 86540], Loss: 2.4184, Accuracy: 0.437500\n",
            "The validation accuracy is: 40.625% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 6399/ 86540], Loss: 2.2252, Accuracy: 0.429688\n",
            "The validation accuracy is: 44.53125% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 6499/ 86540], Loss: 2.2298, Accuracy: 0.429688\n",
            "The validation accuracy is: 45.3125% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 6599/ 86540], Loss: 2.3868, Accuracy: 0.398438\n",
            "The validation accuracy is: 38.28125% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 6699/ 86540], Loss: 2.1411, Accuracy: 0.468750\n",
            "The validation accuracy is: 35.9375% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 6799/ 86540], Loss: 2.1418, Accuracy: 0.500000\n",
            "The validation accuracy is: 50.0% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 6899/ 86540], Loss: 1.9946, Accuracy: 0.453125\n",
            "The validation accuracy is: 41.40625% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 6999/ 86540], Loss: 2.7757, Accuracy: 0.406250\n",
            "The validation accuracy is: 35.15625% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 7099/ 86540], Loss: 2.3861, Accuracy: 0.390625\n",
            "The validation accuracy is: 35.15625% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 7199/ 86540], Loss: 2.4810, Accuracy: 0.382812\n",
            "The validation accuracy is: 47.65625% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 7299/ 86540], Loss: 2.3650, Accuracy: 0.437500\n",
            "The validation accuracy is: 42.96875% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 7399/ 86540], Loss: 2.2737, Accuracy: 0.398438\n",
            "The validation accuracy is: 35.15625% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 7499/ 86540], Loss: 2.1410, Accuracy: 0.453125\n",
            "The validation accuracy is: 40.625% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 7599/ 86540], Loss: 2.2221, Accuracy: 0.484375\n",
            "The validation accuracy is: 48.4375% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 7699/ 86540], Loss: 2.5361, Accuracy: 0.335938\n",
            "The validation accuracy is: 35.15625% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 7799/ 86540], Loss: 2.3516, Accuracy: 0.421875\n",
            "The validation accuracy is: 33.59375% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 7899/ 86540], Loss: 2.4847, Accuracy: 0.375000\n",
            "The validation accuracy is: 39.84375% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 7999/ 86540], Loss: 2.4525, Accuracy: 0.414062\n",
            "The validation accuracy is: 46.09375% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 8099/ 86540], Loss: 2.2905, Accuracy: 0.468750\n",
            "The validation accuracy is: 47.65625% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 8199/ 86540], Loss: 2.4962, Accuracy: 0.375000\n",
            "The validation accuracy is: 46.09375% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 8299/ 86540], Loss: 2.4014, Accuracy: 0.351562\n",
            "The validation accuracy is: 40.625% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 8399/ 86540], Loss: 2.3356, Accuracy: 0.390625\n",
            "The validation accuracy is: 38.28125% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 8499/ 86540], Loss: 2.3645, Accuracy: 0.429688\n",
            "The validation accuracy is: 42.96875% [128]\n",
            "Epoch: [ 1/ 10], Step: [ 8599/ 86540], Loss: 2.0040, Accuracy: 0.492188\n",
            "The validation accuracy is: 53.90625% [128]\n",
            "The testing set accuracy is: 42.82804792616078% [138496]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-6343e15cca9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_train_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m     \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0;34m'port'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m       \u001b[0;34m'path'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m       \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m   })\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "tG9JxlgiCfMb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "filename = save_model(model, network_name, epoch, num_train_steps)\n",
        "files.download(filename) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tFzN5fZ49bcX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Transfer leaning on traning data"
      ]
    },
    {
      "metadata": {
        "id": "-jjaTKo752Te",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 14824
        },
        "outputId": "183d3268-d63e-4c7c-b36b-01d1a787b9a1"
      },
      "cell_type": "code",
      "source": [
        "from functools import reduce\n",
        "from google.colab import files\n",
        "import datetime\n",
        "#files.upload()\n",
        "\n",
        "# gather number of categories\n",
        "num_fine_classes = category_size\n",
        "num_coarse_classes = subcategory_size\n",
        "\n",
        "#Seed\n",
        "torch.manual_seed(0)\n",
        "\n",
        "#Settings\n",
        "max_seq_len = 256\n",
        "dim_embedding = 50\n",
        "num_heads = 5\n",
        "num_encoder_layers = 6\n",
        "ff_num_features = 1024\n",
        "vocab_size = count_lines('./cis700project/cis700/vocab/bert-base-uncased-vocab.txt')\n",
        "model = Classifier(vocab_size, dim_embedding, num_heads,\n",
        "                   ff_num_features, num_encoder_layers, \n",
        "                   max_seq_len, num_fine_classes)\n",
        "#checkpoint = torch.load('transformer-s256-e50-h5-l6.epoch-0.step-8654.pth')\n",
        "checkpoint = torch.load('/content/drive/My Drive/transformer-fine-s256-e50-h5-l6.epoch-9.step-221540.pth')\n",
        "model.load_state_dict(checkpoint)\n",
        "model.eval()\n",
        "\n",
        "total_params = sum([param.nelement() for param in model.parameters()])\n",
        "train_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(\"Original model trainable params %s/%s\" % (train_params, total_params))\n",
        "\n",
        "new_model = model\n",
        "for param in new_model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "feature_cnt = new_model.fc.in_features\n",
        "new_model.fc = torch.nn.Linear(feature_cnt, num_coarse_classes)\n",
        "#print(num_coarse_classes)\n",
        "total_params = sum([param.nelement() for param in new_model.parameters()])\n",
        "train_params = sum(p.numel() for p in new_model.parameters() if p.requires_grad)\n",
        "print(\"New model trainable params %s/%s\" % (train_params, total_params))\n",
        "\n",
        "\n",
        "#Hyperparameters\n",
        "batch_size = 128\n",
        "num_epochs = 5\n",
        "lr = 1e-3\n",
        "\n",
        "network_name = 'transformer-s%d-e%d-h%d-l%d' % (max_seq_len, dim_embedding, num_heads, num_encoder_layers)\n",
        "\n",
        "\n",
        "now = time.mktime(datetime.datetime.now().timetuple())\n",
        "logger = Logger(f'./logs/Transformer_transfer_{now}/')\n",
        "logger_val = Logger(f'./logs/Transformer_transfer_eval_{now}/')\n",
        "\n",
        "# gather number of categories\n",
        "num_fine_classes = category_size\n",
        "num_coarse_classes = subcategory_size\n",
        "\n",
        "#Seed\n",
        "torch.manual_seed(0)\n",
        "\n",
        "\n",
        "text_dataset = AbstractDataset()\n",
        "lengths = [int(len(text_dataset)*0.8), int(len(text_dataset)*0.1), int(len(text_dataset)) - \n",
        "           int(len(text_dataset)*0.8) - int(len(text_dataset)*0.1)]\n",
        "text_dataset_train, text_dataset_val, text_dataset_test = torch.utils.data.random_split(text_dataset, lengths)\n",
        "\n",
        "loader_train = torch.utils.data.DataLoader(text_dataset_train,shuffle=True, batch_size=batch_size, collate_fn=collate_fn,num_workers=3,pin_memory=True)\n",
        "loader_test = torch.utils.data.DataLoader(text_dataset_test,shuffle=True, batch_size=batch_size, collate_fn=collate_fn,num_workers=3,pin_memory=True)\n",
        "torch.backends.cudnn.enabled = True\n",
        "\n",
        "new_model = new_model.cuda()\n",
        "\n",
        "#Loss and optimizer\n",
        "loss_fun = torch.nn.CrossEntropyLoss() \n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "def validate(num_train_steps):     \n",
        "  #Get validation data\n",
        "  rand_sampler = torch.utils.data.RandomSampler(text_dataset_val, num_samples=batch_size, replacement=True)\n",
        "  loader_val = torch.utils.data.DataLoader(text_dataset_val, batch_size=batch_size, collate_fn=collate_fn,num_workers=3,pin_memory=True, sampler=rand_sampler)\n",
        "  get_data_step = iter(loader_val)\n",
        "  model.eval()\n",
        "  count_correct = 0\n",
        "  count_total = 0\n",
        "  with torch.no_grad():\n",
        "    abstract, mask, subcategory, category = next(get_data_step)\n",
        "    abstract = abstract.to(device)\n",
        "    subcategory = subcategory.to(device)\n",
        "    category = category.to(device)\n",
        "    mask = mask.to(device)\n",
        "    \n",
        "    result = new_model(abstract,mask)\n",
        "    loss = loss_fun(result, subcategory)\n",
        "    _, argmax = torch.max(result, 1)\n",
        "    count_total += subcategory.size(0)\n",
        "    count_correct += (argmax == subcategory).sum().item()\n",
        "    accuracy = (subcategory == argmax).float().mean()\n",
        "  \n",
        "    #Tensorboard logging\n",
        "    to_log = {'loss': loss.item(), 'accuracy': accuracy.item()}\n",
        "    for handle, val in to_log.items():\n",
        "      logger_val.scalar_summary(handle, val, num_train_steps+1)\n",
        "\n",
        "  print('The validation accuracy is: %s%% [%s]' % (count_correct/count_total * 100,batch_size))  \n",
        "  model.train()\n",
        "\n",
        "def evaluate():     \n",
        "  #Get testing data\n",
        "  get_data_step = iter(loader_test)\n",
        "  epoch_length = len(loader_test)\n",
        "\n",
        "  model.eval()\n",
        "  count_correct = 0\n",
        "  count_total = 0\n",
        "  with torch.no_grad():\n",
        "    for test_step in range(epoch_length):\n",
        "      abstract, mask, subcategory, category = next(get_data_step)\n",
        "\n",
        "      abstract = abstract.to(device)\n",
        "      subcategory = subcategory.to(device)\n",
        "      category = category.to(device)\n",
        "      mask = mask.to(device)\n",
        "\n",
        "      result = new_model(abstract, mask)\n",
        "      _, argmax = torch.max(result, 1)\n",
        "      count_total += subcategory.size(0)\n",
        "      count_correct += (argmax == subcategory).sum().item()\n",
        "\n",
        "  print('The testing set accuracy is: %s%% [%s]' % (count_correct/count_total * 100,epoch_length * batch_size))  \n",
        "  model.train()\n",
        "\n",
        "#Training loop\n",
        "new_model.train()\n",
        "num_train_steps = 0\n",
        "for epoch in range(num_epochs):\n",
        "    #Get an epoch\n",
        "    get_data_step = iter(loader_train)\n",
        "    epoch_length = len(loader_train)\n",
        "    for train_step in range(epoch_length):\n",
        "      #start = time.time()\n",
        "      num_train_steps += 1\n",
        "      \n",
        "      abstract, mask, subcategory, category = next(get_data_step)\n",
        "      #print(abstract)\n",
        "      abstract = abstract.to(device)\n",
        "      subcategory = subcategory.to(device)\n",
        "      category = category.to(device)\n",
        "      mask = mask.to(device)\n",
        "    \n",
        "      # Do a forward pass\n",
        "      #start = time.time()\n",
        "      result = new_model(abstract, mask)\n",
        "      #end = time.time()\n",
        "      loss = loss_fun(result, subcategory)\n",
        "    \n",
        "      # Now backpropagate\n",
        "      optimizer.zero_grad()\n",
        "      #start = time.time()\n",
        "      loss.backward()\n",
        "      #end = time.time()\n",
        "      \n",
        "      optimizer.step()\n",
        "\n",
        "      # Find the accuracy\n",
        "      _, argmax = torch.max(result,1)\n",
        "      accuracy = (subcategory == argmax).float().mean()\n",
        "      \n",
        "      #Print\n",
        "      if (num_train_steps + 1) % 100 == 0: \n",
        "        print('Epoch: [% d/% d], Step: [% d/% d], Loss: %.4f, Accuracy: %4f'\n",
        "          % (epoch + 1, num_epochs, num_train_steps, len(loader_train) * num_epochs, loss.item(), accuracy.item())) \n",
        "        validate(num_train_steps+1)\n",
        "      #print(torch.cuda.memory_allocated(device))\n",
        "      #print(torch.cuda.memory_cached(device))\n",
        "      end = time.time()\n",
        "      #print(end-start)\n",
        "      del abstract, mask, subcategory, category, result, argmax\n",
        "      torch.cuda.empty_cache()\n",
        "      \n",
        "      if num_train_steps % 1 == 0:  \n",
        "        #Tensorboard logging\n",
        "        to_log = {'loss': loss.item(), 'accuracy': accuracy.item()}\n",
        "        for handle, val in to_log.items():\n",
        "            logger.scalar_summary(handle, val, num_train_steps+1)\n",
        "            \n",
        "    evaluate()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original model trainable params 6945814/6945814\n",
            "New model trainable params 2304180/4513624\n",
            "Epoch: [ 1/ 5], Step: [ 99/ 43270], Loss: 2.4529, Accuracy: 0.367188\n",
            "The validation accuracy is: 32.03125% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 199/ 43270], Loss: 2.2901, Accuracy: 0.406250\n",
            "The validation accuracy is: 34.375% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 299/ 43270], Loss: 2.4178, Accuracy: 0.414062\n",
            "The validation accuracy is: 38.28125% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 399/ 43270], Loss: 2.2191, Accuracy: 0.468750\n",
            "The validation accuracy is: 44.53125% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 499/ 43270], Loss: 2.1496, Accuracy: 0.468750\n",
            "The validation accuracy is: 32.8125% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 599/ 43270], Loss: 2.5263, Accuracy: 0.367188\n",
            "The validation accuracy is: 32.8125% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 699/ 43270], Loss: 2.2607, Accuracy: 0.382812\n",
            "The validation accuracy is: 46.875% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 799/ 43270], Loss: 2.1851, Accuracy: 0.476562\n",
            "The validation accuracy is: 41.40625% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 899/ 43270], Loss: 2.4312, Accuracy: 0.429688\n",
            "The validation accuracy is: 43.75% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 999/ 43270], Loss: 2.3476, Accuracy: 0.429688\n",
            "The validation accuracy is: 30.46875% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 1099/ 43270], Loss: 2.4738, Accuracy: 0.359375\n",
            "The validation accuracy is: 42.96875% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 1199/ 43270], Loss: 2.6964, Accuracy: 0.390625\n",
            "The validation accuracy is: 42.96875% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 1299/ 43270], Loss: 2.7888, Accuracy: 0.312500\n",
            "The validation accuracy is: 37.5% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 1399/ 43270], Loss: 2.6485, Accuracy: 0.351562\n",
            "The validation accuracy is: 37.5% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 1499/ 43270], Loss: 2.6710, Accuracy: 0.398438\n",
            "The validation accuracy is: 33.59375% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 1599/ 43270], Loss: 2.5149, Accuracy: 0.468750\n",
            "The validation accuracy is: 46.09375% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 1699/ 43270], Loss: 2.2698, Accuracy: 0.375000\n",
            "The validation accuracy is: 40.625% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 1799/ 43270], Loss: 2.3799, Accuracy: 0.460938\n",
            "The validation accuracy is: 39.0625% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 1899/ 43270], Loss: 2.3329, Accuracy: 0.445312\n",
            "The validation accuracy is: 38.28125% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 1999/ 43270], Loss: 2.3442, Accuracy: 0.421875\n",
            "The validation accuracy is: 38.28125% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 2099/ 43270], Loss: 2.4321, Accuracy: 0.375000\n",
            "The validation accuracy is: 44.53125% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 2199/ 43270], Loss: 2.5418, Accuracy: 0.390625\n",
            "The validation accuracy is: 42.96875% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 2299/ 43270], Loss: 2.5894, Accuracy: 0.406250\n",
            "The validation accuracy is: 45.3125% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 2399/ 43270], Loss: 2.4317, Accuracy: 0.390625\n",
            "The validation accuracy is: 42.1875% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 2499/ 43270], Loss: 2.6045, Accuracy: 0.406250\n",
            "The validation accuracy is: 50.0% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 2599/ 43270], Loss: 2.6565, Accuracy: 0.375000\n",
            "The validation accuracy is: 42.1875% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 2699/ 43270], Loss: 2.9456, Accuracy: 0.421875\n",
            "The validation accuracy is: 46.875% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 2799/ 43270], Loss: 2.7492, Accuracy: 0.343750\n",
            "The validation accuracy is: 48.4375% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 2899/ 43270], Loss: 2.2073, Accuracy: 0.445312\n",
            "The validation accuracy is: 38.28125% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 2999/ 43270], Loss: 2.4842, Accuracy: 0.429688\n",
            "The validation accuracy is: 47.65625% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 3099/ 43270], Loss: 2.5230, Accuracy: 0.375000\n",
            "The validation accuracy is: 42.96875% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 3199/ 43270], Loss: 2.4955, Accuracy: 0.453125\n",
            "The validation accuracy is: 46.09375% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 3299/ 43270], Loss: 2.6271, Accuracy: 0.414062\n",
            "The validation accuracy is: 43.75% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 3399/ 43270], Loss: 2.7703, Accuracy: 0.406250\n",
            "The validation accuracy is: 33.59375% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 3499/ 43270], Loss: 2.6440, Accuracy: 0.453125\n",
            "The validation accuracy is: 42.96875% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 3599/ 43270], Loss: 2.6695, Accuracy: 0.382812\n",
            "The validation accuracy is: 46.875% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 3699/ 43270], Loss: 2.6072, Accuracy: 0.437500\n",
            "The validation accuracy is: 43.75% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 3799/ 43270], Loss: 2.9394, Accuracy: 0.359375\n",
            "The validation accuracy is: 50.78125% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 3899/ 43270], Loss: 2.5521, Accuracy: 0.390625\n",
            "The validation accuracy is: 34.375% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 3999/ 43270], Loss: 2.7508, Accuracy: 0.421875\n",
            "The validation accuracy is: 42.1875% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 4099/ 43270], Loss: 2.6819, Accuracy: 0.406250\n",
            "The validation accuracy is: 42.1875% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 4199/ 43270], Loss: 2.4942, Accuracy: 0.406250\n",
            "The validation accuracy is: 43.75% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 4299/ 43270], Loss: 2.8477, Accuracy: 0.445312\n",
            "The validation accuracy is: 42.1875% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 4399/ 43270], Loss: 2.8967, Accuracy: 0.367188\n",
            "The validation accuracy is: 37.5% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 4499/ 43270], Loss: 2.7556, Accuracy: 0.390625\n",
            "The validation accuracy is: 49.21875% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 4599/ 43270], Loss: 2.9815, Accuracy: 0.351562\n",
            "The validation accuracy is: 33.59375% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 4699/ 43270], Loss: 2.5451, Accuracy: 0.390625\n",
            "The validation accuracy is: 41.40625% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 4799/ 43270], Loss: 2.8328, Accuracy: 0.414062\n",
            "The validation accuracy is: 42.96875% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 4899/ 43270], Loss: 2.6806, Accuracy: 0.375000\n",
            "The validation accuracy is: 40.625% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 4999/ 43270], Loss: 3.4035, Accuracy: 0.421875\n",
            "The validation accuracy is: 42.1875% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 5099/ 43270], Loss: 3.2976, Accuracy: 0.375000\n",
            "The validation accuracy is: 39.0625% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 5199/ 43270], Loss: 2.5008, Accuracy: 0.359375\n",
            "The validation accuracy is: 44.53125% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 5299/ 43270], Loss: 3.0661, Accuracy: 0.421875\n",
            "The validation accuracy is: 39.0625% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 5399/ 43270], Loss: 2.8001, Accuracy: 0.390625\n",
            "The validation accuracy is: 34.375% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 5499/ 43270], Loss: 3.1539, Accuracy: 0.367188\n",
            "The validation accuracy is: 42.96875% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 5599/ 43270], Loss: 2.6857, Accuracy: 0.406250\n",
            "The validation accuracy is: 40.625% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 5699/ 43270], Loss: 2.4946, Accuracy: 0.390625\n",
            "The validation accuracy is: 47.65625% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 5799/ 43270], Loss: 2.6910, Accuracy: 0.421875\n",
            "The validation accuracy is: 39.84375% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 5899/ 43270], Loss: 2.9721, Accuracy: 0.359375\n",
            "The validation accuracy is: 46.09375% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 5999/ 43270], Loss: 2.7126, Accuracy: 0.390625\n",
            "The validation accuracy is: 42.1875% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 6099/ 43270], Loss: 3.1532, Accuracy: 0.335938\n",
            "The validation accuracy is: 50.78125% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 6199/ 43270], Loss: 2.4662, Accuracy: 0.382812\n",
            "The validation accuracy is: 41.40625% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 6299/ 43270], Loss: 3.4016, Accuracy: 0.328125\n",
            "The validation accuracy is: 43.75% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 6399/ 43270], Loss: 2.5943, Accuracy: 0.406250\n",
            "The validation accuracy is: 46.875% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 6499/ 43270], Loss: 2.6532, Accuracy: 0.367188\n",
            "The validation accuracy is: 50.0% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 6599/ 43270], Loss: 2.6424, Accuracy: 0.429688\n",
            "The validation accuracy is: 39.0625% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 6699/ 43270], Loss: 2.5858, Accuracy: 0.398438\n",
            "The validation accuracy is: 45.3125% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 6799/ 43270], Loss: 2.7367, Accuracy: 0.375000\n",
            "The validation accuracy is: 51.5625% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 6899/ 43270], Loss: 3.0576, Accuracy: 0.335938\n",
            "The validation accuracy is: 36.71875% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 6999/ 43270], Loss: 2.4849, Accuracy: 0.453125\n",
            "The validation accuracy is: 42.96875% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 7099/ 43270], Loss: 2.6356, Accuracy: 0.429688\n",
            "The validation accuracy is: 50.0% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 7199/ 43270], Loss: 2.4969, Accuracy: 0.445312\n",
            "The validation accuracy is: 46.875% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 7299/ 43270], Loss: 2.9769, Accuracy: 0.382812\n",
            "The validation accuracy is: 33.59375% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 7399/ 43270], Loss: 2.6587, Accuracy: 0.445312\n",
            "The validation accuracy is: 42.96875% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 7499/ 43270], Loss: 3.0090, Accuracy: 0.414062\n",
            "The validation accuracy is: 43.75% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 7599/ 43270], Loss: 3.1369, Accuracy: 0.312500\n",
            "The validation accuracy is: 41.40625% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 7699/ 43270], Loss: 2.9096, Accuracy: 0.429688\n",
            "The validation accuracy is: 45.3125% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 7799/ 43270], Loss: 3.1344, Accuracy: 0.406250\n",
            "The validation accuracy is: 37.5% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 7899/ 43270], Loss: 3.1171, Accuracy: 0.390625\n",
            "The validation accuracy is: 36.71875% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 7999/ 43270], Loss: 2.4741, Accuracy: 0.382812\n",
            "The validation accuracy is: 40.625% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 8099/ 43270], Loss: 3.2319, Accuracy: 0.351562\n",
            "The validation accuracy is: 35.15625% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 8199/ 43270], Loss: 2.7384, Accuracy: 0.390625\n",
            "The validation accuracy is: 46.09375% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 8299/ 43270], Loss: 2.8503, Accuracy: 0.382812\n",
            "The validation accuracy is: 39.0625% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 8399/ 43270], Loss: 2.7760, Accuracy: 0.437500\n",
            "The validation accuracy is: 41.40625% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 8499/ 43270], Loss: 2.8924, Accuracy: 0.453125\n",
            "The validation accuracy is: 42.1875% [128]\n",
            "Epoch: [ 1/ 5], Step: [ 8599/ 43270], Loss: 3.1038, Accuracy: 0.398438\n",
            "The validation accuracy is: 53.90625% [128]\n",
            "The testing set accuracy is: 43.824704072568125% [138496]\n",
            "Epoch: [ 2/ 5], Step: [ 8699/ 43270], Loss: 2.1689, Accuracy: 0.445312\n",
            "The validation accuracy is: 46.09375% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 8799/ 43270], Loss: 1.4557, Accuracy: 0.578125\n",
            "The validation accuracy is: 32.8125% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 8899/ 43270], Loss: 2.2632, Accuracy: 0.437500\n",
            "The validation accuracy is: 49.21875% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 8999/ 43270], Loss: 1.9578, Accuracy: 0.492188\n",
            "The validation accuracy is: 46.875% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 9099/ 43270], Loss: 2.0728, Accuracy: 0.484375\n",
            "The validation accuracy is: 45.3125% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 9199/ 43270], Loss: 1.9191, Accuracy: 0.492188\n",
            "The validation accuracy is: 39.0625% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 9299/ 43270], Loss: 2.2499, Accuracy: 0.453125\n",
            "The validation accuracy is: 42.1875% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 9399/ 43270], Loss: 2.2787, Accuracy: 0.476562\n",
            "The validation accuracy is: 49.21875% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 9499/ 43270], Loss: 2.1068, Accuracy: 0.476562\n",
            "The validation accuracy is: 39.0625% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 9599/ 43270], Loss: 2.1748, Accuracy: 0.515625\n",
            "The validation accuracy is: 45.3125% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 9699/ 43270], Loss: 2.0181, Accuracy: 0.484375\n",
            "The validation accuracy is: 32.8125% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 9799/ 43270], Loss: 2.3769, Accuracy: 0.460938\n",
            "The validation accuracy is: 46.875% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 9899/ 43270], Loss: 2.8089, Accuracy: 0.406250\n",
            "The validation accuracy is: 56.25% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 9999/ 43270], Loss: 1.9938, Accuracy: 0.484375\n",
            "The validation accuracy is: 37.5% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 10099/ 43270], Loss: 2.4454, Accuracy: 0.460938\n",
            "The validation accuracy is: 44.53125% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 10199/ 43270], Loss: 1.9199, Accuracy: 0.523438\n",
            "The validation accuracy is: 44.53125% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 10299/ 43270], Loss: 2.4912, Accuracy: 0.429688\n",
            "The validation accuracy is: 41.40625% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 10399/ 43270], Loss: 2.1218, Accuracy: 0.484375\n",
            "The validation accuracy is: 46.09375% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 10499/ 43270], Loss: 2.3148, Accuracy: 0.437500\n",
            "The validation accuracy is: 45.3125% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 10599/ 43270], Loss: 2.7648, Accuracy: 0.421875\n",
            "The validation accuracy is: 48.4375% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 10699/ 43270], Loss: 2.5675, Accuracy: 0.421875\n",
            "The validation accuracy is: 43.75% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 10799/ 43270], Loss: 2.0782, Accuracy: 0.515625\n",
            "The validation accuracy is: 48.4375% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 10899/ 43270], Loss: 2.1714, Accuracy: 0.492188\n",
            "The validation accuracy is: 35.15625% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 10999/ 43270], Loss: 1.9631, Accuracy: 0.500000\n",
            "The validation accuracy is: 43.75% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 11099/ 43270], Loss: 2.2039, Accuracy: 0.484375\n",
            "The validation accuracy is: 48.4375% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 11199/ 43270], Loss: 2.2689, Accuracy: 0.546875\n",
            "The validation accuracy is: 48.4375% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 11299/ 43270], Loss: 2.1303, Accuracy: 0.515625\n",
            "The validation accuracy is: 51.5625% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 11399/ 43270], Loss: 2.7103, Accuracy: 0.429688\n",
            "The validation accuracy is: 46.875% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 11499/ 43270], Loss: 2.3407, Accuracy: 0.445312\n",
            "The validation accuracy is: 42.96875% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 11599/ 43270], Loss: 2.7378, Accuracy: 0.398438\n",
            "The validation accuracy is: 41.40625% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 11699/ 43270], Loss: 2.3864, Accuracy: 0.515625\n",
            "The validation accuracy is: 47.65625% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 11799/ 43270], Loss: 2.7864, Accuracy: 0.398438\n",
            "The validation accuracy is: 42.1875% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 11899/ 43270], Loss: 2.3672, Accuracy: 0.476562\n",
            "The validation accuracy is: 39.84375% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 11999/ 43270], Loss: 2.4162, Accuracy: 0.476562\n",
            "The validation accuracy is: 42.96875% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 12099/ 43270], Loss: 2.2991, Accuracy: 0.523438\n",
            "The validation accuracy is: 45.3125% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 12199/ 43270], Loss: 2.4463, Accuracy: 0.445312\n",
            "The validation accuracy is: 41.40625% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 12299/ 43270], Loss: 2.6769, Accuracy: 0.382812\n",
            "The validation accuracy is: 39.84375% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 12399/ 43270], Loss: 2.8922, Accuracy: 0.429688\n",
            "The validation accuracy is: 54.6875% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 12499/ 43270], Loss: 2.3978, Accuracy: 0.484375\n",
            "The validation accuracy is: 41.40625% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 12599/ 43270], Loss: 2.6368, Accuracy: 0.375000\n",
            "The validation accuracy is: 43.75% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 12699/ 43270], Loss: 2.7217, Accuracy: 0.429688\n",
            "The validation accuracy is: 44.53125% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 12799/ 43270], Loss: 2.5516, Accuracy: 0.476562\n",
            "The validation accuracy is: 38.28125% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 12899/ 43270], Loss: 2.4538, Accuracy: 0.421875\n",
            "The validation accuracy is: 46.09375% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 12999/ 43270], Loss: 2.4753, Accuracy: 0.437500\n",
            "The validation accuracy is: 42.96875% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 13099/ 43270], Loss: 2.6275, Accuracy: 0.429688\n",
            "The validation accuracy is: 40.625% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 13199/ 43270], Loss: 2.7920, Accuracy: 0.445312\n",
            "The validation accuracy is: 45.3125% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 13299/ 43270], Loss: 2.5083, Accuracy: 0.382812\n",
            "The validation accuracy is: 45.3125% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 13399/ 43270], Loss: 2.5085, Accuracy: 0.437500\n",
            "The validation accuracy is: 38.28125% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 13499/ 43270], Loss: 2.5885, Accuracy: 0.390625\n",
            "The validation accuracy is: 42.96875% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 13599/ 43270], Loss: 2.2586, Accuracy: 0.476562\n",
            "The validation accuracy is: 39.0625% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 13699/ 43270], Loss: 2.7344, Accuracy: 0.460938\n",
            "The validation accuracy is: 46.875% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 13799/ 43270], Loss: 2.8339, Accuracy: 0.398438\n",
            "The validation accuracy is: 46.09375% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 13899/ 43270], Loss: 2.3336, Accuracy: 0.437500\n",
            "The validation accuracy is: 42.96875% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 13999/ 43270], Loss: 2.7151, Accuracy: 0.375000\n",
            "The validation accuracy is: 49.21875% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 14099/ 43270], Loss: 2.9115, Accuracy: 0.382812\n",
            "The validation accuracy is: 46.09375% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 14199/ 43270], Loss: 2.8811, Accuracy: 0.437500\n",
            "The validation accuracy is: 46.09375% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 14299/ 43270], Loss: 2.7668, Accuracy: 0.453125\n",
            "The validation accuracy is: 40.625% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 14399/ 43270], Loss: 2.4632, Accuracy: 0.492188\n",
            "The validation accuracy is: 39.84375% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 14499/ 43270], Loss: 2.4698, Accuracy: 0.476562\n",
            "The validation accuracy is: 50.78125% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 14599/ 43270], Loss: 2.3145, Accuracy: 0.468750\n",
            "The validation accuracy is: 41.40625% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 14699/ 43270], Loss: 2.7767, Accuracy: 0.468750\n",
            "The validation accuracy is: 43.75% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 14799/ 43270], Loss: 2.9413, Accuracy: 0.398438\n",
            "The validation accuracy is: 35.9375% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 14899/ 43270], Loss: 2.4760, Accuracy: 0.523438\n",
            "The validation accuracy is: 35.9375% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 14999/ 43270], Loss: 2.6510, Accuracy: 0.437500\n",
            "The validation accuracy is: 44.53125% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 15099/ 43270], Loss: 2.6556, Accuracy: 0.414062\n",
            "The validation accuracy is: 42.96875% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 15199/ 43270], Loss: 2.2983, Accuracy: 0.531250\n",
            "The validation accuracy is: 42.1875% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 15299/ 43270], Loss: 3.2456, Accuracy: 0.328125\n",
            "The validation accuracy is: 44.53125% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 15399/ 43270], Loss: 2.7599, Accuracy: 0.375000\n",
            "The validation accuracy is: 46.09375% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 15499/ 43270], Loss: 3.0115, Accuracy: 0.453125\n",
            "The validation accuracy is: 53.90625% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 15599/ 43270], Loss: 2.5391, Accuracy: 0.468750\n",
            "The validation accuracy is: 53.90625% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 15699/ 43270], Loss: 2.8126, Accuracy: 0.406250\n",
            "The validation accuracy is: 42.1875% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 15799/ 43270], Loss: 2.7246, Accuracy: 0.414062\n",
            "The validation accuracy is: 36.71875% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 15899/ 43270], Loss: 3.1457, Accuracy: 0.359375\n",
            "The validation accuracy is: 37.5% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 15999/ 43270], Loss: 2.8778, Accuracy: 0.375000\n",
            "The validation accuracy is: 42.1875% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 16099/ 43270], Loss: 2.6237, Accuracy: 0.398438\n",
            "The validation accuracy is: 40.625% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 16199/ 43270], Loss: 2.5855, Accuracy: 0.437500\n",
            "The validation accuracy is: 46.875% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 16299/ 43270], Loss: 2.5881, Accuracy: 0.429688\n",
            "The validation accuracy is: 50.78125% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 16399/ 43270], Loss: 2.6776, Accuracy: 0.484375\n",
            "The validation accuracy is: 42.1875% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 16499/ 43270], Loss: 2.7520, Accuracy: 0.367188\n",
            "The validation accuracy is: 50.0% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 16599/ 43270], Loss: 3.0732, Accuracy: 0.429688\n",
            "The validation accuracy is: 39.0625% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 16699/ 43270], Loss: 2.4412, Accuracy: 0.390625\n",
            "The validation accuracy is: 44.53125% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 16799/ 43270], Loss: 2.7364, Accuracy: 0.500000\n",
            "The validation accuracy is: 42.96875% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 16899/ 43270], Loss: 2.6168, Accuracy: 0.460938\n",
            "The validation accuracy is: 42.96875% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 16999/ 43270], Loss: 3.3748, Accuracy: 0.320312\n",
            "The validation accuracy is: 45.3125% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 17099/ 43270], Loss: 2.3345, Accuracy: 0.492188\n",
            "The validation accuracy is: 46.875% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 17199/ 43270], Loss: 2.9339, Accuracy: 0.367188\n",
            "The validation accuracy is: 48.4375% [128]\n",
            "Epoch: [ 2/ 5], Step: [ 17299/ 43270], Loss: 2.7131, Accuracy: 0.375000\n",
            "The validation accuracy is: 48.4375% [128]\n",
            "The testing set accuracy is: 44.065923748582655% [138496]\n",
            "Epoch: [ 3/ 5], Step: [ 17399/ 43270], Loss: 1.6181, Accuracy: 0.585938\n",
            "The validation accuracy is: 45.3125% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 17499/ 43270], Loss: 2.0685, Accuracy: 0.492188\n",
            "The validation accuracy is: 41.40625% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 17599/ 43270], Loss: 2.0410, Accuracy: 0.507812\n",
            "The validation accuracy is: 50.78125% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 17699/ 43270], Loss: 2.5644, Accuracy: 0.320312\n",
            "The validation accuracy is: 46.09375% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 17799/ 43270], Loss: 2.3287, Accuracy: 0.429688\n",
            "The validation accuracy is: 40.625% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 17899/ 43270], Loss: 2.3950, Accuracy: 0.437500\n",
            "The validation accuracy is: 50.78125% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 17999/ 43270], Loss: 1.8662, Accuracy: 0.531250\n",
            "The validation accuracy is: 46.875% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 18099/ 43270], Loss: 2.0620, Accuracy: 0.531250\n",
            "The validation accuracy is: 46.09375% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 18199/ 43270], Loss: 2.6788, Accuracy: 0.468750\n",
            "The validation accuracy is: 45.3125% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 18299/ 43270], Loss: 2.1770, Accuracy: 0.515625\n",
            "The validation accuracy is: 39.0625% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 18399/ 43270], Loss: 2.1007, Accuracy: 0.515625\n",
            "The validation accuracy is: 39.84375% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 18499/ 43270], Loss: 2.1118, Accuracy: 0.453125\n",
            "The validation accuracy is: 46.09375% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 18599/ 43270], Loss: 2.4684, Accuracy: 0.429688\n",
            "The validation accuracy is: 42.96875% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 18699/ 43270], Loss: 1.7541, Accuracy: 0.531250\n",
            "The validation accuracy is: 45.3125% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 18799/ 43270], Loss: 2.0585, Accuracy: 0.460938\n",
            "The validation accuracy is: 45.3125% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 18899/ 43270], Loss: 2.3044, Accuracy: 0.468750\n",
            "The validation accuracy is: 46.875% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 18999/ 43270], Loss: 1.9514, Accuracy: 0.531250\n",
            "The validation accuracy is: 52.34375% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 19099/ 43270], Loss: 2.4814, Accuracy: 0.437500\n",
            "The validation accuracy is: 46.09375% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 19199/ 43270], Loss: 2.4972, Accuracy: 0.421875\n",
            "The validation accuracy is: 41.40625% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 19299/ 43270], Loss: 1.7993, Accuracy: 0.515625\n",
            "The validation accuracy is: 46.875% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 19399/ 43270], Loss: 2.2794, Accuracy: 0.460938\n",
            "The validation accuracy is: 43.75% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 19499/ 43270], Loss: 2.1402, Accuracy: 0.421875\n",
            "The validation accuracy is: 42.1875% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 19599/ 43270], Loss: 2.7453, Accuracy: 0.421875\n",
            "The validation accuracy is: 41.40625% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 19699/ 43270], Loss: 2.1537, Accuracy: 0.500000\n",
            "The validation accuracy is: 44.53125% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 19799/ 43270], Loss: 2.0381, Accuracy: 0.515625\n",
            "The validation accuracy is: 50.78125% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 19899/ 43270], Loss: 2.3622, Accuracy: 0.492188\n",
            "The validation accuracy is: 46.875% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 19999/ 43270], Loss: 2.2927, Accuracy: 0.445312\n",
            "The validation accuracy is: 51.5625% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 20099/ 43270], Loss: 2.5963, Accuracy: 0.414062\n",
            "The validation accuracy is: 48.4375% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 20199/ 43270], Loss: 2.1367, Accuracy: 0.500000\n",
            "The validation accuracy is: 42.1875% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 20299/ 43270], Loss: 2.5795, Accuracy: 0.453125\n",
            "The validation accuracy is: 47.65625% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 20399/ 43270], Loss: 2.4434, Accuracy: 0.492188\n",
            "The validation accuracy is: 46.875% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 20499/ 43270], Loss: 2.4508, Accuracy: 0.468750\n",
            "The validation accuracy is: 37.5% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 20599/ 43270], Loss: 2.6554, Accuracy: 0.406250\n",
            "The validation accuracy is: 40.625% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 20699/ 43270], Loss: 2.2717, Accuracy: 0.492188\n",
            "The validation accuracy is: 38.28125% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 20799/ 43270], Loss: 2.4635, Accuracy: 0.531250\n",
            "The validation accuracy is: 42.96875% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 20899/ 43270], Loss: 2.8955, Accuracy: 0.429688\n",
            "The validation accuracy is: 44.53125% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 20999/ 43270], Loss: 2.4183, Accuracy: 0.484375\n",
            "The validation accuracy is: 46.875% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 21099/ 43270], Loss: 2.0300, Accuracy: 0.539062\n",
            "The validation accuracy is: 41.40625% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 21199/ 43270], Loss: 2.4553, Accuracy: 0.453125\n",
            "The validation accuracy is: 43.75% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 21299/ 43270], Loss: 2.4865, Accuracy: 0.406250\n",
            "The validation accuracy is: 48.4375% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 21399/ 43270], Loss: 2.8282, Accuracy: 0.414062\n",
            "The validation accuracy is: 43.75% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 21499/ 43270], Loss: 2.5842, Accuracy: 0.460938\n",
            "The validation accuracy is: 41.40625% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 21599/ 43270], Loss: 2.3777, Accuracy: 0.484375\n",
            "The validation accuracy is: 38.28125% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 21699/ 43270], Loss: 2.9665, Accuracy: 0.390625\n",
            "The validation accuracy is: 36.71875% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 21799/ 43270], Loss: 2.5230, Accuracy: 0.460938\n",
            "The validation accuracy is: 50.78125% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 21899/ 43270], Loss: 2.5142, Accuracy: 0.492188\n",
            "The validation accuracy is: 48.4375% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 21999/ 43270], Loss: 2.6327, Accuracy: 0.476562\n",
            "The validation accuracy is: 45.3125% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 22099/ 43270], Loss: 2.1450, Accuracy: 0.492188\n",
            "The validation accuracy is: 41.40625% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 22199/ 43270], Loss: 1.9575, Accuracy: 0.476562\n",
            "The validation accuracy is: 48.4375% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 22299/ 43270], Loss: 2.6505, Accuracy: 0.414062\n",
            "The validation accuracy is: 38.28125% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 22399/ 43270], Loss: 2.4323, Accuracy: 0.445312\n",
            "The validation accuracy is: 37.5% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 22499/ 43270], Loss: 2.4526, Accuracy: 0.476562\n",
            "The validation accuracy is: 41.40625% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 22599/ 43270], Loss: 2.6530, Accuracy: 0.445312\n",
            "The validation accuracy is: 45.3125% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 22699/ 43270], Loss: 2.7792, Accuracy: 0.484375\n",
            "The validation accuracy is: 49.21875% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 22799/ 43270], Loss: 2.2189, Accuracy: 0.507812\n",
            "The validation accuracy is: 46.09375% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 22899/ 43270], Loss: 2.6216, Accuracy: 0.390625\n",
            "The validation accuracy is: 42.1875% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 22999/ 43270], Loss: 2.2608, Accuracy: 0.484375\n",
            "The validation accuracy is: 45.3125% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 23099/ 43270], Loss: 2.9075, Accuracy: 0.437500\n",
            "The validation accuracy is: 42.1875% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 23199/ 43270], Loss: 2.5877, Accuracy: 0.429688\n",
            "The validation accuracy is: 43.75% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 23299/ 43270], Loss: 2.7798, Accuracy: 0.445312\n",
            "The validation accuracy is: 50.0% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 23399/ 43270], Loss: 2.5829, Accuracy: 0.476562\n",
            "The validation accuracy is: 42.1875% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 23499/ 43270], Loss: 3.0000, Accuracy: 0.429688\n",
            "The validation accuracy is: 47.65625% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 23599/ 43270], Loss: 3.4782, Accuracy: 0.382812\n",
            "The validation accuracy is: 36.71875% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 23699/ 43270], Loss: 2.6509, Accuracy: 0.460938\n",
            "The validation accuracy is: 41.40625% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 23799/ 43270], Loss: 2.4045, Accuracy: 0.484375\n",
            "The validation accuracy is: 41.40625% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 23899/ 43270], Loss: 2.5451, Accuracy: 0.515625\n",
            "The validation accuracy is: 38.28125% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 23999/ 43270], Loss: 2.2345, Accuracy: 0.500000\n",
            "The validation accuracy is: 51.5625% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 24099/ 43270], Loss: 2.5462, Accuracy: 0.476562\n",
            "The validation accuracy is: 48.4375% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 24199/ 43270], Loss: 2.4780, Accuracy: 0.445312\n",
            "The validation accuracy is: 37.5% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 24299/ 43270], Loss: 2.2694, Accuracy: 0.500000\n",
            "The validation accuracy is: 47.65625% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 24399/ 43270], Loss: 2.8296, Accuracy: 0.445312\n",
            "The validation accuracy is: 42.96875% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 24499/ 43270], Loss: 2.8179, Accuracy: 0.414062\n",
            "The validation accuracy is: 51.5625% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 24599/ 43270], Loss: 2.2062, Accuracy: 0.484375\n",
            "The validation accuracy is: 50.78125% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 24699/ 43270], Loss: 2.8037, Accuracy: 0.398438\n",
            "The validation accuracy is: 53.90625% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 24799/ 43270], Loss: 2.4854, Accuracy: 0.492188\n",
            "The validation accuracy is: 48.4375% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 24899/ 43270], Loss: 2.2042, Accuracy: 0.500000\n",
            "The validation accuracy is: 46.09375% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 24999/ 43270], Loss: 3.2353, Accuracy: 0.390625\n",
            "The validation accuracy is: 42.1875% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 25099/ 43270], Loss: 2.6423, Accuracy: 0.343750\n",
            "The validation accuracy is: 50.78125% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 25199/ 43270], Loss: 3.6902, Accuracy: 0.351562\n",
            "The validation accuracy is: 37.5% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 25299/ 43270], Loss: 2.5666, Accuracy: 0.429688\n",
            "The validation accuracy is: 48.4375% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 25399/ 43270], Loss: 3.3174, Accuracy: 0.421875\n",
            "The validation accuracy is: 45.3125% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 25499/ 43270], Loss: 3.1483, Accuracy: 0.406250\n",
            "The validation accuracy is: 41.40625% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 25599/ 43270], Loss: 2.5206, Accuracy: 0.445312\n",
            "The validation accuracy is: 40.625% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 25699/ 43270], Loss: 2.0312, Accuracy: 0.570312\n",
            "The validation accuracy is: 43.75% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 25799/ 43270], Loss: 3.0897, Accuracy: 0.437500\n",
            "The validation accuracy is: 40.625% [128]\n",
            "Epoch: [ 3/ 5], Step: [ 25899/ 43270], Loss: 3.2592, Accuracy: 0.406250\n",
            "The validation accuracy is: 37.5% [128]\n",
            "The testing set accuracy is: 44.27392155305027% [138496]\n",
            "Epoch: [ 4/ 5], Step: [ 25999/ 43270], Loss: 2.1966, Accuracy: 0.492188\n",
            "The validation accuracy is: 39.84375% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 26099/ 43270], Loss: 1.8564, Accuracy: 0.539062\n",
            "The validation accuracy is: 45.3125% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 26199/ 43270], Loss: 1.9219, Accuracy: 0.507812\n",
            "The validation accuracy is: 46.09375% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 26299/ 43270], Loss: 1.8465, Accuracy: 0.546875\n",
            "The validation accuracy is: 42.1875% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 26399/ 43270], Loss: 2.2439, Accuracy: 0.476562\n",
            "The validation accuracy is: 43.75% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 26499/ 43270], Loss: 2.1220, Accuracy: 0.546875\n",
            "The validation accuracy is: 49.21875% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 26599/ 43270], Loss: 1.9738, Accuracy: 0.554688\n",
            "The validation accuracy is: 46.875% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 26699/ 43270], Loss: 2.0886, Accuracy: 0.531250\n",
            "The validation accuracy is: 45.3125% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 26799/ 43270], Loss: 2.0159, Accuracy: 0.546875\n",
            "The validation accuracy is: 50.0% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 26899/ 43270], Loss: 2.2647, Accuracy: 0.453125\n",
            "The validation accuracy is: 47.65625% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 26999/ 43270], Loss: 1.9164, Accuracy: 0.523438\n",
            "The validation accuracy is: 42.1875% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 27099/ 43270], Loss: 2.1421, Accuracy: 0.484375\n",
            "The validation accuracy is: 45.3125% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 27199/ 43270], Loss: 2.4027, Accuracy: 0.445312\n",
            "The validation accuracy is: 47.65625% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 27299/ 43270], Loss: 2.1286, Accuracy: 0.468750\n",
            "The validation accuracy is: 42.96875% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 27399/ 43270], Loss: 2.3090, Accuracy: 0.468750\n",
            "The validation accuracy is: 42.96875% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 27499/ 43270], Loss: 2.4697, Accuracy: 0.429688\n",
            "The validation accuracy is: 40.625% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 27599/ 43270], Loss: 2.5421, Accuracy: 0.453125\n",
            "The validation accuracy is: 56.25% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 27699/ 43270], Loss: 2.0991, Accuracy: 0.500000\n",
            "The validation accuracy is: 40.625% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 27799/ 43270], Loss: 2.4701, Accuracy: 0.453125\n",
            "The validation accuracy is: 46.875% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 27899/ 43270], Loss: 2.7825, Accuracy: 0.437500\n",
            "The validation accuracy is: 42.96875% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 27999/ 43270], Loss: 2.5381, Accuracy: 0.437500\n",
            "The validation accuracy is: 36.71875% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 28099/ 43270], Loss: 2.3418, Accuracy: 0.531250\n",
            "The validation accuracy is: 41.40625% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 28199/ 43270], Loss: 2.7122, Accuracy: 0.460938\n",
            "The validation accuracy is: 44.53125% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 28299/ 43270], Loss: 3.0259, Accuracy: 0.414062\n",
            "The validation accuracy is: 42.96875% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 28399/ 43270], Loss: 2.4675, Accuracy: 0.515625\n",
            "The validation accuracy is: 44.53125% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 28499/ 43270], Loss: 2.5090, Accuracy: 0.437500\n",
            "The validation accuracy is: 40.625% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 28599/ 43270], Loss: 2.3201, Accuracy: 0.468750\n",
            "The validation accuracy is: 40.625% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 28699/ 43270], Loss: 2.4201, Accuracy: 0.507812\n",
            "The validation accuracy is: 41.40625% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 28799/ 43270], Loss: 2.2930, Accuracy: 0.507812\n",
            "The validation accuracy is: 43.75% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 28899/ 43270], Loss: 2.0809, Accuracy: 0.562500\n",
            "The validation accuracy is: 50.0% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 28999/ 43270], Loss: 1.9762, Accuracy: 0.492188\n",
            "The validation accuracy is: 33.59375% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 29099/ 43270], Loss: 2.2823, Accuracy: 0.476562\n",
            "The validation accuracy is: 46.875% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 29199/ 43270], Loss: 1.9546, Accuracy: 0.531250\n",
            "The validation accuracy is: 36.71875% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 29299/ 43270], Loss: 2.4243, Accuracy: 0.453125\n",
            "The validation accuracy is: 38.28125% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 29399/ 43270], Loss: 2.3345, Accuracy: 0.453125\n",
            "The validation accuracy is: 40.625% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 29499/ 43270], Loss: 2.7368, Accuracy: 0.484375\n",
            "The validation accuracy is: 42.1875% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 29599/ 43270], Loss: 2.4468, Accuracy: 0.468750\n",
            "The validation accuracy is: 44.53125% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 29699/ 43270], Loss: 2.1521, Accuracy: 0.468750\n",
            "The validation accuracy is: 35.15625% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 29799/ 43270], Loss: 2.6374, Accuracy: 0.414062\n",
            "The validation accuracy is: 40.625% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 29899/ 43270], Loss: 2.3288, Accuracy: 0.468750\n",
            "The validation accuracy is: 47.65625% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 29999/ 43270], Loss: 2.3843, Accuracy: 0.484375\n",
            "The validation accuracy is: 46.875% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 30099/ 43270], Loss: 2.2864, Accuracy: 0.500000\n",
            "The validation accuracy is: 49.21875% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 30199/ 43270], Loss: 2.5278, Accuracy: 0.460938\n",
            "The validation accuracy is: 36.71875% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 30299/ 43270], Loss: 2.3739, Accuracy: 0.429688\n",
            "The validation accuracy is: 39.84375% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 30399/ 43270], Loss: 2.6110, Accuracy: 0.468750\n",
            "The validation accuracy is: 52.34375% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 30499/ 43270], Loss: 2.4188, Accuracy: 0.460938\n",
            "The validation accuracy is: 53.125% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 30599/ 43270], Loss: 2.7972, Accuracy: 0.445312\n",
            "The validation accuracy is: 43.75% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 30699/ 43270], Loss: 2.3762, Accuracy: 0.492188\n",
            "The validation accuracy is: 36.71875% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 30799/ 43270], Loss: 2.6241, Accuracy: 0.437500\n",
            "The validation accuracy is: 47.65625% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 30899/ 43270], Loss: 2.3923, Accuracy: 0.523438\n",
            "The validation accuracy is: 33.59375% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 30999/ 43270], Loss: 2.3378, Accuracy: 0.492188\n",
            "The validation accuracy is: 41.40625% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 31099/ 43270], Loss: 2.4915, Accuracy: 0.445312\n",
            "The validation accuracy is: 46.875% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 31199/ 43270], Loss: 2.8440, Accuracy: 0.296875\n",
            "The validation accuracy is: 42.96875% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 31299/ 43270], Loss: 2.4076, Accuracy: 0.453125\n",
            "The validation accuracy is: 41.40625% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 31399/ 43270], Loss: 3.0421, Accuracy: 0.390625\n",
            "The validation accuracy is: 49.21875% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 31499/ 43270], Loss: 2.5014, Accuracy: 0.453125\n",
            "The validation accuracy is: 47.65625% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 31599/ 43270], Loss: 2.6294, Accuracy: 0.445312\n",
            "The validation accuracy is: 44.53125% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 31699/ 43270], Loss: 2.7613, Accuracy: 0.445312\n",
            "The validation accuracy is: 41.40625% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 31799/ 43270], Loss: 2.6382, Accuracy: 0.468750\n",
            "The validation accuracy is: 39.0625% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 31899/ 43270], Loss: 2.9666, Accuracy: 0.468750\n",
            "The validation accuracy is: 44.53125% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 31999/ 43270], Loss: 2.5511, Accuracy: 0.414062\n",
            "The validation accuracy is: 41.40625% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 32099/ 43270], Loss: 2.0536, Accuracy: 0.500000\n",
            "The validation accuracy is: 53.125% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 32199/ 43270], Loss: 3.2026, Accuracy: 0.382812\n",
            "The validation accuracy is: 49.21875% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 32299/ 43270], Loss: 2.3746, Accuracy: 0.484375\n",
            "The validation accuracy is: 47.65625% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 32399/ 43270], Loss: 2.3972, Accuracy: 0.445312\n",
            "The validation accuracy is: 40.625% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 32499/ 43270], Loss: 2.5389, Accuracy: 0.453125\n",
            "The validation accuracy is: 43.75% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 32599/ 43270], Loss: 2.8759, Accuracy: 0.421875\n",
            "The validation accuracy is: 46.09375% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 32699/ 43270], Loss: 3.0535, Accuracy: 0.390625\n",
            "The validation accuracy is: 46.09375% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 32799/ 43270], Loss: 2.8583, Accuracy: 0.445312\n",
            "The validation accuracy is: 35.9375% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 32899/ 43270], Loss: 2.6917, Accuracy: 0.414062\n",
            "The validation accuracy is: 44.53125% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 32999/ 43270], Loss: 2.9301, Accuracy: 0.398438\n",
            "The validation accuracy is: 49.21875% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 33099/ 43270], Loss: 2.9624, Accuracy: 0.429688\n",
            "The validation accuracy is: 46.09375% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 33199/ 43270], Loss: 2.4888, Accuracy: 0.476562\n",
            "The validation accuracy is: 32.8125% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 33299/ 43270], Loss: 2.8936, Accuracy: 0.414062\n",
            "The validation accuracy is: 46.09375% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 33399/ 43270], Loss: 2.6076, Accuracy: 0.460938\n",
            "The validation accuracy is: 46.09375% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 33499/ 43270], Loss: 2.8240, Accuracy: 0.429688\n",
            "The validation accuracy is: 41.40625% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 33599/ 43270], Loss: 2.2936, Accuracy: 0.476562\n",
            "The validation accuracy is: 45.3125% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 33699/ 43270], Loss: 2.6768, Accuracy: 0.429688\n",
            "The validation accuracy is: 42.96875% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 33799/ 43270], Loss: 2.5939, Accuracy: 0.414062\n",
            "The validation accuracy is: 43.75% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 33899/ 43270], Loss: 2.6151, Accuracy: 0.468750\n",
            "The validation accuracy is: 47.65625% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 33999/ 43270], Loss: 3.0104, Accuracy: 0.351562\n",
            "The validation accuracy is: 43.75% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 34099/ 43270], Loss: 2.4859, Accuracy: 0.468750\n",
            "The validation accuracy is: 42.1875% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 34199/ 43270], Loss: 2.2970, Accuracy: 0.507812\n",
            "The validation accuracy is: 45.3125% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 34299/ 43270], Loss: 2.5115, Accuracy: 0.414062\n",
            "The validation accuracy is: 44.53125% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 34399/ 43270], Loss: 2.7240, Accuracy: 0.445312\n",
            "The validation accuracy is: 45.3125% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 34499/ 43270], Loss: 2.5942, Accuracy: 0.398438\n",
            "The validation accuracy is: 37.5% [128]\n",
            "Epoch: [ 4/ 5], Step: [ 34599/ 43270], Loss: 3.1090, Accuracy: 0.382812\n",
            "The validation accuracy is: 45.3125% [128]\n",
            "The testing set accuracy is: 43.520651726454% [138496]\n",
            "Epoch: [ 5/ 5], Step: [ 34699/ 43270], Loss: 2.1311, Accuracy: 0.515625\n",
            "The validation accuracy is: 48.4375% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 34799/ 43270], Loss: 1.7467, Accuracy: 0.500000\n",
            "The validation accuracy is: 44.53125% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 34899/ 43270], Loss: 1.8783, Accuracy: 0.515625\n",
            "The validation accuracy is: 45.3125% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 34999/ 43270], Loss: 2.1704, Accuracy: 0.507812\n",
            "The validation accuracy is: 43.75% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 35099/ 43270], Loss: 2.1265, Accuracy: 0.460938\n",
            "The validation accuracy is: 48.4375% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 35199/ 43270], Loss: 1.7903, Accuracy: 0.546875\n",
            "The validation accuracy is: 41.40625% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 35299/ 43270], Loss: 1.9109, Accuracy: 0.460938\n",
            "The validation accuracy is: 42.96875% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 35399/ 43270], Loss: 2.2521, Accuracy: 0.445312\n",
            "The validation accuracy is: 32.03125% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 35499/ 43270], Loss: 1.7113, Accuracy: 0.585938\n",
            "The validation accuracy is: 42.1875% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 35599/ 43270], Loss: 1.9056, Accuracy: 0.539062\n",
            "The validation accuracy is: 52.34375% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 35699/ 43270], Loss: 1.9468, Accuracy: 0.570312\n",
            "The validation accuracy is: 45.3125% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 35799/ 43270], Loss: 1.9053, Accuracy: 0.500000\n",
            "The validation accuracy is: 39.84375% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 35899/ 43270], Loss: 2.1121, Accuracy: 0.484375\n",
            "The validation accuracy is: 35.9375% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 35999/ 43270], Loss: 2.0001, Accuracy: 0.546875\n",
            "The validation accuracy is: 41.40625% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 36099/ 43270], Loss: 2.2279, Accuracy: 0.476562\n",
            "The validation accuracy is: 46.09375% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 36199/ 43270], Loss: 2.6135, Accuracy: 0.476562\n",
            "The validation accuracy is: 47.65625% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 36299/ 43270], Loss: 2.3076, Accuracy: 0.500000\n",
            "The validation accuracy is: 39.84375% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 36399/ 43270], Loss: 2.1487, Accuracy: 0.476562\n",
            "The validation accuracy is: 41.40625% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 36499/ 43270], Loss: 2.6993, Accuracy: 0.453125\n",
            "The validation accuracy is: 43.75% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 36599/ 43270], Loss: 2.2207, Accuracy: 0.492188\n",
            "The validation accuracy is: 38.28125% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 36699/ 43270], Loss: 2.3297, Accuracy: 0.515625\n",
            "The validation accuracy is: 46.09375% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 36799/ 43270], Loss: 2.3495, Accuracy: 0.500000\n",
            "The validation accuracy is: 47.65625% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 36899/ 43270], Loss: 2.6667, Accuracy: 0.437500\n",
            "The validation accuracy is: 45.3125% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 36999/ 43270], Loss: 2.4583, Accuracy: 0.453125\n",
            "The validation accuracy is: 46.09375% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 37099/ 43270], Loss: 2.4333, Accuracy: 0.476562\n",
            "The validation accuracy is: 42.96875% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 37199/ 43270], Loss: 2.4200, Accuracy: 0.507812\n",
            "The validation accuracy is: 42.96875% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 37299/ 43270], Loss: 2.3812, Accuracy: 0.421875\n",
            "The validation accuracy is: 43.75% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 37399/ 43270], Loss: 2.3475, Accuracy: 0.476562\n",
            "The validation accuracy is: 42.1875% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 37499/ 43270], Loss: 2.7310, Accuracy: 0.460938\n",
            "The validation accuracy is: 40.625% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 37599/ 43270], Loss: 2.3688, Accuracy: 0.445312\n",
            "The validation accuracy is: 50.78125% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 37699/ 43270], Loss: 2.2340, Accuracy: 0.539062\n",
            "The validation accuracy is: 47.65625% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 37799/ 43270], Loss: 2.8233, Accuracy: 0.460938\n",
            "The validation accuracy is: 41.40625% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 37899/ 43270], Loss: 2.3059, Accuracy: 0.453125\n",
            "The validation accuracy is: 47.65625% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 37999/ 43270], Loss: 2.3459, Accuracy: 0.460938\n",
            "The validation accuracy is: 47.65625% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 38099/ 43270], Loss: 2.1364, Accuracy: 0.515625\n",
            "The validation accuracy is: 46.875% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 38199/ 43270], Loss: 2.5715, Accuracy: 0.445312\n",
            "The validation accuracy is: 39.84375% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 38299/ 43270], Loss: 2.7081, Accuracy: 0.476562\n",
            "The validation accuracy is: 35.9375% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 38399/ 43270], Loss: 2.8300, Accuracy: 0.406250\n",
            "The validation accuracy is: 42.1875% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 38499/ 43270], Loss: 2.5458, Accuracy: 0.406250\n",
            "The validation accuracy is: 46.09375% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 38599/ 43270], Loss: 2.5039, Accuracy: 0.421875\n",
            "The validation accuracy is: 45.3125% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 38699/ 43270], Loss: 2.6081, Accuracy: 0.476562\n",
            "The validation accuracy is: 46.875% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 38799/ 43270], Loss: 2.4626, Accuracy: 0.453125\n",
            "The validation accuracy is: 40.625% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 38899/ 43270], Loss: 2.2593, Accuracy: 0.539062\n",
            "The validation accuracy is: 43.75% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 38999/ 43270], Loss: 2.0170, Accuracy: 0.500000\n",
            "The validation accuracy is: 44.53125% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 39099/ 43270], Loss: 2.2591, Accuracy: 0.523438\n",
            "The validation accuracy is: 48.4375% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 39199/ 43270], Loss: 2.6278, Accuracy: 0.398438\n",
            "The validation accuracy is: 45.3125% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 39299/ 43270], Loss: 2.1003, Accuracy: 0.492188\n",
            "The validation accuracy is: 39.0625% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 39399/ 43270], Loss: 2.1014, Accuracy: 0.515625\n",
            "The validation accuracy is: 51.5625% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 39499/ 43270], Loss: 2.3716, Accuracy: 0.453125\n",
            "The validation accuracy is: 35.15625% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 39599/ 43270], Loss: 2.7682, Accuracy: 0.453125\n",
            "The validation accuracy is: 36.71875% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 39699/ 43270], Loss: 2.3280, Accuracy: 0.468750\n",
            "The validation accuracy is: 40.625% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 39799/ 43270], Loss: 1.8995, Accuracy: 0.500000\n",
            "The validation accuracy is: 41.40625% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 39899/ 43270], Loss: 2.3450, Accuracy: 0.437500\n",
            "The validation accuracy is: 40.625% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 39999/ 43270], Loss: 2.4234, Accuracy: 0.468750\n",
            "The validation accuracy is: 45.3125% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 40099/ 43270], Loss: 2.4468, Accuracy: 0.453125\n",
            "The validation accuracy is: 44.53125% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 40199/ 43270], Loss: 2.7137, Accuracy: 0.375000\n",
            "The validation accuracy is: 49.21875% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 40299/ 43270], Loss: 2.3281, Accuracy: 0.484375\n",
            "The validation accuracy is: 42.1875% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 40399/ 43270], Loss: 3.1677, Accuracy: 0.414062\n",
            "The validation accuracy is: 36.71875% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 40499/ 43270], Loss: 3.0722, Accuracy: 0.367188\n",
            "The validation accuracy is: 43.75% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 40599/ 43270], Loss: 2.2622, Accuracy: 0.484375\n",
            "The validation accuracy is: 42.96875% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 40699/ 43270], Loss: 2.3056, Accuracy: 0.507812\n",
            "The validation accuracy is: 42.1875% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 40799/ 43270], Loss: 2.7836, Accuracy: 0.453125\n",
            "The validation accuracy is: 41.40625% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 40899/ 43270], Loss: 2.5483, Accuracy: 0.453125\n",
            "The validation accuracy is: 43.75% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 40999/ 43270], Loss: 2.6004, Accuracy: 0.406250\n",
            "The validation accuracy is: 41.40625% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 41099/ 43270], Loss: 2.3018, Accuracy: 0.492188\n",
            "The validation accuracy is: 42.96875% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 41199/ 43270], Loss: 2.8466, Accuracy: 0.414062\n",
            "The validation accuracy is: 40.625% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 41299/ 43270], Loss: 2.8022, Accuracy: 0.421875\n",
            "The validation accuracy is: 44.53125% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 41399/ 43270], Loss: 2.7640, Accuracy: 0.445312\n",
            "The validation accuracy is: 44.53125% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 41499/ 43270], Loss: 2.4750, Accuracy: 0.468750\n",
            "The validation accuracy is: 39.0625% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 41599/ 43270], Loss: 2.9182, Accuracy: 0.453125\n",
            "The validation accuracy is: 38.28125% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 41699/ 43270], Loss: 3.0206, Accuracy: 0.437500\n",
            "The validation accuracy is: 40.625% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 41799/ 43270], Loss: 2.6799, Accuracy: 0.414062\n",
            "The validation accuracy is: 51.5625% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 41899/ 43270], Loss: 2.2385, Accuracy: 0.421875\n",
            "The validation accuracy is: 41.40625% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 41999/ 43270], Loss: 2.8303, Accuracy: 0.437500\n",
            "The validation accuracy is: 30.46875% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 42099/ 43270], Loss: 2.8665, Accuracy: 0.406250\n",
            "The validation accuracy is: 35.15625% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 42199/ 43270], Loss: 2.9699, Accuracy: 0.421875\n",
            "The validation accuracy is: 41.40625% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 42299/ 43270], Loss: 2.5924, Accuracy: 0.414062\n",
            "The validation accuracy is: 42.1875% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 42399/ 43270], Loss: 2.5043, Accuracy: 0.414062\n",
            "The validation accuracy is: 43.75% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 42499/ 43270], Loss: 3.0698, Accuracy: 0.429688\n",
            "The validation accuracy is: 44.53125% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 42599/ 43270], Loss: 2.8247, Accuracy: 0.421875\n",
            "The validation accuracy is: 42.1875% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 42699/ 43270], Loss: 2.7694, Accuracy: 0.468750\n",
            "The validation accuracy is: 39.0625% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 42799/ 43270], Loss: 2.6005, Accuracy: 0.437500\n",
            "The validation accuracy is: 39.0625% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 42899/ 43270], Loss: 3.0986, Accuracy: 0.390625\n",
            "The validation accuracy is: 42.1875% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 42999/ 43270], Loss: 2.8108, Accuracy: 0.437500\n",
            "The validation accuracy is: 48.4375% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 43099/ 43270], Loss: 3.5747, Accuracy: 0.382812\n",
            "The validation accuracy is: 45.3125% [128]\n",
            "Epoch: [ 5/ 5], Step: [ 43199/ 43270], Loss: 2.4480, Accuracy: 0.476562\n",
            "The validation accuracy is: 41.40625% [128]\n",
            "The testing set accuracy is: 43.6087619075132% [138496]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IaDB5HDp9kEb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Transfer learning on validation data"
      ]
    },
    {
      "metadata": {
        "id": "pfZ0Vbtu9kCi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "QmLrqYrnn79s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "673a8b94-8473-40b7-a5bf-6d9cca498b3a"
      },
      "cell_type": "code",
      "source": [
        "from functools import reduce\n",
        "from google.colab import files\n",
        "import datetime\n",
        "#files.upload()\n",
        "\n",
        "# gather number of categories\n",
        "num_fine_classes = category_size\n",
        "num_coarse_classes = subcategory_size\n",
        "\n",
        "#Seed\n",
        "torch.manual_seed(0)\n",
        "\n",
        "#Settings\n",
        "max_seq_len = 256\n",
        "dim_embedding = 50\n",
        "num_heads = 5\n",
        "num_encoder_layers = 6\n",
        "ff_num_features = 1024\n",
        "vocab_size = count_lines('./cis700project/cis700/vocab/bert-base-uncased-vocab.txt')\n",
        "model = Classifier(vocab_size, dim_embedding, num_heads,\n",
        "                   ff_num_features, num_encoder_layers, \n",
        "                   max_seq_len, num_fine_classes)\n",
        "#checkpoint = torch.load('transformer-s256-e50-h5-l6.epoch-0.step-8654.pth')\n",
        "checkpoint = torch.load('/content/drive/My Drive/transformer-fine-s256-e50-h5-l6.epoch-9.step-221540.pth')\n",
        "model.load_state_dict(checkpoint)\n",
        "model.eval()\n",
        "\n",
        "total_params = sum([param.nelement() for param in model.parameters()])\n",
        "train_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(\"Original model trainable params %s/%s\" % (train_params, total_params))\n",
        "\n",
        "new_model = model\n",
        "for param in new_model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "feature_cnt = new_model.fc.in_features\n",
        "new_model.fc = torch.nn.Linear(feature_cnt, num_coarse_classes)\n",
        "#print(num_coarse_classes)\n",
        "total_params = sum([param.nelement() for param in new_model.parameters()])\n",
        "train_params = sum(p.numel() for p in new_model.parameters() if p.requires_grad)\n",
        "print(\"New model trainable params %s/%s\" % (train_params, total_params))\n",
        "\n",
        "\n",
        "#Hyperparameters\n",
        "batch_size = 128\n",
        "num_epochs = 10\n",
        "lr = 1e-4\n",
        "\n",
        "network_name = 'transformer-s%d-e%d-h%d-l%d' % (max_seq_len, dim_embedding, num_heads, num_encoder_layers)\n",
        "\n",
        "\n",
        "now = time.mktime(datetime.datetime.now().timetuple())\n",
        "logger = Logger(f'./logs/Transformer_transfer_valset_{now}/')\n",
        "\n",
        "# gather number of categories\n",
        "num_fine_classes = category_size\n",
        "num_coarse_classes = subcategory_size\n",
        "\n",
        "#Seed\n",
        "torch.manual_seed(0)\n",
        "\n",
        "\n",
        "text_dataset = AbstractDataset()\n",
        "lengths = [int(len(text_dataset)*0.8), int(len(text_dataset)*0.1), int(len(text_dataset)) - \n",
        "           int(len(text_dataset)*0.8) - int(len(text_dataset)*0.1)]\n",
        "text_dataset_train, text_dataset_val, text_dataset_test = torch.utils.data.random_split(text_dataset, lengths)\n",
        "\n",
        "#New seed\n",
        "torch.manual_seed(99)\n",
        "\n",
        "loader_train = torch.utils.data.DataLoader(text_dataset_val,shuffle=True, batch_size=batch_size, collate_fn=collate_fn,num_workers=3,pin_memory=True)\n",
        "loader_test = torch.utils.data.DataLoader(text_dataset_test,shuffle=True, batch_size=batch_size, collate_fn=collate_fn,num_workers=3,pin_memory=True)\n",
        "torch.backends.cudnn.enabled = True\n",
        "\n",
        "new_model = new_model.cuda()\n",
        "\n",
        "#Loss and optimizer\n",
        "loss_fun = torch.nn.CrossEntropyLoss() \n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "def evaluate():     \n",
        "  #Get testing data\n",
        "  get_data_step = iter(loader_test)\n",
        "  epoch_length = len(loader_test)\n",
        "\n",
        "  model.eval()\n",
        "  count_correct = 0\n",
        "  count_total = 0\n",
        "  with torch.no_grad():\n",
        "    for test_step in range(epoch_length):\n",
        "      abstract, mask, subcategory, category = next(get_data_step)\n",
        "\n",
        "      abstract = abstract.to(device)\n",
        "      subcategory = subcategory.to(device)\n",
        "      category = category.to(device)\n",
        "      mask = mask.to(device)\n",
        "\n",
        "      result = new_model(abstract, mask)\n",
        "      _, argmax = torch.max(result, 1)\n",
        "      count_total += subcategory.size(0)\n",
        "      count_correct += (argmax == subcategory).sum().item()\n",
        "\n",
        "  print('The testing set accuracy is: %s%% [%s]' % (count_correct/count_total * 100,epoch_length * batch_size))  \n",
        "  model.train()\n",
        "\n",
        "#Training loop\n",
        "new_model.train()\n",
        "num_train_steps = 0\n",
        "for epoch in range(num_epochs):\n",
        "    #Get an epoch\n",
        "    get_data_step = iter(loader_train)\n",
        "    epoch_length = len(loader_train)\n",
        "    for train_step in range(epoch_length):\n",
        "      #start = time.time()\n",
        "      num_train_steps += 1\n",
        "      \n",
        "      abstract, mask, subcategory, category = next(get_data_step)\n",
        "      #print(abstract)\n",
        "      abstract = abstract.to(device)\n",
        "      subcategory = subcategory.to(device)\n",
        "      category = category.to(device)\n",
        "      mask = mask.to(device)\n",
        "    \n",
        "      # Do a forward pass\n",
        "      #start = time.time()\n",
        "      result = new_model(abstract, mask)\n",
        "      #end = time.time()\n",
        "      loss = loss_fun(result, subcategory)\n",
        "    \n",
        "      # Now backpropagate\n",
        "      optimizer.zero_grad()\n",
        "      #start = time.time()\n",
        "      loss.backward()\n",
        "      #end = time.time()\n",
        "      \n",
        "      optimizer.step()\n",
        "\n",
        "      # Find the accuracy\n",
        "      _, argmax = torch.max(result,1)\n",
        "      accuracy = (subcategory == argmax).float().mean()\n",
        "      \n",
        "      #Print\n",
        "      if (num_train_steps + 1) % 100 == 0: \n",
        "        print('Epoch: [% d/% d], Step: [% d/% d], Loss: %.4f, Accuracy: %4f'\n",
        "          % (epoch + 1, num_epochs, num_train_steps, len(loader_train) * num_epochs, loss.item(), accuracy.item())) \n",
        "      #print(torch.cuda.memory_allocated(device))\n",
        "      #print(torch.cuda.memory_cached(device))\n",
        "      end = time.time()\n",
        "      #print(end-start)\n",
        "      del abstract, mask, subcategory, category, result, argmax\n",
        "      torch.cuda.empty_cache()\n",
        "      \n",
        "      if num_train_steps % 1 == 0:  \n",
        "        #Tensorboard logging\n",
        "        to_log = {'loss': loss.item(), 'accuracy': accuracy.item()}\n",
        "        for handle, val in to_log.items():\n",
        "            logger.scalar_summary(handle, val, num_train_steps+1)\n",
        "            \n",
        "    evaluate()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original model trainable params 6945814/6945814\n",
            "New model trainable params 2304180/4513624\n",
            "Epoch: [ 1/ 10], Step: [ 99/ 10820], Loss: 3.0839, Accuracy: 0.335938\n",
            "Epoch: [ 1/ 10], Step: [ 199/ 10820], Loss: 2.6236, Accuracy: 0.367188\n",
            "Epoch: [ 1/ 10], Step: [ 299/ 10820], Loss: 2.3976, Accuracy: 0.382812\n",
            "Epoch: [ 1/ 10], Step: [ 399/ 10820], Loss: 2.1420, Accuracy: 0.445312\n",
            "Epoch: [ 1/ 10], Step: [ 499/ 10820], Loss: 2.1794, Accuracy: 0.406250\n",
            "Epoch: [ 1/ 10], Step: [ 599/ 10820], Loss: 2.4794, Accuracy: 0.335938\n",
            "Epoch: [ 1/ 10], Step: [ 699/ 10820], Loss: 2.2558, Accuracy: 0.398438\n",
            "Epoch: [ 1/ 10], Step: [ 799/ 10820], Loss: 1.9127, Accuracy: 0.507812\n",
            "Epoch: [ 1/ 10], Step: [ 899/ 10820], Loss: 2.2455, Accuracy: 0.414062\n",
            "Epoch: [ 1/ 10], Step: [ 999/ 10820], Loss: 2.2568, Accuracy: 0.429688\n",
            "The testing set accuracy is: 43.02737915544225% [138496]\n",
            "Epoch: [ 2/ 10], Step: [ 1099/ 10820], Loss: 1.9046, Accuracy: 0.414062\n",
            "Epoch: [ 2/ 10], Step: [ 1199/ 10820], Loss: 2.1155, Accuracy: 0.453125\n",
            "Epoch: [ 2/ 10], Step: [ 1299/ 10820], Loss: 1.8212, Accuracy: 0.445312\n",
            "Epoch: [ 2/ 10], Step: [ 1399/ 10820], Loss: 1.6328, Accuracy: 0.523438\n",
            "Epoch: [ 2/ 10], Step: [ 1499/ 10820], Loss: 1.9848, Accuracy: 0.421875\n",
            "Epoch: [ 2/ 10], Step: [ 1599/ 10820], Loss: 1.9814, Accuracy: 0.429688\n",
            "Epoch: [ 2/ 10], Step: [ 1699/ 10820], Loss: 1.9190, Accuracy: 0.500000\n",
            "Epoch: [ 2/ 10], Step: [ 1799/ 10820], Loss: 1.7525, Accuracy: 0.460938\n",
            "Epoch: [ 2/ 10], Step: [ 1899/ 10820], Loss: 1.6169, Accuracy: 0.539062\n",
            "Epoch: [ 2/ 10], Step: [ 1999/ 10820], Loss: 1.8784, Accuracy: 0.468750\n",
            "Epoch: [ 2/ 10], Step: [ 2099/ 10820], Loss: 2.0159, Accuracy: 0.390625\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}