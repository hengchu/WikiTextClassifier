{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final_project_LSTM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "nOSjNL93MfM5",
        "colab_type": "code",
        "outputId": "e95eda41-b222-4719-c03f-82e7b562f272",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "#For data files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "p0aCWGMzCgK1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "0ee70bb4-250f-49df-9b44-30b90bb8b63e"
      },
      "cell_type": "code",
      "source": [
        "#Also clone final project repo\n",
        "!git clone https://github.com/huggingface/pytorch-pretrained-BERT/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'cis700project'...\n",
            "remote: Enumerating objects: 68, done.\u001b[K\n",
            "remote: Counting objects: 100% (68/68), done.\u001b[K\n",
            "remote: Compressing objects: 100% (40/40), done.\u001b[K\n",
            "remote: Total 68 (delta 33), reused 53 (delta 22), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (68/68), done.\n",
            "Cloning into 'pytorch-pretrained-BERT'...\n",
            "remote: Enumerating objects: 1, done.\u001b[K\n",
            "remote: Counting objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 3120 (delta 0), reused 0 (delta 0), pack-reused 3119\u001b[K\n",
            "Receiving objects: 100% (3120/3120), 1.39 MiB | 10.32 MiB/s, done.\n",
            "Resolving deltas: 100% (2145/2145), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SF7gM7XNstK1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Tensorboard\n",
        "\n",
        "LOG_DIR = './logs'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "\n",
        "!if [ -f ngrok ] ; then echo \"Ngrok already installed\" ; else wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip > /dev/null 2>&1 && unzip ngrok-stable-linux-amd64.zip > /dev/null 2>&1 ; fi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wiha2Qseywal",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "15e8b532-cb72-40ea-f47b-82e12806c2a0"
      },
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print('Tensorboard Link: ' +str(json.load(sys.stdin)['tunnels'][0]['public_url']))\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorboard Link: https://de400e78.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VBv8-wBzy0CI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Code referenced from https://gist.github.com/gyglim/1f8dfb1b5c82627ae3efcfbbadb9f514\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import scipy.misc \n",
        "try:\n",
        "    from StringIO import StringIO  # Python 2.7\n",
        "except ImportError:\n",
        "    from io import BytesIO         # Python 3.x\n",
        "\n",
        "\n",
        "class Logger(object):\n",
        "    \n",
        "    def __init__(self, log_dir):\n",
        "        \"\"\"Create a summary writer logging to log_dir.\"\"\"\n",
        "        self.writer = tf.summary.FileWriter(log_dir)\n",
        "\n",
        "    def scalar_summary(self, tag, value, step):\n",
        "        \"\"\"Log a scalar variable.\"\"\"\n",
        "        summary = tf.Summary(value=[tf.Summary.Value(tag=tag, simple_value=value)])\n",
        "        self.writer.add_summary(summary, step)\n",
        "\n",
        "    def image_summary(self, tag, images, step):\n",
        "        \"\"\"Log a list of images.\"\"\"\n",
        "\n",
        "        img_summaries = []\n",
        "        for i, img in enumerate(images):\n",
        "            # Write the image to a string\n",
        "            try:\n",
        "                s = StringIO()\n",
        "            except:\n",
        "                s = BytesIO()\n",
        "            scipy.misc.toimage(img).save(s, format=\"png\")\n",
        "\n",
        "            # Create an Image object\n",
        "            img_sum = tf.Summary.Image(encoded_image_string=s.getvalue(),\n",
        "                                       height=img.shape[0],\n",
        "                                       width=img.shape[1])\n",
        "            # Create a Summary value\n",
        "            img_summaries.append(tf.Summary.Value(tag='%s/%d' % (tag, i), image=img_sum))\n",
        "\n",
        "        # Create and write Summary\n",
        "        summary = tf.Summary(value=img_summaries)\n",
        "        self.writer.add_summary(summary, step)\n",
        "        \n",
        "    def histo_summary(self, tag, values, step, bins=1000):\n",
        "        \"\"\"Log a histogram of the tensor of values.\"\"\"\n",
        "\n",
        "        # Create a histogram using numpy\n",
        "        counts, bin_edges = np.histogram(values, bins=bins)\n",
        "\n",
        "        # Fill the fields of the histogram proto\n",
        "        hist = tf.HistogramProto()\n",
        "        hist.min = float(np.min(values))\n",
        "        hist.max = float(np.max(values))\n",
        "        hist.num = int(np.prod(values.shape))\n",
        "        hist.sum = float(np.sum(values))\n",
        "        hist.sum_squares = float(np.sum(values**2))\n",
        "\n",
        "        # Drop the start of the first bin\n",
        "        bin_edges = bin_edges[1:]\n",
        "\n",
        "        # Add bin edges and counts\n",
        "        for edge in bin_edges:\n",
        "            hist.bucket_limit.append(edge)\n",
        "        for c in counts:\n",
        "            hist.bucket.append(c)\n",
        "\n",
        "        # Create and write Summary\n",
        "        summary = tf.Summary(value=[tf.Summary.Value(tag=tag, histo=hist)])\n",
        "        self.writer.add_summary(summary, step)\n",
        "        self.writer.flush()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_HEVfmCVy2mI",
        "colab_type": "code",
        "outputId": "7475aef2-05f3-4644-a537-b5c7e273522a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "cell_type": "code",
      "source": [
        "## Required packages\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "!pip3 install https://download.pytorch.org/whl/cu100/torch-1.0.1-cp36-cp36m-linux_x86_64.whl\n",
        "!pip3 install torchvision\n",
        "  \n",
        "import torch\n",
        "device =  torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==1.0.1 from https://download.pytorch.org/whl/cu100/torch-1.0.1-cp36-cp36m-linux_x86_64.whl\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu100/torch-1.0.1-cp36-cp36m-linux_x86_64.whl (614.8MB)\n",
            "\u001b[K    100% |████████████████████████████████| 614.8MB 24kB/s \n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "  Found existing installation: torch 1.0.1.post2\n",
            "    Uninstalling torch-1.0.1.post2:\n",
            "      Successfully uninstalled torch-1.0.1.post2\n",
            "Successfully installed torch-1.0.1\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.2.post3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.16.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.0.1)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n",
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uFnR5yqbRHzZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "61d22c4b-03f1-41d4-9e9b-28c7204126e9"
      },
      "cell_type": "code",
      "source": [
        "subcategory_size = 0\n",
        "subcategory2id = {}\n",
        "with open('/content/drive/My Drive/supercatstats.csv', 'r') as f:\n",
        "  # build stats\n",
        "  for index,line in enumerate(f):\n",
        "    subcategory2id[line.split(',')[0]]=subcategory_size\n",
        "    subcategory_size += 1\n",
        "    \n",
        "print(subcategory_size)\n",
        "\n",
        "category_size = 0\n",
        "category2id = {}\n",
        "with open('/content/drive/My Drive/catstats.csv', 'r') as f:\n",
        "  # build stats\n",
        "  for index,line in enumerate(f):\n",
        "    category2id[line.split(',')[0]]=category_size\n",
        "    category_size += 1\n",
        "    \n",
        "print(category_size)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "180\n",
            "370\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EvZacJXC14ZL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import linecache\n",
        "import torch.utils.data as data\n",
        "import re\n",
        "import sys\n",
        "sys.path.insert(0, './cis700project')\n",
        "sys.path.insert(0, './pytorch-pretrained-BERT')\n",
        "from cis700 import tokenizer\n",
        "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
        "\n",
        "def build_tokenizer():\n",
        "    tokenizer = BertTokenizer('./cis700project/cis700/vocab/bert-base-uncased-vocab.txt')\n",
        "    return tokenizer\n",
        "\n",
        "tok = build_tokenizer()\n",
        "\n",
        "class AbstractDataset(data.Dataset):\n",
        "  \"\"\"Abstract dataset.\"\"\"\n",
        "\n",
        "  def __init__(self, file = \"joinedlonabstract_en.nt\", root_dir = \"/content/drive/My Drive\"):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      csv_file (string): Path to the nt file.\n",
        "      root_dir (string): Directory with all the images.\n",
        "    \"\"\"\n",
        "    temp = linecache.getline(root_dir + '/' + file, 1)\n",
        "    self.fullfile = open(root_dir + '/' + file).readlines()\n",
        "    self.fullfile_len = len(self.fullfile)\n",
        "    self.root_dir = root_dir\n",
        "    self.category2id = category2id\n",
        "    self.subcategory2id = subcategory2id\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.fullfile_len\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    #line = linecache.getline(self.root_dir + '/' + self.file, index + 1)\n",
        "    line = self.fullfile[index]\n",
        "    match = re.findall(r'(<http://dbpedia.org/[^<]+)', line)\n",
        "    category = match[2].replace('<http://dbpedia.org/resource/Category:','').replace('>','').replace('\\n','').strip()\n",
        "    subcategory = match[3].replace('<http://dbpedia.org/resource/Category:','').replace('>','').replace('\\n','').strip()\n",
        "    abstract = match[1].replace('<http://dbpedia.org/property/abstract> \"','').replace('\"@en .',\"\").replace('\\n','').strip()\n",
        "    tokens = tok.tokenize(abstract)\n",
        "    if len(tokens) > 256:\n",
        "      tokens = tokens[:256]\n",
        "    ids = tok.convert_tokens_to_ids(tokens)\n",
        "    #print(ids)\n",
        "    #print(self.category2id[category])\n",
        "    return torch.Tensor(ids), torch.tensor(self.subcategory2id[subcategory]), torch.tensor(self.category2id[category]) \n",
        "\n",
        "  \n",
        "def collate_fn(data): \n",
        "    #Adapted from https://github.com/yunjey/seq2seq-dataloader/blob/master/data_loader.py\n",
        "    \"\"\"Creates mini-batch tensors from the list of tuples (src_seq, labels).\n",
        "    We should build a custom collate_fn rather than using default collate_fn,\n",
        "    because merging sequences (including padding) is not supported in default.\n",
        "    Seqeuences are padded to the maximum length of mini-batch sequences (dynamic padding).\n",
        "    Args:\n",
        "        data: list of tuple (src_seq, labels).\n",
        "            - src_seq: torch tensor of shape (?); variable length.\n",
        "            - subcategory: non-one-hot encoded labels\n",
        "            - category\n",
        "    Returns:\n",
        "        src_seqs: torch tensor of shape (batch_size, padded_length).\n",
        "        src_lengths: list of length (batch_size); valid length for each padded source sequence.\n",
        "    \"\"\"\n",
        "    def merge(sequences):\n",
        "        lengths = [len(seq) for seq in sequences]\n",
        "        padded_seqs = torch.zeros(len(sequences), max(lengths)).long()\n",
        "        for i, seq in enumerate(sequences):\n",
        "            end = lengths[i]\n",
        "            padded_seqs[i, :end] = seq[:end]\n",
        "        return padded_seqs, lengths\n",
        "\n",
        "    # sort a list by sequence length (descending order) to use pack_padded_sequence\n",
        "    data.sort(key=lambda x: len(x[0]), reverse=True)\n",
        "\n",
        "    # seperate source and target sequences\n",
        "    src_seqs,subcategory, category = zip(*data)\n",
        "\n",
        "    # merge sequences (from tuple of 1D tensor to 2D tensor)\n",
        "    src_seqs, src_lengths = merge(src_seqs)\n",
        "\n",
        "    return src_seqs, src_lengths,torch.stack(subcategory),torch.stack(category)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A3Zev3JWK3uN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6035
        },
        "outputId": "6e246924-b263-4a71-990f-340e3deb3a83"
      },
      "cell_type": "code",
      "source": [
        "import time, datetime\n",
        "import torch.nn as nn\n",
        "\n",
        "now = time.mktime(datetime.datetime.now().timetuple())\n",
        "logger = Logger(f'./logs/biLSTM_{now}/')\n",
        "logger_val = Logger(f'./logs/biLSTM_eval_{now}/')\n",
        "\n",
        "#Hyperparameters\n",
        "batch_size = 512\n",
        "num_epochs = 8\n",
        "learning_rate = 3e-3\n",
        "\n",
        "#Seed\n",
        "torch.manual_seed(0)\n",
        "\n",
        "text_dataset = AbstractDataset()\n",
        "lengths = [int(len(text_dataset)*0.8), int(len(text_dataset)*0.1), int(len(text_dataset)) - \n",
        "           int(len(text_dataset)*0.8) - int(len(text_dataset)*0.1)]\n",
        "text_dataset_train, text_dataset_val, text_dataset_test = torch.utils.data.random_split(text_dataset, lengths)\n",
        "\n",
        "loader_train = torch.utils.data.DataLoader(text_dataset_train,shuffle=True, batch_size=batch_size, collate_fn=collate_fn,num_workers=3,pin_memory=True)\n",
        "loader_test = torch.utils.data.DataLoader(text_dataset_test,shuffle=True, batch_size=batch_size, collate_fn=collate_fn,num_workers=3,pin_memory=True)\n",
        "torch.backends.cudnn.enabled = False\n",
        "\n",
        "# Bidirectional recurrent neural network (many-to-one)\n",
        "class BiLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(BiLSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.embed = nn.Embedding(30522, input_size)\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Linear(hidden_size*2, num_classes)  # 2 for bidirection\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # Set initial states\n",
        "        #h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device) # 2 for bidirection \n",
        "        #c0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device)\n",
        "        \n",
        "        #Embed\n",
        "        x = self.embed(x)\n",
        "        \n",
        "        # Forward propagate LSTM\n",
        "        x, _ = self.lstm(x)  # out: tensor of shape (batch_size, seq_length, hidden_size*2)\n",
        "        \n",
        "        # Decode the hidden state of the last time step\n",
        "        x = self.fc(x[:, -1, :])\n",
        "        return x\n",
        "\n",
        "model = BiLSTM(input_size=50, hidden_size=100, num_layers=1, num_classes=category_size).to(device)\n",
        "\n",
        "#Loss and optimizer\n",
        "loss_fun = torch.nn.CrossEntropyLoss() \n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "\n",
        "def validate(num_train_steps):     \n",
        "  #Get validation data\n",
        "  rand_sampler = torch.utils.data.RandomSampler(text_dataset_val, num_samples=batch_size, replacement=True)\n",
        "  loader_val = torch.utils.data.DataLoader(text_dataset_val, batch_size=batch_size, collate_fn=collate_fn,num_workers=3,pin_memory=True, sampler=rand_sampler)\n",
        "  get_data_step = iter(loader_val)\n",
        "  model.eval()\n",
        "  count_correct = 0\n",
        "  count_total = 0\n",
        "  with torch.no_grad():\n",
        "    abstract, abstract_lengths, subcategory, category = next(get_data_step)\n",
        "\n",
        "    abstract = abstract.to(device)\n",
        "    subcategory = subcategory.to(device)\n",
        "    category = category.to(device)\n",
        "\n",
        "    result = model(abstract)\n",
        "    loss = loss_fun(result, category)\n",
        "    _, argmax = torch.max(result, 1)\n",
        "    count_total += category.size(0)\n",
        "    count_correct += (argmax == category).sum().item()\n",
        "    accuracy = (category == argmax).float().mean()\n",
        "  \n",
        "    #Tensorboard logging\n",
        "    to_log = {'loss': loss.item(), 'accuracy': accuracy.item()}\n",
        "    for handle, val in to_log.items():\n",
        "      logger_val.scalar_summary(handle, val, num_train_steps+1)\n",
        "\n",
        "  print('The validation accuracy is: %s%% [%s]' % (count_correct/count_total * 100,batch_size))  \n",
        "  model.train()\n",
        "\n",
        "def evaluate():     \n",
        "  #Get testing data\n",
        "  get_data_step = iter(loader_test)\n",
        "  epoch_length = len(loader_test)\n",
        "\n",
        "  model.eval()\n",
        "  count_correct = 0\n",
        "  count_total = 0\n",
        "  with torch.no_grad():\n",
        "    for test_step in range(epoch_length):\n",
        "      abstract, abstract_lengths, subcategory, category = next(get_data_step)\n",
        "\n",
        "      abstract = abstract.to(device)\n",
        "      subcategory = subcategory.to(device)\n",
        "      category = category.to(device)\n",
        "\n",
        "      result = model(abstract)\n",
        "      _, argmax = torch.max(result, 1)\n",
        "      count_total += category.size(0)\n",
        "      count_correct += (argmax == category).sum().item()\n",
        "\n",
        "  print('The testing set accuracy is: %s%% [%s]' % (count_correct/count_total * 100,epoch_length * batch_size))  \n",
        "  model.train()\n",
        "  \n",
        "#Training loop\n",
        "model.train()\n",
        "num_train_steps = 0\n",
        "for epoch in range(num_epochs):\n",
        "    #Get an epoch\n",
        "    get_data_step = iter(loader_train)\n",
        "    epoch_length = len(loader_train)\n",
        "    for train_step in range(epoch_length):\n",
        "      #start = time.time()\n",
        "      num_train_steps += 1\n",
        "      \n",
        "      abstract, abstract_lengths, subcategory, category = next(get_data_step)\n",
        "      #print(abstract.size())\n",
        "      abstract = abstract.to(device)\n",
        "      subcategory = subcategory.to(device)\n",
        "      category = category.to(device)\n",
        "    \n",
        "      # Do a forward pass\n",
        "      #start = time.time()\n",
        "      result = model(abstract)\n",
        "      #end = time.time()\n",
        "      loss = loss_fun(result, category)\n",
        "    \n",
        "      # Now backpropagate\n",
        "      optimizer.zero_grad()\n",
        "      #start = time.time()\n",
        "      loss.backward()\n",
        "      #end = time.time()\n",
        "      \n",
        "      optimizer.step()\n",
        "\n",
        "      # Find the accuracy\n",
        "      _, argmax = torch.max(result,1)\n",
        "      accuracy = (category == argmax).float().mean()\n",
        "      \n",
        "      #Print\n",
        "      if (num_train_steps + 1) % 100 == 0: \n",
        "        print('Epoch: [% d/% d], Step: [% d/% d], Loss: %.4f, Accuracy: %4f'\n",
        "          % (epoch + 1, num_epochs, num_train_steps, len(loader_train) * num_epochs, loss.item(), accuracy.item())) \n",
        "        validate(num_train_steps+1)\n",
        "      #print(torch.cuda.memory_allocated(device))\n",
        "      #print(torch.cuda.memory_cached(device))\n",
        "      end = time.time()\n",
        "      #print(end-start)\n",
        "      del abstract, abstract_lengths, subcategory, category, result, argmax\n",
        "      torch.cuda.empty_cache()\n",
        "      \n",
        "      if num_train_steps % 1 == 0:  \n",
        "        #Tensorboard logging\n",
        "        to_log = {'loss': loss.item(), 'accuracy': accuracy.item()}\n",
        "        for handle, val in to_log.items():\n",
        "            logger.scalar_summary(handle, val, num_train_steps+1)\n",
        "            \n",
        "    evaluate()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: [ 1/ 8], Step: [ 99/ 17312], Loss: 5.3816, Accuracy: 0.048828\n",
            "The validation accuracy is: 6.4453125% [512]\n",
            "Epoch: [ 1/ 8], Step: [ 199/ 17312], Loss: 5.3469, Accuracy: 0.080078\n",
            "The validation accuracy is: 5.859375% [512]\n",
            "Epoch: [ 1/ 8], Step: [ 299/ 17312], Loss: 5.3896, Accuracy: 0.041016\n",
            "The validation accuracy is: 2.9296875% [512]\n",
            "Epoch: [ 1/ 8], Step: [ 399/ 17312], Loss: 4.9805, Accuracy: 0.082031\n",
            "The validation accuracy is: 8.0078125% [512]\n",
            "Epoch: [ 1/ 8], Step: [ 499/ 17312], Loss: 4.9285, Accuracy: 0.091797\n",
            "The validation accuracy is: 8.984375% [512]\n",
            "Epoch: [ 1/ 8], Step: [ 599/ 17312], Loss: 5.1298, Accuracy: 0.070312\n",
            "The validation accuracy is: 9.5703125% [512]\n",
            "Epoch: [ 1/ 8], Step: [ 699/ 17312], Loss: 4.6173, Accuracy: 0.121094\n",
            "The validation accuracy is: 9.765625% [512]\n",
            "Epoch: [ 1/ 8], Step: [ 799/ 17312], Loss: 4.6023, Accuracy: 0.113281\n",
            "The validation accuracy is: 11.71875% [512]\n",
            "Epoch: [ 1/ 8], Step: [ 899/ 17312], Loss: 4.5458, Accuracy: 0.109375\n",
            "The validation accuracy is: 13.0859375% [512]\n",
            "Epoch: [ 1/ 8], Step: [ 999/ 17312], Loss: 4.2471, Accuracy: 0.126953\n",
            "The validation accuracy is: 14.453125% [512]\n",
            "Epoch: [ 1/ 8], Step: [ 1099/ 17312], Loss: 4.0529, Accuracy: 0.173828\n",
            "The validation accuracy is: 17.1875% [512]\n",
            "Epoch: [ 1/ 8], Step: [ 1199/ 17312], Loss: 3.8896, Accuracy: 0.179688\n",
            "The validation accuracy is: 19.921875% [512]\n",
            "Epoch: [ 1/ 8], Step: [ 1299/ 17312], Loss: 3.8995, Accuracy: 0.181641\n",
            "The validation accuracy is: 20.3125% [512]\n",
            "Epoch: [ 1/ 8], Step: [ 1399/ 17312], Loss: 3.6038, Accuracy: 0.210938\n",
            "The validation accuracy is: 18.75% [512]\n",
            "Epoch: [ 1/ 8], Step: [ 1499/ 17312], Loss: 3.5794, Accuracy: 0.226562\n",
            "The validation accuracy is: 24.21875% [512]\n",
            "Epoch: [ 1/ 8], Step: [ 1599/ 17312], Loss: 3.3689, Accuracy: 0.253906\n",
            "The validation accuracy is: 22.4609375% [512]\n",
            "Epoch: [ 1/ 8], Step: [ 1699/ 17312], Loss: 3.3959, Accuracy: 0.257812\n",
            "The validation accuracy is: 26.171875% [512]\n",
            "Epoch: [ 1/ 8], Step: [ 1799/ 17312], Loss: 3.3501, Accuracy: 0.289062\n",
            "The validation accuracy is: 21.484375% [512]\n",
            "Epoch: [ 1/ 8], Step: [ 1899/ 17312], Loss: 3.2762, Accuracy: 0.279297\n",
            "The validation accuracy is: 26.3671875% [512]\n",
            "Epoch: [ 1/ 8], Step: [ 1999/ 17312], Loss: 3.1368, Accuracy: 0.306641\n",
            "The validation accuracy is: 30.46875% [512]\n",
            "Epoch: [ 1/ 8], Step: [ 2099/ 17312], Loss: 3.3095, Accuracy: 0.253906\n",
            "The validation accuracy is: 26.3671875% [512]\n",
            "The testing set accuracy is: 29.131248059048264% [138752]\n",
            "Epoch: [ 2/ 8], Step: [ 2199/ 17312], Loss: 3.1704, Accuracy: 0.289062\n",
            "The validation accuracy is: 30.2734375% [512]\n",
            "Epoch: [ 2/ 8], Step: [ 2299/ 17312], Loss: 3.1582, Accuracy: 0.320312\n",
            "The validation accuracy is: 31.25% [512]\n",
            "Epoch: [ 2/ 8], Step: [ 2399/ 17312], Loss: 3.0269, Accuracy: 0.291016\n",
            "The validation accuracy is: 30.859375% [512]\n",
            "Epoch: [ 2/ 8], Step: [ 2499/ 17312], Loss: 3.0455, Accuracy: 0.294922\n",
            "The validation accuracy is: 36.1328125% [512]\n",
            "Epoch: [ 2/ 8], Step: [ 2599/ 17312], Loss: 2.9971, Accuracy: 0.320312\n",
            "The validation accuracy is: 31.0546875% [512]\n",
            "Epoch: [ 2/ 8], Step: [ 2699/ 17312], Loss: 3.0669, Accuracy: 0.308594\n",
            "The validation accuracy is: 30.2734375% [512]\n",
            "Epoch: [ 2/ 8], Step: [ 2799/ 17312], Loss: 2.9412, Accuracy: 0.304688\n",
            "The validation accuracy is: 31.25% [512]\n",
            "Epoch: [ 2/ 8], Step: [ 2899/ 17312], Loss: 2.9581, Accuracy: 0.296875\n",
            "The validation accuracy is: 33.984375% [512]\n",
            "Epoch: [ 2/ 8], Step: [ 2999/ 17312], Loss: 2.8694, Accuracy: 0.337891\n",
            "The validation accuracy is: 31.640625% [512]\n",
            "Epoch: [ 2/ 8], Step: [ 3099/ 17312], Loss: 2.9605, Accuracy: 0.289062\n",
            "The validation accuracy is: 29.8828125% [512]\n",
            "Epoch: [ 2/ 8], Step: [ 3199/ 17312], Loss: 2.8798, Accuracy: 0.341797\n",
            "The validation accuracy is: 33.984375% [512]\n",
            "Epoch: [ 2/ 8], Step: [ 3299/ 17312], Loss: 2.8619, Accuracy: 0.353516\n",
            "The validation accuracy is: 34.1796875% [512]\n",
            "Epoch: [ 2/ 8], Step: [ 3399/ 17312], Loss: 2.7596, Accuracy: 0.361328\n",
            "The validation accuracy is: 32.8125% [512]\n",
            "Epoch: [ 2/ 8], Step: [ 3499/ 17312], Loss: 2.7203, Accuracy: 0.359375\n",
            "The validation accuracy is: 36.9140625% [512]\n",
            "Epoch: [ 2/ 8], Step: [ 3599/ 17312], Loss: 2.9664, Accuracy: 0.298828\n",
            "The validation accuracy is: 34.9609375% [512]\n",
            "Epoch: [ 2/ 8], Step: [ 3699/ 17312], Loss: 2.7966, Accuracy: 0.367188\n",
            "The validation accuracy is: 34.375% [512]\n",
            "Epoch: [ 2/ 8], Step: [ 3799/ 17312], Loss: 2.7982, Accuracy: 0.328125\n",
            "The validation accuracy is: 33.203125% [512]\n",
            "Epoch: [ 2/ 8], Step: [ 3899/ 17312], Loss: 2.7082, Accuracy: 0.380859\n",
            "The validation accuracy is: 39.2578125% [512]\n",
            "Epoch: [ 2/ 8], Step: [ 3999/ 17312], Loss: 2.6805, Accuracy: 0.375000\n",
            "The validation accuracy is: 36.328125% [512]\n",
            "Epoch: [ 2/ 8], Step: [ 4099/ 17312], Loss: 2.7486, Accuracy: 0.343750\n",
            "The validation accuracy is: 31.640625% [512]\n",
            "Epoch: [ 2/ 8], Step: [ 4199/ 17312], Loss: 2.8198, Accuracy: 0.343750\n",
            "The validation accuracy is: 33.3984375% [512]\n",
            "Epoch: [ 2/ 8], Step: [ 4299/ 17312], Loss: 2.7254, Accuracy: 0.361328\n",
            "The validation accuracy is: 36.9140625% [512]\n",
            "The testing set accuracy is: 36.65311310602832% [138752]\n",
            "Epoch: [ 3/ 8], Step: [ 4399/ 17312], Loss: 2.6532, Accuracy: 0.359375\n",
            "The validation accuracy is: 36.9140625% [512]\n",
            "Epoch: [ 3/ 8], Step: [ 4499/ 17312], Loss: 2.7636, Accuracy: 0.365234\n",
            "The validation accuracy is: 35.9375% [512]\n",
            "Epoch: [ 3/ 8], Step: [ 4599/ 17312], Loss: 2.6941, Accuracy: 0.369141\n",
            "The validation accuracy is: 34.1796875% [512]\n",
            "Epoch: [ 3/ 8], Step: [ 4699/ 17312], Loss: 2.7149, Accuracy: 0.347656\n",
            "The validation accuracy is: 35.3515625% [512]\n",
            "Epoch: [ 3/ 8], Step: [ 4799/ 17312], Loss: 2.7390, Accuracy: 0.353516\n",
            "The validation accuracy is: 34.375% [512]\n",
            "Epoch: [ 3/ 8], Step: [ 4899/ 17312], Loss: 2.7792, Accuracy: 0.337891\n",
            "The validation accuracy is: 38.4765625% [512]\n",
            "Epoch: [ 3/ 8], Step: [ 4999/ 17312], Loss: 2.6319, Accuracy: 0.367188\n",
            "The validation accuracy is: 36.71875% [512]\n",
            "Epoch: [ 3/ 8], Step: [ 5099/ 17312], Loss: 2.5818, Accuracy: 0.388672\n",
            "The validation accuracy is: 40.625% [512]\n",
            "Epoch: [ 3/ 8], Step: [ 5199/ 17312], Loss: 2.6170, Accuracy: 0.396484\n",
            "The validation accuracy is: 37.3046875% [512]\n",
            "Epoch: [ 3/ 8], Step: [ 5299/ 17312], Loss: 2.5611, Accuracy: 0.398438\n",
            "The validation accuracy is: 40.8203125% [512]\n",
            "Epoch: [ 3/ 8], Step: [ 5399/ 17312], Loss: 2.6221, Accuracy: 0.380859\n",
            "The validation accuracy is: 33.984375% [512]\n",
            "Epoch: [ 3/ 8], Step: [ 5499/ 17312], Loss: 2.4732, Accuracy: 0.400391\n",
            "The validation accuracy is: 38.8671875% [512]\n",
            "Epoch: [ 3/ 8], Step: [ 5599/ 17312], Loss: 2.5422, Accuracy: 0.384766\n",
            "The validation accuracy is: 39.84375% [512]\n",
            "Epoch: [ 3/ 8], Step: [ 5699/ 17312], Loss: 2.4474, Accuracy: 0.429688\n",
            "The validation accuracy is: 34.9609375% [512]\n",
            "Epoch: [ 3/ 8], Step: [ 5799/ 17312], Loss: 2.4817, Accuracy: 0.375000\n",
            "The validation accuracy is: 38.8671875% [512]\n",
            "Epoch: [ 3/ 8], Step: [ 5899/ 17312], Loss: 2.5232, Accuracy: 0.384766\n",
            "The validation accuracy is: 38.4765625% [512]\n",
            "Epoch: [ 3/ 8], Step: [ 5999/ 17312], Loss: 2.4915, Accuracy: 0.388672\n",
            "The validation accuracy is: 39.453125% [512]\n",
            "Epoch: [ 3/ 8], Step: [ 6099/ 17312], Loss: 2.5121, Accuracy: 0.410156\n",
            "The validation accuracy is: 43.5546875% [512]\n",
            "Epoch: [ 3/ 8], Step: [ 6199/ 17312], Loss: 2.6134, Accuracy: 0.375000\n",
            "The validation accuracy is: 36.328125% [512]\n",
            "Epoch: [ 3/ 8], Step: [ 6299/ 17312], Loss: 2.5808, Accuracy: 0.367188\n",
            "The validation accuracy is: 34.765625% [512]\n",
            "Epoch: [ 3/ 8], Step: [ 6399/ 17312], Loss: 2.4431, Accuracy: 0.384766\n",
            "The validation accuracy is: 42.578125% [512]\n",
            "The testing set accuracy is: 39.44880581816081% [138752]\n",
            "Epoch: [ 4/ 8], Step: [ 6499/ 17312], Loss: 2.3977, Accuracy: 0.419922\n",
            "The validation accuracy is: 37.109375% [512]\n",
            "Epoch: [ 4/ 8], Step: [ 6599/ 17312], Loss: 2.4501, Accuracy: 0.419922\n",
            "The validation accuracy is: 38.28125% [512]\n",
            "Epoch: [ 4/ 8], Step: [ 6699/ 17312], Loss: 2.3729, Accuracy: 0.416016\n",
            "The validation accuracy is: 35.7421875% [512]\n",
            "Epoch: [ 4/ 8], Step: [ 6799/ 17312], Loss: 2.4865, Accuracy: 0.376953\n",
            "The validation accuracy is: 36.1328125% [512]\n",
            "Epoch: [ 4/ 8], Step: [ 6899/ 17312], Loss: 2.4339, Accuracy: 0.408203\n",
            "The validation accuracy is: 39.6484375% [512]\n",
            "Epoch: [ 4/ 8], Step: [ 6999/ 17312], Loss: 2.5355, Accuracy: 0.380859\n",
            "The validation accuracy is: 39.84375% [512]\n",
            "Epoch: [ 4/ 8], Step: [ 7099/ 17312], Loss: 2.3825, Accuracy: 0.427734\n",
            "The validation accuracy is: 38.8671875% [512]\n",
            "Epoch: [ 4/ 8], Step: [ 7199/ 17312], Loss: 2.4041, Accuracy: 0.408203\n",
            "The validation accuracy is: 41.6015625% [512]\n",
            "Epoch: [ 4/ 8], Step: [ 7299/ 17312], Loss: 2.3736, Accuracy: 0.431641\n",
            "The validation accuracy is: 37.109375% [512]\n",
            "Epoch: [ 4/ 8], Step: [ 7399/ 17312], Loss: 2.3622, Accuracy: 0.427734\n",
            "The validation accuracy is: 46.2890625% [512]\n",
            "Epoch: [ 4/ 8], Step: [ 7499/ 17312], Loss: 2.3747, Accuracy: 0.410156\n",
            "The validation accuracy is: 40.8203125% [512]\n",
            "Epoch: [ 4/ 8], Step: [ 7599/ 17312], Loss: 2.3525, Accuracy: 0.396484\n",
            "The validation accuracy is: 41.6015625% [512]\n",
            "Epoch: [ 4/ 8], Step: [ 7699/ 17312], Loss: 2.2558, Accuracy: 0.398438\n",
            "The validation accuracy is: 42.3828125% [512]\n",
            "Epoch: [ 4/ 8], Step: [ 7799/ 17312], Loss: 2.2782, Accuracy: 0.427734\n",
            "The validation accuracy is: 36.328125% [512]\n",
            "Epoch: [ 4/ 8], Step: [ 7899/ 17312], Loss: 2.3248, Accuracy: 0.412109\n",
            "The validation accuracy is: 37.6953125% [512]\n",
            "Epoch: [ 4/ 8], Step: [ 7999/ 17312], Loss: 2.3549, Accuracy: 0.421875\n",
            "The validation accuracy is: 40.8203125% [512]\n",
            "Epoch: [ 4/ 8], Step: [ 8099/ 17312], Loss: 2.2799, Accuracy: 0.429688\n",
            "The validation accuracy is: 41.2109375% [512]\n",
            "Epoch: [ 4/ 8], Step: [ 8199/ 17312], Loss: 2.2667, Accuracy: 0.425781\n",
            "The validation accuracy is: 39.6484375% [512]\n",
            "Epoch: [ 4/ 8], Step: [ 8299/ 17312], Loss: 2.2914, Accuracy: 0.404297\n",
            "The validation accuracy is: 39.2578125% [512]\n",
            "Epoch: [ 4/ 8], Step: [ 8399/ 17312], Loss: 2.3013, Accuracy: 0.421875\n",
            "The validation accuracy is: 36.328125% [512]\n",
            "Epoch: [ 4/ 8], Step: [ 8499/ 17312], Loss: 2.3950, Accuracy: 0.384766\n",
            "The validation accuracy is: 41.6015625% [512]\n",
            "Epoch: [ 4/ 8], Step: [ 8599/ 17312], Loss: 2.3979, Accuracy: 0.443359\n",
            "The validation accuracy is: 37.109375% [512]\n",
            "The testing set accuracy is: 40.84412442313109% [138752]\n",
            "Epoch: [ 5/ 8], Step: [ 8699/ 17312], Loss: 2.1532, Accuracy: 0.458984\n",
            "The validation accuracy is: 37.890625% [512]\n",
            "Epoch: [ 5/ 8], Step: [ 8799/ 17312], Loss: 2.2359, Accuracy: 0.425781\n",
            "The validation accuracy is: 37.3046875% [512]\n",
            "Epoch: [ 5/ 8], Step: [ 8899/ 17312], Loss: 2.1336, Accuracy: 0.480469\n",
            "The validation accuracy is: 38.8671875% [512]\n",
            "Epoch: [ 5/ 8], Step: [ 8999/ 17312], Loss: 2.3429, Accuracy: 0.404297\n",
            "The validation accuracy is: 42.3828125% [512]\n",
            "Epoch: [ 5/ 8], Step: [ 9099/ 17312], Loss: 2.1782, Accuracy: 0.441406\n",
            "The validation accuracy is: 42.578125% [512]\n",
            "Epoch: [ 5/ 8], Step: [ 9199/ 17312], Loss: 2.3069, Accuracy: 0.453125\n",
            "The validation accuracy is: 39.84375% [512]\n",
            "Epoch: [ 5/ 8], Step: [ 9299/ 17312], Loss: 2.2944, Accuracy: 0.398438\n",
            "The validation accuracy is: 38.8671875% [512]\n",
            "Epoch: [ 5/ 8], Step: [ 9399/ 17312], Loss: 2.2182, Accuracy: 0.449219\n",
            "The validation accuracy is: 40.234375% [512]\n",
            "Epoch: [ 5/ 8], Step: [ 9499/ 17312], Loss: 2.2705, Accuracy: 0.455078\n",
            "The validation accuracy is: 42.3828125% [512]\n",
            "Epoch: [ 5/ 8], Step: [ 9599/ 17312], Loss: 2.2783, Accuracy: 0.447266\n",
            "The validation accuracy is: 43.5546875% [512]\n",
            "Epoch: [ 5/ 8], Step: [ 9699/ 17312], Loss: 2.3660, Accuracy: 0.437500\n",
            "The validation accuracy is: 46.09375% [512]\n",
            "Epoch: [ 5/ 8], Step: [ 9799/ 17312], Loss: 2.4192, Accuracy: 0.396484\n",
            "The validation accuracy is: 39.2578125% [512]\n",
            "Epoch: [ 5/ 8], Step: [ 9899/ 17312], Loss: 2.2332, Accuracy: 0.439453\n",
            "The validation accuracy is: 41.015625% [512]\n",
            "Epoch: [ 5/ 8], Step: [ 9999/ 17312], Loss: 2.3273, Accuracy: 0.425781\n",
            "The validation accuracy is: 39.6484375% [512]\n",
            "Epoch: [ 5/ 8], Step: [ 10099/ 17312], Loss: 2.2545, Accuracy: 0.437500\n",
            "The validation accuracy is: 43.359375% [512]\n",
            "Epoch: [ 5/ 8], Step: [ 10199/ 17312], Loss: 2.0832, Accuracy: 0.503906\n",
            "The validation accuracy is: 38.28125% [512]\n",
            "Epoch: [ 5/ 8], Step: [ 10299/ 17312], Loss: 2.3571, Accuracy: 0.402344\n",
            "The validation accuracy is: 41.6015625% [512]\n",
            "Epoch: [ 5/ 8], Step: [ 10399/ 17312], Loss: 2.1638, Accuracy: 0.455078\n",
            "The validation accuracy is: 43.1640625% [512]\n",
            "Epoch: [ 5/ 8], Step: [ 10499/ 17312], Loss: 2.1919, Accuracy: 0.451172\n",
            "The validation accuracy is: 40.4296875% [512]\n",
            "Epoch: [ 5/ 8], Step: [ 10599/ 17312], Loss: 2.2143, Accuracy: 0.425781\n",
            "The validation accuracy is: 39.453125% [512]\n",
            "Epoch: [ 5/ 8], Step: [ 10699/ 17312], Loss: 2.1210, Accuracy: 0.457031\n",
            "The validation accuracy is: 41.015625% [512]\n",
            "Epoch: [ 5/ 8], Step: [ 10799/ 17312], Loss: 2.2119, Accuracy: 0.457031\n",
            "The validation accuracy is: 40.4296875% [512]\n",
            "The testing set accuracy is: 41.57356116796545% [138752]\n",
            "Epoch: [ 6/ 8], Step: [ 10899/ 17312], Loss: 2.0900, Accuracy: 0.470703\n",
            "The validation accuracy is: 38.8671875% [512]\n",
            "Epoch: [ 6/ 8], Step: [ 10999/ 17312], Loss: 2.1532, Accuracy: 0.482422\n",
            "The validation accuracy is: 41.9921875% [512]\n",
            "Epoch: [ 6/ 8], Step: [ 11099/ 17312], Loss: 2.2460, Accuracy: 0.421875\n",
            "The validation accuracy is: 38.8671875% [512]\n",
            "Epoch: [ 6/ 8], Step: [ 11199/ 17312], Loss: 2.0853, Accuracy: 0.460938\n",
            "The validation accuracy is: 40.625% [512]\n",
            "Epoch: [ 6/ 8], Step: [ 11299/ 17312], Loss: 2.2855, Accuracy: 0.431641\n",
            "The validation accuracy is: 39.84375% [512]\n",
            "Epoch: [ 6/ 8], Step: [ 11399/ 17312], Loss: 2.1596, Accuracy: 0.447266\n",
            "The validation accuracy is: 42.7734375% [512]\n",
            "Epoch: [ 6/ 8], Step: [ 11499/ 17312], Loss: 2.1524, Accuracy: 0.447266\n",
            "The validation accuracy is: 44.921875% [512]\n",
            "Epoch: [ 6/ 8], Step: [ 11599/ 17312], Loss: 2.1085, Accuracy: 0.492188\n",
            "The validation accuracy is: 40.234375% [512]\n",
            "Epoch: [ 6/ 8], Step: [ 11699/ 17312], Loss: 2.1065, Accuracy: 0.466797\n",
            "The validation accuracy is: 41.6015625% [512]\n",
            "Epoch: [ 6/ 8], Step: [ 11799/ 17312], Loss: 2.2805, Accuracy: 0.423828\n",
            "The validation accuracy is: 40.625% [512]\n",
            "Epoch: [ 6/ 8], Step: [ 11899/ 17312], Loss: 1.8700, Accuracy: 0.498047\n",
            "The validation accuracy is: 39.2578125% [512]\n",
            "Epoch: [ 6/ 8], Step: [ 11999/ 17312], Loss: 2.2767, Accuracy: 0.439453\n",
            "The validation accuracy is: 41.40625% [512]\n",
            "Epoch: [ 6/ 8], Step: [ 12099/ 17312], Loss: 2.2939, Accuracy: 0.427734\n",
            "The validation accuracy is: 40.234375% [512]\n",
            "Epoch: [ 6/ 8], Step: [ 12199/ 17312], Loss: 2.0748, Accuracy: 0.458984\n",
            "The validation accuracy is: 45.8984375% [512]\n",
            "Epoch: [ 6/ 8], Step: [ 12299/ 17312], Loss: 2.2078, Accuracy: 0.449219\n",
            "The validation accuracy is: 41.40625% [512]\n",
            "Epoch: [ 6/ 8], Step: [ 12399/ 17312], Loss: 2.0711, Accuracy: 0.460938\n",
            "The validation accuracy is: 42.1875% [512]\n",
            "Epoch: [ 6/ 8], Step: [ 12499/ 17312], Loss: 2.1461, Accuracy: 0.445312\n",
            "The validation accuracy is: 45.1171875% [512]\n",
            "Epoch: [ 6/ 8], Step: [ 12599/ 17312], Loss: 2.2076, Accuracy: 0.462891\n",
            "The validation accuracy is: 39.2578125% [512]\n",
            "Epoch: [ 6/ 8], Step: [ 12699/ 17312], Loss: 2.2165, Accuracy: 0.433594\n",
            "The validation accuracy is: 40.234375% [512]\n",
            "Epoch: [ 6/ 8], Step: [ 12799/ 17312], Loss: 2.1398, Accuracy: 0.453125\n",
            "The validation accuracy is: 43.9453125% [512]\n",
            "Epoch: [ 6/ 8], Step: [ 12899/ 17312], Loss: 2.2141, Accuracy: 0.443359\n",
            "The validation accuracy is: 37.5% [512]\n",
            "The testing set accuracy is: 42.20549894195561% [138752]\n",
            "Epoch: [ 7/ 8], Step: [ 12999/ 17312], Loss: 2.1787, Accuracy: 0.439453\n",
            "The validation accuracy is: 40.4296875% [512]\n",
            "Epoch: [ 7/ 8], Step: [ 13099/ 17312], Loss: 2.1691, Accuracy: 0.437500\n",
            "The validation accuracy is: 39.0625% [512]\n",
            "Epoch: [ 7/ 8], Step: [ 13199/ 17312], Loss: 2.1715, Accuracy: 0.462891\n",
            "The validation accuracy is: 38.0859375% [512]\n",
            "Epoch: [ 7/ 8], Step: [ 13299/ 17312], Loss: 1.9855, Accuracy: 0.492188\n",
            "The validation accuracy is: 42.3828125% [512]\n",
            "Epoch: [ 7/ 8], Step: [ 13399/ 17312], Loss: 2.0334, Accuracy: 0.484375\n",
            "The validation accuracy is: 43.75% [512]\n",
            "Epoch: [ 7/ 8], Step: [ 13499/ 17312], Loss: 2.0898, Accuracy: 0.447266\n",
            "The validation accuracy is: 43.75% [512]\n",
            "Epoch: [ 7/ 8], Step: [ 13599/ 17312], Loss: 2.0975, Accuracy: 0.472656\n",
            "The validation accuracy is: 43.75% [512]\n",
            "Epoch: [ 7/ 8], Step: [ 13699/ 17312], Loss: 2.0694, Accuracy: 0.466797\n",
            "The validation accuracy is: 40.0390625% [512]\n",
            "Epoch: [ 7/ 8], Step: [ 13799/ 17312], Loss: 2.1100, Accuracy: 0.468750\n",
            "The validation accuracy is: 41.40625% [512]\n",
            "Epoch: [ 7/ 8], Step: [ 13899/ 17312], Loss: 2.1488, Accuracy: 0.460938\n",
            "The validation accuracy is: 43.75% [512]\n",
            "Epoch: [ 7/ 8], Step: [ 13999/ 17312], Loss: 2.1282, Accuracy: 0.455078\n",
            "The validation accuracy is: 40.0390625% [512]\n",
            "Epoch: [ 7/ 8], Step: [ 14099/ 17312], Loss: 2.0302, Accuracy: 0.486328\n",
            "The validation accuracy is: 38.671875% [512]\n",
            "Epoch: [ 7/ 8], Step: [ 14199/ 17312], Loss: 2.0648, Accuracy: 0.433594\n",
            "The validation accuracy is: 41.796875% [512]\n",
            "Epoch: [ 7/ 8], Step: [ 14299/ 17312], Loss: 2.2323, Accuracy: 0.453125\n",
            "The validation accuracy is: 42.1875% [512]\n",
            "Epoch: [ 7/ 8], Step: [ 14399/ 17312], Loss: 2.0400, Accuracy: 0.460938\n",
            "The validation accuracy is: 42.3828125% [512]\n",
            "Epoch: [ 7/ 8], Step: [ 14499/ 17312], Loss: 2.0936, Accuracy: 0.453125\n",
            "The validation accuracy is: 41.796875% [512]\n",
            "Epoch: [ 7/ 8], Step: [ 14599/ 17312], Loss: 2.1387, Accuracy: 0.470703\n",
            "The validation accuracy is: 39.84375% [512]\n",
            "Epoch: [ 7/ 8], Step: [ 14699/ 17312], Loss: 2.2190, Accuracy: 0.462891\n",
            "The validation accuracy is: 43.75% [512]\n",
            "Epoch: [ 7/ 8], Step: [ 14799/ 17312], Loss: 2.1765, Accuracy: 0.437500\n",
            "The validation accuracy is: 41.015625% [512]\n",
            "Epoch: [ 7/ 8], Step: [ 14899/ 17312], Loss: 2.2103, Accuracy: 0.431641\n",
            "The validation accuracy is: 40.234375% [512]\n",
            "Epoch: [ 7/ 8], Step: [ 14999/ 17312], Loss: 2.1935, Accuracy: 0.437500\n",
            "The validation accuracy is: 42.7734375% [512]\n",
            "Epoch: [ 7/ 8], Step: [ 15099/ 17312], Loss: 2.0203, Accuracy: 0.460938\n",
            "The validation accuracy is: 41.40625% [512]\n",
            "The testing set accuracy is: 42.526162223843194% [138752]\n",
            "Epoch: [ 8/ 8], Step: [ 15199/ 17312], Loss: 1.9456, Accuracy: 0.488281\n",
            "The validation accuracy is: 41.2109375% [512]\n",
            "Epoch: [ 8/ 8], Step: [ 15299/ 17312], Loss: 2.1104, Accuracy: 0.468750\n",
            "The validation accuracy is: 38.0859375% [512]\n",
            "Epoch: [ 8/ 8], Step: [ 15399/ 17312], Loss: 1.8710, Accuracy: 0.482422\n",
            "The validation accuracy is: 40.234375% [512]\n",
            "Epoch: [ 8/ 8], Step: [ 15499/ 17312], Loss: 1.9841, Accuracy: 0.476562\n",
            "The validation accuracy is: 38.8671875% [512]\n",
            "Epoch: [ 8/ 8], Step: [ 15599/ 17312], Loss: 2.1211, Accuracy: 0.466797\n",
            "The validation accuracy is: 43.9453125% [512]\n",
            "Epoch: [ 8/ 8], Step: [ 15699/ 17312], Loss: 2.0630, Accuracy: 0.494141\n",
            "The validation accuracy is: 42.96875% [512]\n",
            "Epoch: [ 8/ 8], Step: [ 15799/ 17312], Loss: 2.0889, Accuracy: 0.503906\n",
            "The validation accuracy is: 42.1875% [512]\n",
            "Epoch: [ 8/ 8], Step: [ 15899/ 17312], Loss: 1.8843, Accuracy: 0.509766\n",
            "The validation accuracy is: 42.578125% [512]\n",
            "Epoch: [ 8/ 8], Step: [ 15999/ 17312], Loss: 2.0927, Accuracy: 0.476562\n",
            "The validation accuracy is: 42.578125% [512]\n",
            "Epoch: [ 8/ 8], Step: [ 16099/ 17312], Loss: 1.8542, Accuracy: 0.513672\n",
            "The validation accuracy is: 45.1171875% [512]\n",
            "Epoch: [ 8/ 8], Step: [ 16199/ 17312], Loss: 1.8868, Accuracy: 0.523438\n",
            "The validation accuracy is: 38.28125% [512]\n",
            "Epoch: [ 8/ 8], Step: [ 16299/ 17312], Loss: 1.9869, Accuracy: 0.496094\n",
            "The validation accuracy is: 42.1875% [512]\n",
            "Epoch: [ 8/ 8], Step: [ 16399/ 17312], Loss: 2.0440, Accuracy: 0.492188\n",
            "The validation accuracy is: 37.890625% [512]\n",
            "Epoch: [ 8/ 8], Step: [ 16499/ 17312], Loss: 1.9544, Accuracy: 0.476562\n",
            "The validation accuracy is: 41.6015625% [512]\n",
            "Epoch: [ 8/ 8], Step: [ 16599/ 17312], Loss: 2.1787, Accuracy: 0.466797\n",
            "The validation accuracy is: 40.4296875% [512]\n",
            "Epoch: [ 8/ 8], Step: [ 16699/ 17312], Loss: 2.0112, Accuracy: 0.521484\n",
            "The validation accuracy is: 42.7734375% [512]\n",
            "Epoch: [ 8/ 8], Step: [ 16799/ 17312], Loss: 1.9641, Accuracy: 0.501953\n",
            "The validation accuracy is: 45.703125% [512]\n",
            "Epoch: [ 8/ 8], Step: [ 16899/ 17312], Loss: 2.0810, Accuracy: 0.466797\n",
            "The validation accuracy is: 40.234375% [512]\n",
            "Epoch: [ 8/ 8], Step: [ 16999/ 17312], Loss: 2.1762, Accuracy: 0.455078\n",
            "The validation accuracy is: 37.5% [512]\n",
            "Epoch: [ 8/ 8], Step: [ 17099/ 17312], Loss: 2.2529, Accuracy: 0.472656\n",
            "The validation accuracy is: 37.3046875% [512]\n",
            "Epoch: [ 8/ 8], Step: [ 17199/ 17312], Loss: 1.9425, Accuracy: 0.501953\n",
            "The validation accuracy is: 43.1640625% [512]\n",
            "Epoch: [ 8/ 8], Step: [ 17299/ 17312], Loss: 2.0856, Accuracy: 0.478516\n",
            "The validation accuracy is: 41.9921875% [512]\n",
            "The testing set accuracy is: 42.547828661808566% [138752]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}